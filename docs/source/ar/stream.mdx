# ุงูุจุซ ุงููุจุงุดุฑ

ูุชูุญ ูู ุจุซ ูุฌููุนุฉ ุงูุจูุงูุงุช ุงูุนูู ูุน ูุฌููุนุฉ ุจูุงูุงุช ุฏูู ุชูุฒูููุง. ูุชู ุจุซ ุงูุจูุงูุงุช ุฃุซูุงุก ุชูููู ุนุจุฑ ูุฌููุนุฉ ุงูุจูุงูุงุช. ููุฐุง ูููุฏ ุจุดูู ุฎุงุต ุนูุฏูุง:

- ูุง ุชุฑูุฏ ุงูุงูุชุธุงุฑ ุญุชู ูุชู ุชูุฒูู ูุฌููุนุฉ ุจูุงูุงุช ูุจูุฑุฉ ููุบุงูุฉ.
- ูุชุฌุงูุฒ ุญุฌู ูุฌููุนุฉ ุงูุจูุงูุงุช ูุณุงุญุฉ ุงููุฑุต ุงููุชููุฑุฉ ุนูู ุฌูุงุฒ ุงูููุจููุชุฑ ุงูุฎุงุต ุจู.
- ุชุฑูุฏ ุงุณุชูุดุงู ุนุฏุฏ ูููู ููุท ูู ุนููุงุช ูุฌููุนุฉ ุงูุจูุงูุงุช ุจุณุฑุนุฉ.

![ุตูุฑุฉ ูุชุญุฑูุฉ ุชูุถุญ ุจุซ ูุฌููุนุฉ ุงูุจูุงูุงุช](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/datasets/streaming.gif)

ุนูู ุณุจูู ุงููุซุงูุ ูุจูุบ ุญุฌู ูุณู ุงููุบุฉ ุงูุฅูุฌููุฒูุฉ ูู ูุฌููุนุฉ ุจูุงูุงุช [oscar-corpus/OSCAR-2201](https://huggingface.co/datasets/oscar-corpus/OSCAR-2201) 1.2 ุชูุฑุงุจุงูุชุ ูููู ููููู ุงุณุชุฎุฏุงููุง ุนูู ุงูููุฑ ุจุงุณุชุฎุฏุงู ุงูุจุซ. ูู ุจุจุซ ูุฌููุนุฉ ุจูุงูุงุช ุนู ุทุฑูู ุชุนููู `streaming=True` ูู [`load_dataset`] ููุง ูู ููุถุญ ุฃุฏูุงู:

```py
>>> from datasets import load_dataset
>>> dataset = load_dataset('oscar-corpus/OSCAR-2201', 'en', split='train', streaming=True)
>>> print(next(iter(dataset)))
{'id': 0, 'text': 'ุชุฃุณุณุช Golden Bees ูู ุนุงู 2015ุ ููู ููุตุฉ ุชูุธูู ุจุฑูุฌูุฉ ูุฎุตุตุฉ ูุฃุตุญุงุจ ุงูุนูู ูููุงูุงุช ุงูุชูุธูู ููุฌุงูุณ ุงูุนูู. ููุฏ ุทูุฑุช ุงูุดุฑูุฉ ุชูููุงุช ูุฎุตุตุฉ ููููุงุฑุฏ ุงูุจุดุฑูุฉ ูุฎูุงุฑุฒููุงุช ุชูุจุคูุฉ ูุฑูุฏุฉ ูุชุญุฏูุฏ ุฃูุถู ุงููุฑุดุญูู ููุฑุตุฉ ุนูู ูุฌุฐุจูู.'ุ ...
```

ููุง ูุณูุญ ุจุซ ูุฌููุนุฉ ุงูุจูุงูุงุช ุจุงูุนูู ูุน ูุฌููุนุฉ ุจูุงูุงุช ูุตููุนุฉ ูู ูููุงุช ูุญููุฉ ุฏูู ุฅุฌุฑุงุก ุฃู ุชุญููู. ูู ูุฐู ุงูุญุงูุฉุ ูุชู ุจุซ ุงูุจูุงูุงุช ูู ุงููููุงุช ุงููุญููุฉ ุฃุซูุงุก ุชูููู ุนุจุฑ ูุฌููุนุฉ ุงูุจูุงูุงุช. ููุฐุง ูููุฏ ุจุดูู ุฎุงุต ุนูุฏูุง:

- ูุง ุชุฑูุฏ ุงูุงูุชุธุงุฑ ุญุชู ูุชู ุชุญููู ูุฌููุนุฉ ุจูุงูุงุช ูุญููุฉ ูุจูุฑุฉ ุฌุฏูุง ุฅูู Arrow.
- ุณูุชุฌุงูุฒ ุญุฌู ุงููููุงุช ุงููุญููุฉ ูุณุงุญุฉ ุงููุฑุต ุงููุชููุฑุฉ ุนูู ุฌูุงุฒ ุงูููุจููุชุฑ ุงูุฎุงุต ุจู.
- ุชุฑูุฏ ุงุณุชูุดุงู ุนุฏุฏ ูููู ููุท ูู ุนููุงุช ูุฌููุนุฉ ุงูุจูุงูุงุช ุจุณุฑุนุฉ.

ุนูู ุณุจูู ุงููุซุงูุ ููููู ุจุซ ูุฌููุนุฉ ุจูุงูุงุช ูุญููุฉ ููููุฉ ูู ูุฆุงุช ูููุงุช JSONL ุงููุถุบูุทุฉ ูุซู [oscar-corpus/OSCAR-2201](https://huggingface.co/datasets/oscar-corpus/OSCAR-2201) ูุงุณุชุฎุฏุงููุง ุนูู ุงูููุฑ:

```py
>>> from datasets import load_dataset
>>> data_files = {'train': 'path/to/OSCAR-2201/compressed/en_meta/*.jsonl.gz'}
>>> dataset = load_dataset('json', data_files=data_files, split='train', streaming=True)
>>> print(next(iter(dataset)))
{'id': 0, 'text': 'ุชุฃุณุณุช Golden Bees ูู ุนุงู 2015ุ ููู ููุตุฉ ุชูุธูู ุจุฑูุฌูุฉ ูุฎุตุตุฉ ูุฃุตุญุงุจ ุงูุนูู ูููุงูุงุช ุงูุชูุธูู ููุฌุงูุณ ุงูุนูู. ููุฏ ุทูุฑุช ุงูุดุฑูุฉ ุชูููุงุช ูุฎุตุตุฉ ููููุงุฑุฏ ุงูุจุดุฑูุฉ ูุฎูุงุฑุฒููุงุช ุชูุจุคูุฉ ูุฑูุฏุฉ ูุชุญุฏูุฏ ุฃูุถู ุงููุฑุดุญูู ููุฑุตุฉ ุนูู ูุฌุฐุจูู.'ุ ...
```

ูุคุฏู ุชุญููู ูุฌููุนุฉ ุจูุงูุงุช ูู ูุถุน ุงูุจุซ ุฅูู ุฅูุดุงุก ูุซูู ููุน ูุฌููุนุฉ ุจูุงูุงุช ุฌุฏูุฏุฉ (ุจุฏูุงู ูู ูุงุฆู [`Dataset`] ุงูููุงุณููู)ุ ุงููุนุฑูู ุจุงุณู [`IterableDataset`]. ูุญุชูู ูุฐุง ุงูููุน ุงูุฎุงุต ูู ูุฌููุนุฉ ุงูุจูุงูุงุช ุนูู ูุฌููุนุฉ ุฎุงุตุฉ ุจู ูู ุทุฑู ุงููุนุงูุฌุฉ ุงูููุถุญุฉ ุฃุฏูุงู.

> ููุงุญุธุฉ: ุชุนุฏ [`IterableDataset`] ูููุฏุฉ ูููุธุงุฆู ุงููุชูุฑุฑุฉ ูุซู ุชุฏุฑูุจ ูููุฐุฌ. ูุง ูุฌุจ ุงุณุชุฎุฏุงู [`IterableDataset`] ูููุธุงุฆู ุงูุชู ุชุชุทูุจ ุงููุตูู ุงูุนุดูุงุฆู ุฅูู ุงูุฃูุซูุฉ ูุฃูู ูุถุทุฑ ููุชููู ูู ุฌููุน ุฃูุญุงุก ุจุงุณุชุฎุฏุงู ุญููุฉ for. ุณูุชุทูุจ ุงูุญุตูู ุนูู ุงููุซุงู ุงูุฃุฎูุฑ ูู ูุฌููุนุฉ ุจูุงูุงุช ูุงุจูุฉ ููุชููู ููู ุงูุชููู ุนุจุฑ ุฌููุน ุงูุฃูุซูุฉ ุงูุณุงุจูุฉ. ููููู ุงูุนุซูุฑ ุนูู ูุฒูุฏ ูู ุงูุชูุงุตูู ูู ุฏููู [Dataset vs. IterableDataset](./about_mapstyle_vs_iterable).

## ุงูุชุญููู ูู ูุฌููุนุฉ ุจูุงูุงุช

ุฅุฐุง ูุงู ูุฏูู ูุงุฆู [`Dataset`] ููุฌูุฏุ ูููููู ุชุญูููู ุฅูู [`IterableDataset`] ุจุงุณุชุฎุฏุงู ุฏุงูุฉ [`~Dataset.to_iterable_dataset`]. ูู ุงููุงูุนุ ูุฐุง ุฃุณุฑุน ูู ุชุนููู ูุณูุท `streaming=True` ูู [`load_dataset`] ูุฃู ุงูุจูุงูุงุช ูุชู ุจุซูุง ูู ูููุงุช ูุญููุฉ.

```py
>>> from datasets import load_dataset

# ุฃุณุฑุน ๐
>>> dataset = load_dataset("food101")
>>> iterable_dataset = dataset.to_iterable_dataset()

# ุฃุจุทุฃ ๐ข
>>> iterable_dataset = load_dataset("food101", streaming=True)
```

ุชุฏุนู ุฏุงูุฉ [`~Dataset.to_iterable_dataset`] ุงูุชุฌุฒุฆุฉ ุนูุฏูุง ูุชู ุฅูุดุงุก ูุซูู [`IterableDataset`]. ูุฐุง ูููุฏ ุนูุฏ ุงูุนูู ูุน ูุฌููุนุงุช ุจูุงูุงุช ูุจูุฑุฉุ ูุชุฑุบุจ ูู ุฎูุท ูุฌููุนุฉ ุงูุจูุงูุงุช ุฃู ุชูููู ุงูุชุญููู ุงูููุงุฒู ุงูุณุฑูุน ุจุงุณุชุฎุฏุงู PyTorch DataLoader.

```py
>>> import torch
>>> from datasets import load_dataset

>>> dataset = load_dataset("food101")
>>> iterable_dataset = dataset.to_iterable_dataset(num_shards=64) # ุชุฌุฒุฆุฉ ูุฌููุนุฉ ุงูุจูุงูุงุช
>>> iterable_dataset = iterable_dataset.shuffle(buffer_size=10_000)  # ุฎูุท ุชุฑุชูุจ ุงูุชุฌุฒุฆุฉ ูุงุณุชุฎุฏุงู ูุฎุฒู ูุคูุช ููุฎูุท ุนูุฏ ุจุฏุก ุงูุชููู
dataloader = torch.utils.data.DataLoader(iterable_datasetุ num_workers=4)  # ุชุนููู 64 / 4 = 16 ุดุธูุฉ ูู ูุงุฆูุฉ ุงูุชุฌุฒุฆุฉ ุงููุฎููุทุฉ ููู ุนุงูู ุนูุฏ ุจุฏุก ุงูุชููู
```

## ุฎูุท

ูุซู ูุงุฆู [`Dataset`] ุงูุนุงุฏูุ ููููู ุฃูุถูุง ุฎูุท [`IterableDataset`] ุจุงุณุชุฎุฏุงู [`IterableDataset.shuffle`].

ูุชุญูู ูุณูุท `buffer_size` ูู ุญุฌู ุงููุฎุฒู ุงููุคูุช ูุงุฎุชูุงุฑ ุฃูุซูุฉ ุนุดูุงุฆูุฉ ููู. ูููุชุฑุถ ุฃู ูุฏูู ูุฌููุนุฉ ุจูุงูุงุช ุชุญุชูู ุนูู ููููู ูุซุงูุ ูุชุญุฏุฏ ุญุฌู ุงููุฎุฒู ุงููุคูุช ุฅูู ุนุดุฑุฉ ุขูุงู. ุณูุฎุชุงุฑ [`IterableDataset.shuffle`] ุนุดูุงุฆููุง ุฃูุซูุฉ ูู ุฃูู ุนุดุฑุฉ ุขูุงู ูุซุงู ูู ุงููุฎุฒู ุงููุคูุช. ูุชู ุงุณุชุจุฏุงู ุงูุฃูุซูุฉ ุงููุญุฏุฏุฉ ูู ุงููุฎุฒู ุงููุคูุช ุจุฃูุซูุฉ ุฌุฏูุฏุฉ. ูููู ุญุฌู ุงููุฎุฒู ุงููุคูุช ุงูุงูุชุฑุงุถู 1000.

```py
>>> from datasets import load_dataset
>>> dataset = load_dataset('oscar', "unshuffled_deduplicated_en"ุ split='train'ุ streaming=True)
>>> shuffled_dataset = dataset.shuffle(seed=42ุ buffer_size=10_000)
```

> ุชูููุญ: ุณูููู [`IterableDataset.shuffle`] ุฃูุถูุง ุจุฎูุท ุชุฑุชูุจ ุงูุชุฌุฒุฆุฉ ุฅุฐุง ุชู ุชูุณูู ูุฌููุนุฉ ุงูุจูุงูุงุช ุฅูู ูููุงุช ูุชุนุฏุฏุฉ.

## ุฅุนุงุฏุฉ ุงูุฎูุท

ูู ุจุนุถ ุงูุฃุญูุงูุ ูุฏ ุชุฑุบุจ ูู ุฅุนุงุฏุฉ ุฎูุท ูุฌููุนุฉ ุงูุจูุงูุงุช ุจุนุฏ ูู ูุชุฑุฉ. ุณูุชุทูุจ ุฐูู ููู ุชุนููู ุจุฐุฑุฉ ูุฎุชููุฉ ููู ูุชุฑุฉ. ุงุณุชุฎุฏู [`IterableDataset.set_epoch`] ุจูู ุงููุชุฑุงุช ูุฅุฎุจุงุฑ ูุฌููุนุฉ ุงูุจูุงูุงุช ุจุงููุชุฑุฉ ุงูุชู ุฃูุช ูููุง.

ุชุตุจุญ ุงูุจุฐุฑุฉ ุงูุฎุงุตุฉ ุจู ุจุดูู ูุนุงู: `ุงูุจุฐุฑุฉ ุงูุฃูููุฉ + ุงููุชุฑุฉ ุงูุญุงููุฉ`.

```py
>>> for epoch in range(epochs):
...     shuffled_dataset.set_epoch(epoch)
...     for example in shuffled_dataset:
...         ...
```

## ุชูุณูู ูุฌููุนุฉ ุงูุจูุงูุงุช

ููููู ุชูุณูู ูุฌููุนุฉ ุงูุจูุงูุงุช ุงูุฎุงุตุฉ ุจู ุจุทุฑููุชูู:

- [`IterableDataset.take`] ูุนูุฏ ุฃูู `n` ุฃูุซูุฉ ูู ูุฌููุนุฉ ุจูุงูุงุช:

```py
>>> dataset = load_dataset('oscar', "unshuffled_deduplicated_en"ุ split='train'ุ streaming=True)
>>> dataset_head = dataset.take(2)
>>> list(dataset_head)
[{'id': 0ุ 'text': 'ูุฑูุฉ ูุชูุฏูุฑู ูุณุชูุญุงุฉ ูู ุงูุฑุคูุฉ ...'}, {'id': 1ุ 'text': 'ูุง ุชุณุชุทูุน ูููู ุฌููุณ ูุญุงุฑุจุฉ ุงูููุณููู ...'}]
```

- [`IterableDataset.skip`] ูุชุฌุงูู ุฃูู `n` ุฃูุซูุฉ ูู ูุฌููุนุฉ ุจูุงูุงุช ููุนูุฏ ุงูุฃูุซูุฉ ุงููุชุจููุฉ:

```py
>>> train_dataset = shuffled_dataset.skip(1000)
```

> ุชุญุฐูุฑ: ุชููุน `take` ู`skip` ุงูุงุณุชุฏุนุงุกุงุช ุงููุณุชูุจููุฉ ูู `shuffle` ูุฃููุง ุชููู ุชุฑุชูุจ ุงูุชุฌุฒุฆุฉ. ูุฌุจ ุนููู `ุฎูุท` ูุฌููุนุฉ ุงูุจูุงูุงุช ุงูุฎุงุตุฉ ุจู ูุจู ุชูุณูููุง.

<a id='interleave_datasets'></a>

## ุงูุชุฏุงุฎู

ูููู ุฃู [`interleave_datasets`] ุงูุฌูุน ุจูู [`IterableDataset`] ูุน ูุฌููุนุงุช ุงูุจูุงูุงุช ุงูุฃุฎุฑู. ุชุฌูุน ูุฌููุนุฉ ุงูุจูุงูุงุช ุงููุดุชุฑูุฉ ุฃูุซูุฉ ูุชูุงูุจุฉ ูู ูู ูู ูุฌููุนุงุช ุงูุจูุงูุงุช ุงูุฃุตููุฉ.

```py
>>> from datasets import interleave_datasets
>>> en_dataset = load_dataset('oscar', "unshuffled_deduplicated_en"ุ split='train'ุ streaming=Trueุ trust_remote_code=True)
>>> fr_dataset = load_dataset('oscar', "unshuffled_deduplicated_fr"ุ split='train'ุ streaming=Trueุ trust_remote_code=True)

>>> multilingual_dataset = interleave_datasets([en_datasetุ fr_dataset])
>>> list(multilingual_dataset.take(2))
[{'text': 'ูุฑูุฉ ูุชูุฏูุฑู ูุณุชูุญุงุฉ ูู ุงูุฑุคูุฉ ...'}, {'text': "ููุฏูุง ููููุงุด ุงูุฃููุงุฑ ูุงูุซูุงูุฉ ูุงูุฃุฏุจ ..."}]
```

ุญุฏุฏ ุงุญุชูุงูุงุช ุฃุฎุฐ ุงูุนููุงุช ูู ูู ูู ูุฌููุนุงุช ุงูุจูุงูุงุช ุงูุฃุตููุฉ ููุฒูุฏ ูู ุงูุชุญูู ูู ููููุฉ ุฃุฎุฐ ุงูุนููุงุช ูู ูู ูููุง ูุฏูุฌูุง. ูู ุจุชุนููู ูุณูุท `probabilities` ูุน ุงุญุชูุงูุงุช ุฃุฎุฐ ุงูุนููุงุช ุงููุฑุบูุจุฉ:

```py
>>> multilingual_dataset_with_oversampling = interleave_datasets([en_datasetุ fr_dataset]ุ probabilities=[0.8ุ 0.2]ุ seed=42)
>>> list(multilingual_dataset_with_oversampling.take(2))
[{'text': 'ูุฑูุฉ ูุชูุฏูุฑู ูุณุชูุญุงุฉ ูู ุงูุฑุคูุฉ ...'}, {'text': 'ูุง ุชุณุชุทูุน ูููู ุฌููุณ ูุญุงุฑุจุฉ ุงูููุณููู ...'}]
```

ุญูุงูู 80% ูู ูุฌููุนุฉ ุงูุจูุงูุงุช ุงูููุงุฆูุฉ ูุตููุนุฉ ูู `en_dataset`ุ ู20% ูู `fr_dataset`.

ููููู ุฃูุถูุง ุชุญุฏูุฏ `stopping_strategy`. ุงูุงุณุชุฑุงุชูุฌูุฉ ุงูุงูุชุฑุงุถูุฉุ `first_exhausted`ุ ูู ุงุณุชุฑุงุชูุฌูุฉ ุงูุงุณุชุฎูุงุต ุงููุฑุนูุ ุฃู ูุชู ุฅููุงู ุจูุงุก ูุฌููุนุฉ ุงูุจูุงูุงุช ุจูุฌุฑุฏ ููุงุฏ ุนููุงุช ุฅุญุฏู ูุฌููุนุงุช ุงูุจูุงูุงุช.

ููููู ุชุญุฏูุฏ `stopping_strategy=all_exhausted` ูุชูููุฐ ุงุณุชุฑุงุชูุฌูุฉ ุงูุฅูุฑุงุท ูู ุฃุฎุฐ ุงูุนููุงุช. ูู ูุฐู ุงูุญุงูุฉุ ูุชููู ุจูุงุก ูุฌููุนุฉ ุงูุจูุงูุงุช ุจูุฌุฑุฏ ุฅุถุงูุฉ ูู ุนููุฉ ูู ูู ูุฌููุนุฉ ุจูุงูุงุช ูุฑุฉ ูุงุญุฏุฉ ุนูู ุงูุฃูู. ูู ุงูููุงุฑุณุฉ ุงูุนูููุฉุ ูุฐุง ูุนูู ุฃูู ุฅุฐุง ููุฏุช ูุฌููุนุฉ ุงูุจูุงูุงุชุ ูุณุชุนูุฏ ุฅูู ุจุฏุงูุฉ ูุฌููุนุฉ ุงูุจูุงูุงุช ูุฐู ุญุชู ูุชู ุงููุตูู ุฅูู ูุนูุงุฑ ุงูุชููู.

ูุงุญุธ ุฃูู ุฅุฐุง ูู ูุชู ุชุญุฏูุฏ ุงุญุชูุงูุงุช ุฃุฎุฐ ุงูุนููุงุชุ ูุณุชุญุชูู ูุฌููุนุฉ ุงูุจูุงูุงุช ุงูุฌุฏูุฏุฉ ุนูู `max_length_datasets*nb_dataset samples`.

## ุฅุนุงุฏุฉ ุงูุชุณููุฉ ูุงูุฅุฒุงูุฉ ูุงูุตุจ

ุชุณูุญ ุงูุทุฑู ุงูุชุงููุฉ ุจุชุนุฏูู ุฃุนูุฏุฉ ูุฌููุนุฉ ุงูุจูุงูุงุช. ูุฐู ุงูุทุฑู ูููุฏุฉ ูุฅุนุงุฏุฉ ุชุณููุฉ ุงูุฃุนูุฏุฉ ุฃู ุฅุฒุงูุชูุง ุฃู ุชุบููุฑูุง ุฅูู ูุฌููุนุฉ ุฌุฏูุฏุฉ ูู ุงูููุฒุงุช.

### ุฅุนุงุฏุฉ ุงูุชุณููุฉ

ุงุณุชุฎุฏู [`IterableDataset.rename_column`] ุนูุฏ ุงูุญุงุฌุฉ ุฅูู ุฅุนุงุฏุฉ ุชุณููุฉ ุนููุฏ ูู ูุฌููุนุฉ ุงูุจูุงูุงุช ุงูุฎุงุตุฉ ุจู. ูุชู ููู ุงูููุฒุงุช ุงููุฑุชุจุทุฉ ุจุงูุนููุฏ ุงูุฃุตูู ูุนูููุง ุชุญุช ุงุณู ุงูุนููุฏ ุงูุฌุฏูุฏุ ุจุฏูุงู ูู ูุฌุฑุฏ ุงุณุชุจุฏุงู ุงูุนููุฏ ุงูุฃุตูู ูู ููุงูู.

ูู ุจุชุฒููุฏ [`IterableDataset.rename_column`] ุจุงุณู ุงูุนููุฏ ุงูุฃุตููุ ูุงุณู ุงูุนููุฏ ุงูุฌุฏูุฏ:

```py
>>> from datasets import load_dataset
>>> dataset = load_dataset('mc4', 'en'ุ streaming=Trueุ split='train'ุ trust_remote_code=True)
>>> dataset = dataset.rename_column("text"ุ "content")
```

### ุฅุฒุงูุฉ

ุนูุฏูุง ุชุญุชุงุฌ ุฅูู ุฅุฒุงูุฉ ุนููุฏ ูุงุญุฏ ุฃู ุฃูุซุฑุ ูู ุจุชุฒููุฏ [`IterableDataset.remove_columns`] ุจุงุณู ุงูุนููุฏ ุงูุฐู ุณูุชู ุฅุฒุงูุชู. ูู ุจุฅุฒุงูุฉ ุฃูุซุฑ ูู ุนููุฏ ูุงุญุฏ ุนู ุทุฑูู ุชูููุฑ ูุงุฆูุฉ ุจุฃุณูุงุก ุงูุฃุนูุฏุฉ:

```py
>>> from datasets import load_dataset
>>> dataset = load_dataset('mc4', 'en'ุ streaming=Trueุ split='train'ุ trust_remote_code=True)
>>> dataset = dataset.remove_columns('timestamp')
```

### Cast

[`IterableDataset.cast`] ูุบูุฑ ููุน ุงูููุฒุฉ ููุงุญุฏ ุฃู ุฃูุซุฑ ูู ุงูุฃุนูุฏุฉ. ุชุฃุฎุฐ ูุฐู ุงูุทุฑููุฉ `Features` ุงูุฌุฏูุฏ ุงูุฎุงุต ุจู ููุณูุท ููุง. ููุถุญ ูุซุงู ุงูุชุนูููุงุช ุงูุจุฑูุฌูุฉ ุงูุชุงูู ููููุฉ ุชุบููุฑ ุฃููุงุน ุงูููุฒุงุช ูู `ClassLabel` ู`Value`:

```py
>>> from datasets import load_dataset
>>> dataset = load_dataset('glue', 'mrpc'ุ split='train'ุ streaming=True)
>>> dataset.features
{'sentence1': Value(dtype='string'ุ id=None)ุ
'sentence2': Value(dtype='string'ุ id=None)ุ
'label': ClassLabel(num_classes=2ุ names=['not_equivalent'ุ 'equivalent']ุ names_file=Noneุ id=None)ุ
'idx': Value(dtype='int32'ุ id=None)}

>>> from datasets import ClassLabelุ Value
>>> new_features = dataset.features.copy()
>>> new_features["label"] = ClassLabel(names=['negative'ุ 'positive'])
>>> new_features["idx"] = Value('int64')
>>> dataset = dataset.cast(new_features)
>>> dataset.features
{'sentence1': Value(dtype='string'ุ id=None)ุ
'sentence2': Value(dtype='string'ุ id=None)ุ
'label': ClassLabel(num_classes=2ุ names=['negative'ุ 'positive']ุ names_file=Noneุ id=None)ุ
'idx': Value(dtype='int64'ุ id=None)}
```

> ุชูููุญ: ูุนูู ุงูุตุจ ููุท ุฅุฐุง ูุงู ููุน ุงูููุฒุฉ ุงูุฃุตูู ูููุน ุงูููุฒุฉ ุงูุฌุฏูุฏ ูุชูุงูููู. ุนูู ุณุจูู ุงููุซุงูุ ููููู ุตุจ ุนููุฏ ุจุณูุงุช `Value('int32')` ุฅูู `Value('bool')` ุฅุฐุง ูุงู ุงูุนููุฏ ุงูุฃุตูู ูุญุชูู ููุท ุนูู ุฃุญุงุฏ ูุตูุงุฑ.

ุงุณุชุฎุฏู [`IterableDataset.cast_column`] ูุชุบููุฑ ููุน ุงูููุฒุฉ ูุนููุฏ ูุงุญุฏ ููุท. ูุฑุฑ ุงุณู ุงูุนููุฏ ูููุน ุงูููุฒุฉ ุงูุฌุฏูุฏ ุงูุฎุงุต ุจู ููุณูุทุงุช:

```py
>>> dataset.features
{'audio': Audio(sampling_rate=44100ุ mono=Trueุ id=None)}

>>> dataset = dataset.cast_column("audio"ุ Audio(sampling_rate=16000))
>>> dataset.features
{'audio': Audio(sampling_rate=16000ุ mono=Trueุ id=None)}
```
## Map

ุนูู ุบุฑุงุฑ ูุธููุฉ [`Dataset.map`] ููุฌููุนุฉ ุจูุงูุงุช ุนุงุฏูุฉ [`Dataset`]ุ ุชููุฑ ููุชุจุฉ ๐ค Datasets ูุธููุฉ [`IterableDataset.map`] ููุนุงูุฌุฉ [`IterableDataset`].

ุชุทุจู [`IterableDataset.map`] ุงููุนุงูุฌุฉ ุฃุซูุงุก ุงูุชููู ุนูุฏูุง ูุชู ุจุซ ุงูุฃูุซูุฉ.

ุชุชูุญ ูู ุชุทุจูู ุฏุงูุฉ ูุนุงูุฌุฉ ุนูู ูู ูุซุงู ูู ูุฌููุนุฉ ุงูุจูุงูุงุชุ ุจุดูู ูุณุชูู ุฃู ูู ูุฌููุนุงุช. ูููู ููุฐู ุงูุฏุงูุฉ ุญุชู ุฅูุดุงุก ุตููู ูุฃุนูุฏุฉ ุฌุฏูุฏุฉ.

ููุถุญ ุงููุซุงู ุงูุชุงูู ููููุฉ ุชููููุฒุงุช ูุฌููุนุฉ ุจูุงูุงุช [`IterableDataset`]. ูุฌุจ ุฃู ุชูุจู ุงูุฏุงูุฉ ุฅุฎุฑุงุฌ "dict":

```py
>>> def add_prefix(example):
...     example['text'] = 'My text: ' + example['text']
...     return example
```

ุจุนุฏ ุฐููุ ูู ุจุชุทุจูู ูุฐู ุงูุฏุงูุฉ ุนูู ูุฌููุนุฉ ุงูุจูุงูุงุช ุจุงุณุชุฎุฏุงู [`IterableDataset.map`]:

```py
>>> from datasets import load_dataset
>>> dataset = load_dataset('oscar', 'unshuffled_deduplicated_en', streaming=True, split='train', trust_remote_code=True)
>>> updated_dataset = dataset.map(add_prefix)
>>> list(updated_dataset.take(3))
[{'id': 0, 'text': 'My text: Mtendere Village was inspired by...'},
{'id': 1, 'text': 'My text: Lily James cannot fight the music...'},
{'id': 2, 'text': 'My text: "I\'d love to help kickstart...'}]
```

ุฏุนููุง ูููู ูุธุฑุฉ ุนูู ูุซุงู ุขุฎุฑุ ูููู ูุฐู ุงููุฑุฉุ ุณูู ุชููู ุจุฅุฒุงูุฉ ุนููุฏ ุจุงุณุชุฎุฏุงู [`IterableDataset.map`]. ุนูุฏ ุฅุฒุงูุฉ ุนููุฏุ ุชุชู ุฅุฒุงูุชู ููุท ุจุนุฏ ุชูููุฑ ุงููุซุงู ููุฏุงูุฉ ุงููุญุฏุฏุฉ. ูุณูุญ ูุฐุง ููุฏุงูุฉ ุงููุญุฏุฏุฉ ุจุงุณุชุฎุฏุงู ูุญุชูู ุงูุฃุนูุฏุฉ ูุจู ุฅุฒุงูุชูุง.

ุญุฏุฏ ุงูุนููุฏ ุงูุฐู ุชุฑูุฏ ุฅุฒุงูุชู ุจุงุณุชุฎุฏุงู ูุณูุท `remove_columns` ูู [`IterableDataset.map`]:

```py
>>> updated_dataset = dataset.map(add_prefix, remove_columns=["id"])
>>> list(updated_dataset.take(3))
[{'text': 'My text: Mtendere Village was inspired by...'},
{'text': 'My text: Lily James cannot fight the music...'},
{'text': 'My text: "I\'d love to help kickstart...'}]
```

### ูุนุงูุฌุฉ ุงูุฏูุนุงุช

ูุฏุนู [`IterableDataset.map`] ุฃูุถูุง ุงูุนูู ูุน ุฏูุนุงุช ูู ุงูุฃูุซูุฉ. ููุนูู ุนูู ุงูุฏูุนุงุชุ ูู ุจุชุนููู `batched=True`. ุญุฌู ุงูุฏูุนุฉ ุงูุงูุชุฑุงุถู ูู 1000ุ ูููู ููููู ุถุจุทู ุจุงุณุชุฎุฏุงู ูุณูุท `batch_size`. ููุชุญ ูุฐุง ุงูุจุงุจ ุฃูุงู ุงูุนุฏูุฏ ูู ุงูุชุทุจููุงุช ุงููุซูุฑุฉ ููุงูุชูุงู ูุซู ุงูุชููููุฒุงุชุ ูุชูุณูู ุงูุฌูู ุงูุทูููุฉ ุฅูู ูุทุน ุฃูุตุฑุ ูุชุนุฒูุฒ ุงูุจูุงูุงุช.

#### ุงูุชููููุฒุงุช

```py
>>> from datasets import load_dataset
>>> from transformers import AutoTokenizer
>>> dataset = load_dataset("mc4", "en", streaming=True, split="train", trust_remote_code=True)
>>> tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')
>>> def encode(examples):
...     return tokenizer(examples['text'], truncation=True, padding='max_length')
>>> dataset = dataset.map(encode, batched=True, remove_columns=["text", "timestamp", "url"])
>>> next(iter(dataset))
{'input_ids': [101, 8466, 1018, 1010, 4029, 2475, 2062, 18558, 3100, 2061, ...,1106, 3739, 102],
'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ..., 1, 1]}
```

<Tip>

ุฑุงุฌุน ุฃูุซูุฉ ุฃุฎุฑู ุนูู ูุนุงูุฌุฉ ุงูุฏูุนุงุช ูู ูุซุงุฆู [ูุนุงูุฌุฉ ุงูุฎุฑุงุฆุท ุฐุงุช ุงูุฏูุนุงุช](./process#batch-processing). ุชุนูู ุจููุณ ุงูุทุฑููุฉ ููุฌููุนุงุช ุงูุจูุงูุงุช ุงููุงุจูุฉ ููุจุซ.

</Tip>

### ูุฑุดุญ

ููููู ุชุตููุฉ ุงูุตููู ูู ูุฌููุนุฉ ุงูุจูุงูุงุช ุจูุงุกู ุนูู ุฏุงูุฉ ุดุฑุทูุฉ ุจุงุณุชุฎุฏุงู [`Dataset.filter`]. ููู ูุนูุฏ ุงูุตููู ุงูุชู ุชุชุทุงุจู ูุน ุดุฑุท ูุญุฏุฏ:

```py
>>> from datasets import load_dataset
>>> dataset = load_dataset('oscar', 'unshuffled_deduplicated_en', streaming=True, split='train', trust_remote_code=True)
>>> start_with_ar = dataset.filter(lambda example: example['text'].startswith('Ar'))
>>> next(iter(start_with_ar))
{'id': 4, 'text': 'Are you looking for Number the Stars (Essential Modern Classics)?...'}
```

ูููู ุฃูุถูุง ูู [`Dataset.filter`] ุงูุชุตููุฉ ุญุณุจ ุงูููุงุฑุณ ุฅุฐุง ููุช ุจุชุนููู `with_indices=True`:

```py
>>> even_dataset = dataset.filter(lambda example, idx: idx % 2 == 0, with_indices=True)
>>> list(even_dataset.take(3))
[{'id': 0, 'text': 'Mtendere Village was inspired by the vision of Chief Napoleon Dzombe, ...'},
{'id': 2, 'text': '"I\'d love to help kickstart continued development! And 0 EUR/month...'},
{'id': 4, 'text': 'Are you looking for Number the Stars (Essential Modern Classics)? Normally, ...'}]
```

## ุงูุจุซ ูู ุญููุฉ ุชุฏุฑูุจ

ูููู ุฏูุฌ [`IterableDataset`] ูู ุญููุฉ ุชุฏุฑูุจ. ุฃููุงูุ ูู ุจุฎูุท ูุฌููุนุฉ ุงูุจูุงูุงุช:

<frameworkcontent>
<pt>
```py
>>> seed, buffer_size = 42, 10_000
>>> dataset = dataset.shuffle(seed, buffer_size=buffer_size)
```

ุฃุฎูุฑูุงุ ูู ุจุฅูุดุงุก ุญููุฉ ุชุฏุฑูุจ ุจุณูุทุฉ ูุงุจุฏุฃ ุงูุชุฏุฑูุจ:

```py
>>> import torch
>>> from torch.utils.data import DataLoader
>>> from transformers import AutoModelForMaskedLM, DataCollatorForLanguageModeling
>>> from tqdm import tqdm
>>> dataset = dataset.with_format("torch")
>>> dataloader = DataLoader(dataset, collate_fn=DataCollatorForLanguageModeling(tokenizer))
>>> device = 'cuda' if torch.cuda.is_available() else 'cpu'
>>> model = AutoModelForMaskedLM.from_pretrained("distilbert-base-uncased")
>>> model.train().to(device)
>>> optimizer = torch.optim.AdamW(params=model.parameters(), lr=1e-5)
>>> for epoch in range(3):
...     dataset.set_epoch(epoch)
...     for i, batch in enumerate(tqdm(dataloader, total=5)):
...         if i == 5:
...             break
...         batch = {k: v.to(device) for k, v in batch.items()}
...         outputs = model(**batch)
...         loss = outputs[0]
...         loss.backward()
...         optimizer.step()
...         optimizer.zero_grad()
...         if i % 10 == 0:
...             print(f"loss: {loss}")
```

</pt>
</frameworkcontent>

<!-- TODO: ุงูุชุจ ุงููุญุชูู TF! -->

### ุญูุธ ููุทุฉ ุชูุชูุด ููุฌููุนุฉ ุงูุจูุงูุงุช ูุงุณุชุฆูุงู ุงูุชูุฑุงุฑ

ุฅุฐุง ุชูููุช ุญููุฉ ุงูุชุฏุฑูุจ ุงูุฎุงุตุฉ ุจูุ ููุฏ ุชุฑุบุจ ูู ุงุณุชุฆูุงู ุงูุชุฏุฑูุจ ูู ุญูุซ ุชูููุช. ููููุงู ุจุฐููุ ููููู ุญูุธ ููุทุฉ ุชูุชูุด ููููุฐุฌู ููุคุดุฑุงุช ุงูุชุฑุงุจุทุ ุจุงูุฅุถุงูุฉ ุฅูู ุจุฑูุงูุฌ ุชุญููู ุงูุจูุงูุงุช ุงูุฎุงุต ุจู.

ูุง ุชููุฑ ูุฌููุนุงุช ุงูุจูุงูุงุช ุงููุงุจูุฉ ููุจุซ ุฅููุงููุฉ ุงููุตูู ุงูุนุดูุงุฆู ุฅูู ููุฑุณ ูุซุงู ูุญุฏุฏ ูุงุณุชุฆูุงู ุงูุนูู ูููุ ูููู ููููู ุงุณุชุฎุฏุงู [`IterableDataset.state_dict`] ู [`IterableDataset.load_state_dict`] ูุงุณุชุฆูุงู ุงูุนูู ูู ููุทุฉ ุชูุชูุด ุจุฏูุงู ูู ุฐููุ ุนูู ุบุฑุงุฑ ูุง ููููู ุงูููุงู ุจู ููููุงุฐุฌ ููุคุดุฑุงุช ุงูุชุฑุงุจุท:

```python
>>> iterable_dataset = Dataset.from_dict({"a": range(6)}).to_iterable_dataset(num_shards=3)
>>> for idx, example in enumerate(iterable_dataset):
...     print(example)
...     if idx == 2:
...         state_dict = iterable_dataset.state_dict()
...         print("checkpoint")
...         break
>>> iterable_dataset.load_state_dict(state_dict)
>>> print(f"restart from checkpoint")
>>> for example in iterable_dataset:
...     print(example)
```

ุงูุฅุฑุฌุงุน:

```
{'a': 0}
{'a': 1}
{'a': 2}
checkpoint
restart from checkpoint
{'a': 3}
{'a': 4}
{'a': 5}
```

ุชุญุช ุงูุบุทุงุกุ ุชุญุชูุธ ูุฌููุนุฉ ุงูุจูุงูุงุช ุงููุงุจูุฉ ููุจุซ ุจุชุชุจุน ุงูุดุฑูุญุฉ ุงูุญุงููุฉ ุงูุชู ุชุชู ูุฑุงุกุชูุง ูููุฑุณ ุงููุซุงู ูู ุงูุดุฑูุญุฉ ุงูุญุงููุฉุ ูุชุฎุฒู ูุฐู ุงููุนูููุงุช ูู `state_dict`.

ููุงุณุชุฆูุงู ูู ููุทุฉ ุชูุชูุดุ ุชููู ูุฌููุนุฉ ุงูุจูุงูุงุช ุจุชุฎุทู ุฌููุน ุงูุดุฑุงุฆุญ ุงูุชู ุชู ูุฑุงุกุชูุง ุณุงุจููุง ูุงุณุชุฆูุงู ุงูุนูู ูู ุงูุดุฑูุญุฉ ุงูุญุงููุฉ.

ุซู ุชูุฑุฃ ุงูุดุฑูุญุฉ ูุชุชุฎุทู ุงูุฃูุซูุฉ ุญุชู ุชุตู ุฅูู ุงููุซุงู ุงููุญุฏุฏ ูู ููุทุฉ ุงูุชูุชูุด.

ูุฐููุ ูุฅู ุฅุนุงุฏุฉ ุชุดุบูู ูุฌููุนุฉ ุจูุงูุงุช ุฃูุฑ ุณุฑูุน ููุบุงูุฉุ ุญูุซ ูู ุชููู ุจุฅุนุงุฏุฉ ูุฑุงุกุฉ ุงูุดุฑุงุฆุญ ุงูุชู ุชูุช ูุฑุงุกุชูุง ุจุงููุนู. ููุน ุฐููุ ูุฅู ุงุณุชุฆูุงู ูุฌููุนุฉ ุจูุงูุงุช ููุณ ููุฑููุง ุจุดูู ุนุงู ูุฃูู ูุฌุจ ุฃู ูุจุฏุฃ ุงููุฑุงุกุฉ ูู ุจุฏุงูุฉ ุงูุดุฑูุญุฉ ุงูุญุงููุฉ ููุชุฎุทู ุงูุฃูุซูุฉ ุญุชู ูุตู ุฅูู ูููุน ููุทุฉ ุงูุชูุชูุด.

ูููู ุงุณุชุฎุฏุงู ูุฐุง ูุน `StatefulDataLoader` ูู `torchdata`:

```python
>>> from torchdata.stateful_dataloader import StatefulDataLoader
>>> iterable_dataset = load_dataset("deepmind/code_contests", streaming=True, split="train")
>>> dataloader = StatefulDataLoader(iterable_dataset, batch_size=32, num_workers=4)
>>> # checkpoint
>>> state_dict = dataloader.state_dict() # uses iterable_dataset.state_dict() under the hood
>>> # resume from checkpoint
>>> dataloader.load_state_dict(state_dict) # uses iterable_dataset.load_state_dict() under the hood
```

<Tip>

ุชุณุชุฃูู ููุทุฉ ุงูุชูุชูุด ูู ุงูููุงู ุงูุฐู ุชู ุญูุธูุง ููู ุชูุงููุง ูุง ูู ูุชู ุงุณุชุฎุฏุงู `.shuffle()`: ูุชู ููุฏุงู ุงูุฃูุซูุฉ ูู ูุฎุงุฒู ุงูุชุฎุฒูู ุงููุคูุช ููุฎูุท ุนูุฏ ุงูุงุณุชุฆูุงู ููุชู ุฅุนุงุฏุฉ ููุก ุงููุฎุงุฒู ุงููุคูุชุฉ ุจุงูุจูุงูุงุช ุงูุฌุฏูุฏุฉ.

</Tip>