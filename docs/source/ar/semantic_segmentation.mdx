# التجزئة الدلالية

تُستخدم مجموعات بيانات التجزئة الدلالية لتدريب نموذج لتصنيف كل بكسل في صورة. وهناك مجموعة واسعة من التطبيقات التي تمكّنها هذه المجموعات من البيانات مثل إزالة الخلفية من الصور، أو تحويل الصور إلى أسلوب معين، أو فهم المشهد للقيادة الذاتية. سيوضح هذا الدليل كيفية تطبيق التحولات على مجموعة بيانات تجزئة الصور.

قبل البدء، تأكد من أن لديك الإصدارات المحدثة من `albumentations` و`cv2` المثبتة:

```bash
pip install -U albumentations opencv-python
```

[Albumentations](https://albumentations.ai/) هي مكتبة بايثون للقيام بزيادة البيانات للرؤية الحاسوبية. تدعم العديد من مهام الرؤية الحاسوبية مثل تصنيف الصور، وكشف الأشياء، والتجزئة، وتقدير النقاط الرئيسية.

يستخدم هذا الدليل مجموعة بيانات [Scene Parsing](https://huggingface.co/datasets/scene_parse_150) لتجزئة وتحليل صورة إلى مناطق صورة مختلفة مرتبطة بفئات دلالية، مثل السماء، والطريق، والشخص، والسرير.

قم بتحميل قسم `train` من مجموعة البيانات وإلقاء نظرة على مثال:

```py
>>> from datasets import load_dataset

>>> dataset = load_dataset("scene_parse_150", split="train")
>>> index = 10
>>> dataset[index]
{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=683x512 at 0x7FB37B0EC810>,
'annotation': <PIL.PngImagePlugin.PngImageFile image mode=L size=683x512 at 0x7FB37B0EC9D0>,
'scene_category': 927}
```

تحتوي مجموعة البيانات على ثلاثة حقول:

* `image`: كائن صورة PIL.
* `annotation`: قناع التجزئة للصورة.
* `scene_category`: التسمية أو فئة المشهد للصورة (مثل "المطبخ" أو "المكتب").

بعد ذلك، تحقق من صورة باستخدام:

```py
>>> dataset[index]["image"]
```

<div class="flex justify-center">
<img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/datasets/image_seg.png">
</div>

وبالمثل، يمكنك التحقق من قناع التجزئة المقابل:

```py
>>> dataset[index]["annotation"]
```

<div class="flex justify-center">
<img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/datasets/seg_mask.png">
</div>

يمكننا أيضًا إضافة [لوحة ألوان](https://github.com/tensorflow/models/blob/3f1ca33afe3c1631b733ea7e40c294273b9e406d/research/deeplab/utils/get_dataset_colormap.py#L51) على قناع التجزئة ووضعه فوق الصورة الأصلية لتصور مجموعة البيانات:

بعد تحديد لوحة الألوان، يجب أن تكون جاهزًا لعرض بعض الطبقات.

```py
>>> import matplotlib.pyplot as plt

>>> def visualize_seg_mask(image: np.ndarray, mask: np.ndarray):
    color_seg = np.zeros((mask.shape[0], mask.shape[1], 3), dtype=np.uint8)
    palette = np.array(create_ade20k_label_colormap())
    for label, color in enumerate(palette):
        color_seg[mask == label, :] = color
    color_seg = color_seg[..., ::-1] # تحويل إلى BGR

    img = np.array(image) * 0.5 + color_seg * 0.5 # عرض الصورة مع خريطة التجزئة
    img = img.astype(np.uint8)

    plt.figure(figsize=(15, 10))
    plt.imshow(img)
    plt.axis("off")
    plt.show()


>>> visualize_seg_mask(
    np.array(dataset[index]["image"]),
    np.array(dataset[index]["annotation"])
)
```

<div class="flex justify-center">
<img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/datasets/seg_overlay.png">
</div>

الآن قم بتطبيق بعض التحسينات باستخدام `albumentations`. أولاً، ستقوم بإعادة تحجيم الصورة وتعديل سطوعها.

```py
>>> import albumentations

>>> transform = albumentations.Compose(
    [
        albumentations.Resize(256, 256),
        albumentations.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=0.5),
    ]
)
```

قم بإنشاء دالة لتطبيق التحويل على الصور:

```py
>>> def transforms(examples):
    transformed_images, transformed_masks = [], []

    for image, seg_mask in zip(examples["image"], examples["annotation"]):
        image, seg_mask = np.array(image), np.array(seg_mask)
        transformed = transform(image=image, mask=seg_mask)
        transformed_images.append(transformed["image"])
        transformed_masks.append(transformed["mask"])

    examples["pixel_values"] = transformed_images
    examples["label"] = transformed_masks
    return examples
```

استخدم وظيفة [`~Dataset.set_transform`] لتطبيق التحويل أثناء التنقل على دفعات من مجموعة البيانات لتقليل مساحة القرص المستخدمة:

```py
>>> dataset.set_transform(transforms)
```

يمكنك التحقق من نجاح التحويل عن طريق الفهرسة في `pixel_values` و`label` لمثال:

```py
>>> image = np.array(dataset[index]["pixel_values"])
>>> mask = np.array(dataset[index]["label"])

>>> visualize_seg_mask(image, mask)
```

<div class="flex justify-center">
<img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/datasets/albumentations_seg.png">
</div>

في هذا الدليل، استخدمت `albumentations` لزيادة مجموعة البيانات. من الممكن أيضًا استخدام `torchvision` لتطبيق بعض التحولات المماثلة.

```py
>>> from torchvision.transforms import Resize, ColorJitter, Compose

>>> transformation_chain = Compose([
    Resize((256, 256)),
    ColorJitter(brightness=0.25, contrast=0.25, saturation=0.25, hue=0.1)
])
>>> resize = Resize((256, 256))

>>> def train_transforms(example_batch):
    example_batch["pixel_values"] = [transformation_chain(x) for x in example_batch["image"]]
    example_batch["label"] = [resize(x) for x in example_batch["annotation"]]
    return example_batch

>>> dataset.set_transform(train_transforms)

>>> image = np.array(dataset[index]["pixel_values"])
>>> mask = np.array(dataset[index]["label"])

>>> visualize_seg_mask(image, mask)
```

<div class="flex justify-center">
<img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/datasets/torchvision_seg.png">
</div>

<Tip>

الآن بعد أن عرفت كيفية معالجة مجموعة بيانات للتجزئة الدلالية، تعلم [كيفية تدريب نموذج تجزئة دلالية](https://huggingface.co/docs/transformers/tasks/semantic_segmentation) واستخدامه للاستدلال.

</Tip>