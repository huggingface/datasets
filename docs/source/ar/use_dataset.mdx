# ูุนุงูุฌุฉ ูุณุจูุฉ

ุจุงูุฅุถุงูุฉ ุฅูู ุชุญููู ูุฌููุนุงุช ุงูุจูุงูุงุชุ ูุชูุซู ุงููุฏู ุงูุฑุฆูุณู ุงูุขุฎุฑ ูู ๐ค Datasets ูู ุชูุฏูู ูุฌููุนุฉ ูุชููุนุฉ ูู ูุธุงุฆู ุงููุนุงูุฌุฉ ุงููุณุจูุฉ ูุชุญููู ูุฌููุนุฉ ุงูุจูุงูุงุช ุฅูู ุชูุณูู ููุงุณุจ ููุชุฏุฑูุจ ูุน ุฅุทุงุฑ ุนูู ุงูุชุนูู ุงูุขูู ุงูุฎุงุต ุจู.

ููุงู ุงูุนุฏูุฏ ูู ุงูุทุฑู ุงูููููุฉ ููุนุงูุฌุฉ ูุฌููุนุฉ ุงูุจูุงูุงุช ูุณุจููุงุ ููู ุฐูู ูุนุชูุฏ ุนูู ูุฌููุนุฉ ุงูุจูุงูุงุช ุงููุญุฏุฏุฉ ุงูุฎุงุตุฉ ุจู. ูู ุจุนุถ ุงูุฃุญูุงูุ ูุฏ ุชุญุชุงุฌ ุฅูู ุฅุนุงุฏุฉ ุชุณููุฉ ุนููุฏุ ููู ุฃุญูุงู ุฃุฎุฑูุ ูุฏ ุชุญุชุงุฌ ุฅูู ุฅูุบุงุก ุชุณุทูุญ ุงูุญููู ุงููุถููุฉ. ูููุฑ ๐ค Datasets ุทุฑููุฉ ููููุงู ุจูุนุธู ูุฐู ุงูุฃุดูุงุก. ูููู ูู ุฌููุน ุญุงูุงุช ุงููุนุงูุฌุฉ ุงููุณุจูุฉ ุชูุฑูุจูุงุ ุงุนุชูุงุฏูุง ุนูู ุทุฑููุฉ ูุฌููุนุฉ ุงูุจูุงูุงุช ุงูุฎุงุตุฉ ุจูุ ุณุชุญุชุงุฌ ุฅูู:

- ุฑููุฒ ูุตูุฉ ููุฌููุนุฉ ุจูุงูุงุช ูุตูุฉ.
- ุฅุนุงุฏุฉ ุฃุฎุฐ ุนููุงุช ูู ูุฌููุนุฉ ุจูุงูุงุช ุตูุชูุฉ.
- ุชุทุจูู ุชุญูููุงุช ุนูู ูุฌููุนุฉ ุจูุงูุงุช ุงูุตูุฑ.

ุชุชูุซู ุฎุทูุฉ ุงููุนุงูุฌุฉ ุงููุณุจูุฉ ุงูุฃุฎูุฑุฉ ุนุงุฏุฉู ูู ุชุนููู ุชูุณูู ูุฌููุนุฉ ุงูุจูุงูุงุช ุงูุฎุงุตุฉ ุจู ููููู ูุชูุงูููุง ูุน ุชูุณูู ุงูุฅุฏุฎุงู ุงููุชููุน ูุฅุทุงุฑ ุนูู ุงูุชุนูู ุงูุขูู ุงูุฎุงุต ุจู.

ูู ูุฐุง ุงูุจุฑูุงูุฌ ุงูุชุนููููุ ุณุชุญุชุงุฌ ุฃูุถูุง ุฅูู ุชุซุจูุช ููุชุจุฉ ๐ค Transformers:

```bash
pip install transformers
```

ุงุญุตู ุนูู ูุฌููุนุฉ ุจูุงูุงุช ูู ุงุฎุชูุงุฑู ูุงุชุจุน ุงูุชุนูููุงุช!

## ุฑููุฒ ูุตูุฉ

ูุง ูููู ููููุงุฐุฌ ูุนุงูุฌุฉ ุงููุต ุงูุฎุงูุ ูุฐูู ุณุชุญุชุงุฌ ุฅูู ุชุญููู ุงููุต ุฅูู ุฃุฑูุงู. ุชููุฑ ุนูููุฉ ุงูุฑูุฒูุฉ ุทุฑููุฉ ููููุงู ุจุฐูู ูู ุฎูุงู ุชูุณูู ุงููุต ุฅูู ูููุงุช ูุฑุฏูุฉ ุชุณูู *ุงูุฑููุฒ*. ูุชู ุชุญููู ุงูุฑููุฒ ูู ุงูููุงูุฉ ุฅูู ุฃุฑูุงู.

<Tip>

ุงุทูุน ุนูู ูุณู [ุงูุฑููุฒ](https://huggingface.co/course/chapter2/4ุfw=pt) ูู ุงููุตู 2 ูู ุฏูุฑุฉ Hugging Face ููุฒูุฏ ูู ุงููุนูููุงุช ุญูู ุงูุฑูุฒูุฉ ูุฎูุงุฑุฒููุงุช ุงูุฑูุฒูุฉ ุงููุฎุชููุฉ.

</Tip>

**1**. ุงุจุฏุฃ ุจุชุญููู ูุฌููุนุฉ ุจูุงูุงุช [rotten_tomatoes](https://huggingface.co/datasets/rotten_tomatoes) ููุญูู ุงูุฑููุฒ ุงูููุงุจู ููููุฐุฌ [BERT](https://huggingface.co/bert-base-uncased) ุงููุนูู ูุณุจููุง. ูู ุงูููู ุงุณุชุฎุฏุงู ููุณ ูุญูู ุงูุฑููุฒ ูุซู ุงููููุฐุฌ ุงููุนูู ูุณุจููุง ูุฃูู ุชุฑูุฏ ุงูุชุฃูุฏ ูู ุชูุณูู ุงููุต ุจููุณ ุงูุทุฑููุฉ.

```py
>>> from transformers import AutoTokenizer
>>> from datasets import load_dataset

>>> tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")
>>> dataset = load_dataset("rotten_tomatoes", split="train")
```

**2**. ูู ุจุงูุงุชุตุงู ุจูุญูู ุงูุฑููุฒ ุนูู ุงูุณุทุฑ ุงูุฃูู ูู `text` ูู ูุฌููุนุฉ ุงูุจูุงูุงุช:

```py
>>> tokenizer(dataset[0]["text"])
{'input_ids': [101, 1103, 2067, 1110, 17348, 1106, 1129, 1103, 6880, 1432, 112, 188, 1207, 107, 14255, 1389, 107, 1105, 1115, 1119, 112, 188, 1280, 1106, 1294, 170, 24194, 1256, 3407, 1190, 170, 11791, 5253, 188, 1732, 7200, 10947, 12606, 2895, 117, 179, 7766, 118, 172, 15554, 1181, 3498, 6961, 3263, 1137, 188, 1566, 7912, 14516, 6997, 119, 102],
'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
```

ูุนูุฏ ูุญูู ุงูุฑููุฒ ูุงููุณูุง ูุญุชูู ุนูู ุซูุงุซุฉ ุนูุงุตุฑ:

- `input_ids`: ุงูุฃุฑูุงู ุงูุชู ุชูุซู ุงูุฑููุฒ ูู ุงููุต.
- `token_type_ids`: ูุดูุฑ ุฅูู ุงูุชุณูุณู ุงูุฐู ููุชูู ุฅููู ุงูุฑูุฒ ุฅุฐุง ูุงู ููุงู ุฃูุซุฑ ูู ุชุณูุณู ูุงุญุฏ.
- `attention_mask`: ูุดูุฑ ุฅูู ูุง ุฅุฐุง ูุงู ูุฌุจ ุฅุฎูุงุก ุฑูุฒ ุฃู ูุง.

ูุฐู ุงูููู ูู ูู ุงููุงูุน ุฅุฏุฎุงูุงุช ุงููููุฐุฌ.

**3**. ุฃุณุฑุน ุทุฑููุฉ ูุฑููุฒ ูุฌููุนุฉ ุงูุจูุงูุงุช ุจุฃููููุง ูู ุงุณุชุฎุฏุงู ูุธููุฉ [`~ Dataset.map`] . ุชุณุฑุน ูุฐู ุงููุธููุฉ ุนูููุฉ ุงูุฑูุฒูุฉ ูู ุฎูุงู ุชุทุจูู ูุญูู ุงูุฑููุฒ ุนูู ุฏูุนุงุช ูู ุงูุฃูุซูุฉ ุจุฏูุงู ูู ุงูุฃูุซูุฉ ุงููุฑุฏูุฉ. ูู ุจุชุนููู ูุนููุฉ `batched` ุฅูู `True`:

```py
>>> def tokenization(example):
...     return tokenizer(example["text"])

>>> dataset = dataset.map(tokenization, batched=True)
```

**4**. ูู ุจุชุนููู ุชูุณูู ูุฌููุนุฉ ุงูุจูุงูุงุช ุงูุฎุงุตุฉ ุจู ููููู ูุชูุงูููุง ูุน ุฅุทุงุฑ ุนูู ุงูุชุนูู ุงูุขูู ุงูุฎุงุต ุจู:

<frameworkcontent>

<pt>

ุงุณุชุฎุฏู ูุธููุฉ [`~ Dataset.set_format`] ูุชุนููู ุชูุณูู ูุฌููุนุฉ ุงูุจูุงูุงุช ููููู ูุชูุงูููุง ูุน PyTorch:

```py
>>> dataset.set_format(type="torch", columns=["input_ids", "token_type_ids", "attention_mask", "label"])
>>> dataset.format['type']
'torch'
```

</pt>

<tf>

ุงุณุชุฎุฏู ูุธููุฉ [`~ Dataset.to_tf_dataset`] ูุชุนููู ุชูุณูู ูุฌููุนุฉ ุงูุจูุงูุงุช ููููู ูุชูุงูููุง ูุน TensorFlow. ุณุชุญุชุงุฌ ุฃูุถูุง ุฅูู ุงุณุชูุฑุงุฏ [collator ุงูุจูุงูุงุช](https://huggingface.co/docs/transformers/main_classes/data_collator#transformers.DataCollatorWithPadding) ูู ๐ค Transformers ูุฏูุฌ ุฃุทูุงู ุงูุชุณูุณูุงุช ุงููุชุบูุฑุฉ ูู ุฏูุนุฉ ูุงุญุฏุฉ ูู ุงูุฃุทูุงู ุงููุชุณุงููุฉ:

```py
>>> from transformers import DataCollatorWithPadding

>>> data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors="tf")
>>> tf_dataset = dataset.to_tf_dataset(
...     columns=["input_ids", "token_type_ids", "attention_mask"],
...     label_cols=["label"],
...     batch_size=2,
...     collate_fn=data_collator,
...     shuffle=True
... )
```

</tf>

</frameworkcontent>

**5**. ูุฌููุนุฉ ุงูุจูุงูุงุช ุฌุงูุฒุฉ ุงูุขู ููุชุฏุฑูุจ ุจุงุณุชุฎุฏุงู ุฅุทุงุฑ ุนูู ุงูุชุนูู ุงูุขูู ุงูุฎุงุต ุจู!

## ุฅุนุงุฏุฉ ุฃุฎุฐ ุนููุงุช ูู ุฅุดุงุฑุงุช ุงูุตูุช

ูุซู ูุฌููุนุงุช ุงูุจูุงูุงุช ุงููุตูุฉุ ุชุญุชุงุฌ ุฅุฏุฎุงูุงุช ุงูุตูุช ุฅูู ุชูุณูููุง ุฅูู ููุงุท ุจูุงูุงุช ูููุตูุฉ. ููุนุฑู ูุฐุง ุจุงุณู *ุงูุนููุงุช*ุ ููุนุฏู ุงูุนููุงุช ูุฎุจุฑู ุจูููุฉ ุฅุดุงุฑุฉ ุงูููุงู ุงูุชู ูุชู ุงูุชูุงุทูุง ูู ุงูุซุงููุฉ. ูู ุงูููู ุงูุชุฃูุฏ ูู ุฃู ูุนุฏู ุนููุงุช ูุฌููุนุฉ ุงูุจูุงูุงุช ุงูุฎุงุตุฉ ุจู ูุชุทุงุจู ูุน ูุนุฏู ุนููุงุช ุงูุจูุงูุงุช ุงููุณุชุฎุฏูุฉ ูุชุฏุฑูุจ ุงููููุฐุฌ ุงูุฐู ุชุณุชุฎุฏูู ูุณุจููุง. ุฅุฐุง ูุงูุช ูุนุฏูุงุช ุงูุนููุงุช ูุฎุชููุฉุ ููุฏ ูุคุฏู ุงููููุฐุฌ ุงููุนูู ูุณุจููุง ุฅูู ุฃุฏุงุก ุถุนูู ุนูู ูุฌููุนุฉ ุงูุจูุงูุงุช ุงูุฎุงุตุฉ ุจู ูุฃูู ูุง ูุชุนุฑู ุนูู ุงูุงุฎุชูุงูุงุช ูู ูุนุฏู ุงูุนููุงุช.

**1**. ุงุจุฏุฃ ุจุชุญููู ูุฌููุนุฉ ุจูุงูุงุช [MInDS-14](https://huggingface.co/datasets/PolyAI/minds14) ูููุฒุฉ [`Audio`] ููุณุชุฎุฑุฌ ุงูููุฒุงุช ุงูููุงุจู ููููุฐุฌ [Wav2Vec2](https://huggingface.co/facebook/wav2vec2-base-960h) ุงููุนูู ูุณุจููุง:

```py
>>> from transformers import AutoFeatureExtractor
>>> from datasets import load_dataset, Audio

>>> feature_extractor = AutoFeatureExtractor.from_pretrained("facebook/wav2vec2-base-960h")
>>> dataset = load_dataset("PolyAI/minds14", "en-US", split="train")
```

**2**. ูู ุจููุฑุณุฉ ุงูุณุทุฑ ุงูุฃูู ูู ูุฌููุนุฉ ุงูุจูุงูุงุช. ุนูุฏูุง ุชุณุชุฏุนู ุนููุฏ `audio` ูู ูุฌููุนุฉ ุงูุจูุงูุงุชุ ูุชู ูู ุชุฑููุฒู ูุฅุนุงุฏุฉ ุฃุฎุฐ ุนููุงุช ููู ุชููุงุฆููุง:

```py
>>> dataset[0]["audio"]
{'array': array([ 0.        ,  0.00024414, -0.00024414, ..., -0.00024414,
         0.        ,  0.        ], dtype=float32),
 'path': '/root/.cache/huggingface/datasets/downloads/extracted/f14948e0e84be638dd7943ac36518a4cf3324e8b7aa331c5ab11541518e9368c/en-US~JOINT_ACCOUNT/602ba55abb1e6d0fbce92065.wav',
 'sampling_rate': 8000}
```

**3**. ุฅู ูุฑุงุกุฉ ุจุทุงูุฉ ูุฌููุนุฉ ุงูุจูุงูุงุช ูููุฏุฉ ููุบุงูุฉ ููููู ุฃู ุชุนุทูู ุงููุซูุฑ ูู ุงููุนูููุงุช ุญูู ูุฌููุนุฉ ุงูุจูุงูุงุช. ูุธุฑุฉ ุณุฑูุนุฉ ุนูู ุจุทุงูุฉ ูุฌููุนุฉ ุจูุงูุงุช MInDS-14 ุชุฎุจุฑู ุจุฃู ูุนุฏู ุงูุนููุฉ ูู 8 ูููู ูุฑุชุฒ. ูุจุงููุซูุ ููููู ุงูุญุตูู ุนูู ุงูุนุฏูุฏ ูู ุงูุชูุงุตูู ุญูู ูููุฐุฌ ูู ุจุทุงูุฉ ุงููููุฐุฌ ุงูุฎุงุตุฉ ุจู. ุชููู ุจุทุงูุฉ ูููุฐุฌ Wav2Vec2 ุฅูู ุชู ุฃุฎุฐ ุนููุงุช ููู ุนูู ุตูุช 16 ูููู ูุฑุชุฒ. ููุฐุง ูุนูู ุฃูู ุณุชุญุชุงุฌ ุฅูู ุฒูุงุฏุฉ ุนููุงุช ูุฌููุนุฉ ุจูุงูุงุช MInDS-14 ููุทุงุจูุฉ ูุนุฏู ุนููุงุช ุงููููุฐุฌ.

ุงุณุชุฎุฏู ูุธููุฉ [`~ Dataset.cast_column`] ููู ุจุชุนููู ูุนููุฉ `sampling_rate` ูู ููุฒุฉ [`Audio`] ูุฒูุงุฏุฉ ุนููุงุช ุฅุดุงุฑุฉ ุงูุตูุช. ุนูุฏูุง ุชุณุชุฏุนู ุนููุฏ `audio` ุงูุขูุ ูุชู ูู ุชุดููุฑู ูุฅุนุงุฏุฉ ุฃุฎุฐ ุงูุนููุงุช ููู ุฅูู 16 ูููู ูุฑุชุฒ:

```py
>>> dataset = dataset.cast_column("audio", Audio(sampling_rate=16_000))
>>> dataset[0]["audio"]
{'array': array([ 2.3443763e-05,  2.1729663e-04,  2.2145823e-04, ...,
         3.8356509e-05, -7.3497440e-06, -2.1754686e-05], dtype=float32),
 'path': '/root/.cache/huggingface/datasets/downloads/extracted/f14948e0e84be638dd7943ac36518a4cf3324e8b7aa331c5ab11541518e9368c/en-US~JOINT_ACCOUNT/602ba55abb1e6d0fbce92065.wav',
 'sampling_rate': 16000}
```

**4**. ุงุณุชุฎุฏู ูุธููุฉ [`~ Dataset.map`] ูุฅุนุงุฏุฉ ุฃุฎุฐ ุนููุงุช ูู ูุฌููุนุฉ ุงูุจูุงูุงุช ุจุฃููููุง ุฅูู 16 ูููู ูุฑุชุฒ. ุชุณุฑุน ูุฐู ุงููุธููุฉ ุนูููุฉ ุฅุนุงุฏุฉ ุฃุฎุฐ ุงูุนููุงุช ูู ุฎูุงู ุชุทุจูู ูุณุชุฎุฑุฌ ุงูููุฒุงุช ุนูู ุฏูุนุงุช ูู ุงูุฃูุซูุฉ ุจุฏูุงู ูู ุงูุฃูุซูุฉ ุงููุฑุฏูุฉ. ูู ุจุชุนููู ูุนููุฉ `batched` ุฅูู `True`:

```py
>>> def preprocess_function(examples):
...     audio_arrays = [x["array"] for x in examples["audio"]]
...     inputs = feature_extractor(
...         audio_arrays, sampling_rate=feature_extractor.sampling_rate, max_length=16000, truncation=True
...     )
...     return inputs

>>> dataset = dataset.map(preprocess_function, batched=True)
```

**5**. ูุฌููุนุฉ ุงูุจูุงูุงุช ุฌุงูุฒุฉ ุงูุขู ููุชุฏุฑูุจ ุจุงุณุชุฎุฏุงู ุฅุทุงุฑ ุนูู ุงูุชุนูู ุงูุขูู ุงูุฎุงุต ุจู!

## ุชุทุจูู ุงูุชุนุฒูุฒุงุช ุงูุจูุงูุงุช

ุฃุดูุน ูุนุงูุฌุฉ ูุณุจูุฉ ุณุชููู ุจูุง ูุน ูุฌููุนุงุช ุจูุงูุงุช ุงูุตูุฑ ูู *ุชุนุฒูุฒ ุงูุจูุงูุงุช*ุ ููู ุนูููุฉ ุชููู ุจุฅุฏุฎุงู ุงุฎุชูุงูุงุช ุนุดูุงุฆูุฉ ุนูู ุตูุฑุฉ ุฏูู ุชุบููุฑ ูุนูู ุงูุจูุงูุงุช. ูุฏ ูุนูู ุฐูู ุชุบููุฑ ุฎุตุงุฆุต ุงูููู ูุตูุฑุฉ ุฃู ุงูุชุตุงุต ุตูุฑุฉ ุจุดูู ุนุดูุงุฆู. ุฃูุช ุญุฑ ูู ุงุณุชุฎุฏุงู ุฃู ููุชุจุฉ ูุชุนุฒูุฒ ุงูุจูุงูุงุช ุงูุชู ุชุฑูุฏูุงุ ูุณูุณุงุนุฏู ๐ค Datasets ูู ุชุทุจูู ุชุนุฒูุฒุงุช ุงูุจูุงูุงุช ุงูุฎุงุตุฉ ุจู ุนูู ูุฌููุนุฉ ุงูุจูุงูุงุช ุงูุฎุงุตุฉ ุจู.

**1**. ุงุจุฏุฃ ุจุชุญููู ูุฌููุนุฉ ุจูุงูุงุช [Beans](https://huggingface.co/datasets/beans) ูููุฒุฉ `Image` ููุณุชุฎุฑุฌ ุงูููุฒุงุช ุงูููุงุจู ููููุฐุฌ [ViT](https://huggingface.co/google/vit-base-patch16-224-in21k) ุงููุนูู ูุณุจููุง:

```py
>>> from transformers import AutoFeatureExtractor
>>> from datasets import load_dataset, Image

>>> feature_extractor = AutoFeatureExtractor.from_pretrained("google/vit-base-patch16-224-in21k")
>>> dataset = load_dataset("beans", split="train")
```

**2**. ูู ุจููุฑุณุฉ ุงูุณุทุฑ ุงูุฃูู ูู ูุฌููุนุฉ ุงูุจูุงูุงุช. ุนูุฏูุง ุชุณุชุฏุนู ุนููุฏ `image` ูู ูุฌููุนุฉ ุงูุจูุงูุงุชุ ูุชู ูู ุชุดููุฑ ูุงุฆู PIL ุงูุฃุณุงุณู ุชููุงุฆููุง ุฅูู ุตูุฑุฉ.

```py
>>> dataset[0]["image"]
<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at 0x7FE5A047CC70>
```

ุชุชููุน ูุนุธู ููุงุฐุฌ ุงูุตูุฑ ุฃู ุชููู ุงูุตูุฑุฉ ูู ูุถุน RGB. ุตูุฑ ุงููุงุตูููุง ูู ุจุงููุนู ูู ูุถุน RGBุ ูููู ุฅุฐุง ูุงูุช ูุฌููุนุฉ ุงูุจูุงูุงุช ุงูุฎุงุตุฉ ุจู ุชุญุชูู ุนูู ุตูุฑ ูู ูุถุน ูุฎุชููุ ูููููู ุงุณุชุฎุฏุงู ูุธููุฉ [`~ Dataset.cast_column`] ูุชุนููู ุงููุถุน ุฅูู RGB:

```py
>>> dataset = dataset.cast_column("image", Image(mode="RGB"))
```

**3**. ุงูุขูุ ููููู ุชุทุจูู ุจุนุถ ุงูุชุญูููุงุช ุนูู ุงูุตูุฑุฉ. ูุง ุชุชุฑุฏุฏ ูู ุฅููุงุก ูุธุฑุฉ ุนูู [ุงูุชุญูููุงุช ุงููุฎุชููุฉ ุงููุชุงุญุฉ](https://pytorch.org/vision/stable/auto_examples/plot_transforms.html#sphx-glr-auto-examples-plot-transforms-py) ูู torchvision ูุงุฎุชูุงุฑ ูุงุญุฏ ุชุฑูุฏ ุชุฌุฑุจุชู. ูุฐุง ุงููุซุงู ูุทุจู ุชุญููููุง ูููู ุจุชุฏููุฑ ุงูุตูุฑุฉ ุจุดูู ุนุดูุงุฆู:

```py
>>> from torchvision.transforms import RandomRotation

>>> rotate = RandomRotation(degrees=(0, 90))
>>> def transforms(examples):
...     examples["pixel_values"] = [rotate(image) for image in examples["image"]]
...     return examples
```

**4**. ุงุณุชุฎุฏู ูุธููุฉ [`~ Dataset.set_transform`] ูุชุทุจูู ุงูุชุญููู ุฃุซูุงุก ุงูุชููู. ุนูุฏูุง ุชููู ุจููุฑุณุฉ ููู ุจูุณู ุงูุตูุฑุฉุ ูุชู ุชุทุจูู ุงูุชุญูููุ ููุชู ุชุฏููุฑ ุตูุฑุชู.

```py
>>> dataset.set_transform(transforms)
>>> dataset[0]["pixel_values"]
```

**5**. ูุฌููุนุฉ ุงูุจูุงูุงุช ุฌุงูุฒุฉ ุงูุขู ููุชุฏุฑูุจ ุจุงุณุชุฎุฏุงู ุฅุทุงุฑ ุนูู ุงูุชุนูู ุงูุขูู ุงูุฎุงุต ุจู!