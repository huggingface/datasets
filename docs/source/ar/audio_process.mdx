# معالجة البيانات الصوتية

يُظهر هذا الدليل طرقًا محددة لمعالجة مجموعات البيانات الصوتية. تعلم كيفية:

- إعادة أخذ عينات من معدل العينات.
- استخدام [`~Dataset.map`] مع مجموعات البيانات الصوتية.

للحصول على دليل حول كيفية معالجة أي نوع من مجموعات البيانات، راجع <a class="underline decoration-sky-400 decoration-2 font-semibold" href="./process">دليل العملية العامة</a>.

## الصب

تُستخدم دالة [`~Dataset.cast_column`] لصب عمود إلى ميزة أخرى ليتم فك تشفيرها. عندما تستخدم هذه الدالة مع ميزة [`Audio`]`Audio`، يمكنك إعادة أخذ عينات من معدل العينات:

```py
>>> from datasets import load_dataset, Audio

>>> dataset = load_dataset("PolyAI/minds14", "en-US", split="train")
>>> dataset = dataset.cast_column("audio", Audio(sampling_rate=16000))
```

يتم فك تشفير ملفات الصوت وإعادة أخذ العينات أثناء التنقل، لذلك في المرة التالية التي تصل فيها إلى مثال، يتم إعادة أخذ عينات من ملف الصوت إلى 16 كيلو هرتز:

```py
>>> dataset[0]["audio"]
{'array': array([ 2.3443763e-05,  2.1729663e-04,  2.2145823e-04, ...,
3.8356509e-05, -7.3497440e-06, -2.1754686e-05], dtype=float32),
'path': '/root/.cache/huggingface/datasets/downloads/extracted/f14948e0e84be638dd7943ac36518a4cf3324e8b7aa331c5ab11541518e9368c/en-US~JOINT_ACCOUNT/602ba55abb1e6d0fbce92065.wav',
'sampling_rate': 16000}
```

<div class="flex justify-center">
<img class="block dark:hidden" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/datasets/resample.gif"/>
<img class="hidden dark:block" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/datasets/resample-dark.gif"/>
</div>

## خريطة

تساعد دالة [`~Dataset.map`] في معالجة مجموعة البيانات بأكملها مرة واحدة. اعتمادًا على نوع النموذج الذي تعمل عليه، ستحتاج إلى تحميل إما [مستخرج الميزات](https://huggingface.co/docs/transformers/model_doc/auto#transformers.AutoFeatureExtractor) أو [معالج](https://huggingface.co/docs/transformers/model_doc/auto#transformers.AutoProcessor).

- بالنسبة لنماذج التعرف على الكلام المُدربة مسبقًا، قم بتحميل مستخرج ميزات ومُعلم رموز ودمجهما في معالج:

```py
>>> from transformers import AutoTokenizer, AutoFeatureExtractor, AutoProcessor

>>> model_checkpoint = "facebook/wav2vec2-large-xlsr-53"
# بعد تحديد ملف vocab.json، يمكنك إنشاء كائن tokenizer:
>>> tokenizer = AutoTokenizer("./vocab.json", unk_token="[UNK]", pad_token="[PAD]", word_delimiter_token="|")
>>> feature_extractor = AutoFeatureExtractor.from_pretrained(model_checkpoint)
>>> processor = AutoProcessor.from_pretrained(feature_extractor=feature_extractor, tokenizer=tokenizer)
```

- بالنسبة لنماذج التعرف على الكلام الدقيقة، فأنت بحاجة فقط إلى تحميل معالج:

```py
>>> from transformers import AutoProcessor

>>> processor = AutoProcessor.from_pretrained("facebook/wav2vec2-base-960h")
```

عندما تستخدم [`~Dataset.map`] مع دالة المعالجة المسبقة، قم بتضمين عمود "الصوت" للتأكد من إعادة أخذ عينات بيانات الصوت بالفعل:

```py
>>> def prepare_dataset(batch):
...     audio = batch["audio"]
...     batch["input_values"] = processor(audio["array"], sampling_rate=audio["sampling_rate"]).input_values[0]
...     batch["input_length"] = len(batch["input_values"])
...     with processor.as_target_processor():
...         batch["labels"] = processor(batch["sentence"]).input_ids
...     return batch
>>> dataset = dataset.map(prepare_dataset, remove_columns=dataset.column_names)
```
