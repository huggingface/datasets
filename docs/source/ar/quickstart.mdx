# ุจุฏุงูุฉ ุณุฑูุนุฉ

[[open-in-colab]]

ูุฐู ุงูุจุฏุงูุฉ ุงูุณุฑูุนุฉ ูุฎุตุตุฉ ูููุทูุฑูู ุงูุฐูู ูุฑุบุจูู ูู ุงูุบูุต ูู ุงูุดูุฑุฉ ุงูุจุฑูุฌูุฉ ูุฑุคูุฉ ูุซุงู ุนูู ููููุฉ ุฏูุฌ ๐ค Datasets ูู ุณูุฑ ุนูู ุงูุชุฏุฑูุจ ุนูู ุงูููุงุฐุฌ. ุฅุฐุง ููุช ูุจุชุฏุฆูุงุ ููุตู ุจุงูุจุฏุก ูุน [ุงูุจุฑุงูุฌ ุงูุชุนููููุฉ](./tutorial)ุ ุญูุซ ุณุชุชุนุฑู ุนูู ููุฏูุฉ ุฃูุซุฑ ุดูููุงู.

ูุนุฏ ูู ูุฌููุนุฉ ุจูุงูุงุช ูุฑูุฏุฉ ูู ููุนูุงุ ูุงุนุชูุงุฏูุง ุนูู ุงููููุฉุ ูุฏ ุชุชุทูุจ ุจุนุถ ูุฌููุนุงุช ุงูุจูุงูุงุช ุฎุทูุงุช ุฅุถุงููุฉ ูุฅุนุฏุงุฏูุง ููุชุฏุฑูุจ. ูููู ููููู ุฏุงุฆููุง ุงุณุชุฎุฏุงู ุฃุฏูุงุช ๐ค Datasets ูุชุญููู ููุนุงูุฌุฉ ูุฌููุนุฉ ุงูุจูุงูุงุช. ุฃุณุฑุน ูุฃุณูู ุทุฑููุฉ ููุจุฏุก ูู ุชุญููู ูุฌููุนุฉ ุจูุงูุงุช ููุฌูุฏุฉ ูู [Hugging Face Hub](https://huggingface.co/datasets). ููุงู ุงูุขูุงู ูู ูุฌููุนุงุช ุงูุจูุงูุงุช ููุงุฎุชูุงุฑ ูู ุจูููุงุ ูุงูุชู ุชุบุทู ุงูุนุฏูุฏ ูู ุงูููุงู. ุงุฎุชุฑ ููุน ูุฌููุนุฉ ุงูุจูุงูุงุช ุงูุชู ุชุฑูุฏ ุงูุนูู ุจูุงุ ูููุจุฏุฃ!

<div class="mt-4">
<div class="w-full flex flex-col space-y-4 md:space-y-0 md:grid md:grid-cols-3 md:gap-y-4 md:gap-x-5">
<a class="!no-underline border dark:border-gray-700 p-5 rounded-lg shadow hover:shadow-lg" href="#audio"
><div class="w-full text-center bg-gradient-to-r from-violet-300 via-sky-400 to-green-500 rounded-lg py-1.5 font-semibold mb-5 text-white text-lg leading-relaxed">ุงูุตูุช</div>
<p class="text-gray-700">ุฃุนุฏ ุฃุฎุฐ ุนููุงุช ูู ูุฌููุนุฉ ุจูุงูุงุช ุตูุชูุฉ ูุฌุนููุง ุฌุงูุฒุฉ ููููุฐุฌ ูุชุตููู ููุน ุงููุดููุฉ ุงููุตุฑููุฉ ุงูุชู ูุชุตู ุจูุง ุงููุชุญุฏุซ.</p>
</a>
<a class="!no-underline border dark:border-gray-700 p-5 rounded-lg shadow hover:shadow-lg" href="#vision"
><div class="w-full text-center bg-gradient-to-r from-pink-400 via-purple-400 to-blue-500 rounded-lg py-1.5 font-semibold mb-5 text-white text-lg leading-relaxed">ุงูุฑุคูุฉ</div>
<p class="text-gray-700">ุชุทุจูู ุฒูุงุฏุฉ ุงูุจูุงูุงุช ุนูู ูุฌููุนุฉ ุจูุงูุงุช ุตูุฑุฉ ูุฌุนููุง ุฌุงูุฒุฉ ููููุฐุฌ ูุชุดุฎูุต ุงููุฑุถ ูู ูุจุงุชุงุช ุงููุงุตูููุง.</p>
</a>
<a class="!no-underline border dark:border-gray-700 p-5 rounded-lg shadow hover:shadow-lg" href="#nlp"
><div class="w-full text-center bg-gradient-to-r from-orange-300 via-red-400 to-violet-500 rounded-lg py-1.5 font-semibold mb-5 text-white text-lg leading-relaxed">NLP</div>
<p class="text-gray-700">ูู ุจุฑูุฒูุฉ ูุฌููุนุฉ ุจูุงูุงุช ูุชุญุถูุฑูุง ููููุฐุฌ ูุชุญุฏูุฏ ูุง ุฅุฐุง ูุงู ุฒูุฌ ูู ุงูุฌูู ูููุง ููุณ ุงููุนูู.</p>
</a>
</div>
</div>

<Tip>

ุงุทูุน ุนูู [ุงููุตู 5](https://huggingface.co/course/chapter5/1ุfw=pt) ูู ุฏูุฑุฉ Hugging Face ููุชุนุฑู ุนูู ุงููุฒูุฏ ูู ุงูููุถูุนุงุช ุงููููุฉ ูุซู ุชุญููู ูุฌููุนุงุช ุงูุจูุงูุงุช ุงูุจุนูุฏุฉ ุฃู ุงููุญููุฉุ ูุฃุฏูุงุช ูุชูุธูู ูุฌููุนุฉ ุจูุงูุงุชุ ูุฅูุดุงุก ูุฌููุนุฉ ุงูุจูุงูุงุช ุงูุฎุงุตุฉ ุจู.

</Tip>

ุงุจุฏุฃ ุจุชุซุจูุช ๐ค Datasets:

```bash
pip install datasets
```

๐ค Datasets ุชุฏุนู ุฃูุถูุง ุชูุณููุงุช ุงูุจูุงูุงุช ุงูุตูุชูุฉ ูุงูุตูุฑ:

* ููุนูู ูุน ูุฌููุนุงุช ุงูุจูุงูุงุช ุงูุตูุชูุฉุ ูู ุจุชุซุจูุช ููุฒุฉ [`Audio`]:

```bash
pip install datasets[audio]
```

* ููุนูู ูุน ูุฌููุนุงุช ุงูุจูุงูุงุช ุงูุตูุฑูุฉุ ูู ุจุชุซุจูุช ููุฒุฉ [`Image`]:

```bash
pip install datasets[vision]
```

ุจุงูุฅุถุงูุฉ ุฅูู ๐ค Datasetsุ ุชุฃูุฏ ูู ุชุซุจูุช ุฅุทุงุฑ ุนูู ุงูุชุนูู ุงูุขูู ุงูููุถู ูุฏูู:

<frameworkcontent>
<pt>

```bash
pip install torch
```

</pt>
<tf>

```bash
pip install tensorflow
```

</tf>
</frameworkcontent>

## ุงูุตูุช

ูุชู ุชุญููู ูุฌููุนุงุช ุงูุจูุงูุงุช ุงูุตูุชูุฉ ุชูุงููุง ูุซู ูุฌููุนุงุช ุงูุจูุงูุงุช ุงููุตูุฉ. ููุน ุฐููุ ูุชู ูุนุงูุฌุฉ ูุฌููุนุฉ ุงูุจูุงูุงุช ุงูุตูุชูุฉ ุจุดูู ูุฎุชูู ููููุงู. ุจุฏูุงู ูู ุฃุฏุงุฉ ุงูุชุนุฑู ุนูู ุงูููุงูุงุช ุงููุณูุงุฉุ ุณุชุญุชุงุฌ ุฅูู [ูุณุชุฎุฑุฌ ุงูููุฒุงุช](https://huggingface.co/docs/transformers/main_classes/feature_extractor#feature-extractor). ูุฏ ูุชุทูุจ ุฅุฏุฎุงู ุงูุตูุช ุฃูุถูุง ุฅุนุงุฏุฉ ุฃุฎุฐ ุนููุงุช ูู ูุนุฏู ุงูุนููุงุช ุงูุฎุงุต ุจู ููุทุงุจูุฉ ูุนุฏู ุนููุงุช ุงููููุฐุฌ ุงููุณุจู ุงูุชุฏุฑูุจ ุงูุฐู ุชุณุชุฎุฏูู. ูู ูุฐู ุงูุจุฏุงูุฉ ุงูุณุฑูุนุฉุ ุณุชุนุฏ ูุฌููุนุฉ ุจูุงูุงุช [MInDS-14](https://huggingface.co/datasets/PolyAI/minds14) ูุชุฏุฑูุจ ูููุฐุฌ ุนูู ุชุตููู ุงููุดููุฉ ุงููุตุฑููุฉ ุงูุชู ููุงุฌููุง ุงูุนููู.

**1**. ูู ุจุชุญููู ูุฌููุนุฉ ุจูุงูุงุช MInDS-14 ุนู ุทุฑูู ุชุฒููุฏ ุงูุฏุงูุฉ [`load_dataset`] ุจุงุณู ูุฌููุนุฉ ุงูุจูุงูุงุชุ ูุชูููู ูุฌููุนุฉ ุงูุจูุงูุงุช (ูุง ุชุญุชูู ุฌููุน ูุฌููุนุงุช ุงูุจูุงูุงุช ุนูู ุชูููู)ุ ูุงููุณุงู ูุฌููุนุฉ ุงูุจูุงูุงุช:

```py
>>> from datasets import load_dataset, Audio

>>> dataset = load_dataset("PolyAI/minds14", "en-US", split="train")
```

**2**. ุจุนุฏ ุฐููุ ูู ุจุชุญููู ูููุฐุฌ Wav2Vec2 ูุณุจู ุงูุชุฏุฑูุจ ููุณุชุฎุฑุฌ ุงูููุฒุงุช ุงูููุงุจู ูู ูู ููุชุจุฉ [๐ค Transformers](https://huggingface.co/transformers/). ูู ุงูุทุจูุนู ุชูุงููุง ุฃู ุชุฑู ุชุญุฐูุฑูุง ุจุนุฏ ุชุญููู ุงููููุฐุฌ ุญูู ุจุนุถ ุงูุฃูุฒุงู ุงูุชู ูู ูุชู ุชููุฆุชูุง. ูุฐุง ูุชููุน ูุฃูู ุชููู ุจุชุญููู ููุทุฉ ุชูุชูุด ูุฐุง ุงููููุฐุฌ ููุชุฏุฑูุจ ูุน ูููุฉ ุฃุฎุฑู.

```py
>>> from transformers import AutoModelForAudioClassification, AutoFeatureExtractor

>>> model = AutoModelForAudioClassification.from_pretrained("facebook/wav2vec2-base")
>>> feature_extractor = AutoFeatureExtractor.from_pretrained("facebook/wav2vec2-base")
```

**3**. ุชุดูุฑ ุจุทุงูุฉ ูุฌููุนุฉ ุจูุงูุงุช [MInDS-14](https://huggingface.co/datasets/PolyAI/minds14) ุฅูู ุฃู ูุนุฏู ุงูุนููุงุช ูุจูุบ 8 ูููู ูุฑุชุฒุ ูููู ุชู ุชุฏุฑูุจ ูููุฐุฌ Wav2Vec2 ูุณุจููุง ุนูู ูุนุฏู ุนููุงุช ูุจูุบ 16 ูููู ูุฑุชุฒ. ุณุชุญุชุงุฌ ุฅูู ุฅุนุงุฏุฉ ุฃุฎุฐ ุนููุงุช ูู ุนููุฏ "ุงูุตูุช" ุจุงุณุชุฎุฏุงู ุฏุงูุฉ [`~Dataset.cast_column`] ูููุฒุฉ [`Audio`] ููุทุงุจูุฉ ูุนุฏู ุนููุงุช ุงููููุฐุฌ.

```py
>>> dataset = dataset.cast_column("audio", Audio(sampling_rate=16000))
>>> dataset[0]["audio"]
{'array': array([ 2.3443763e-05,  2.1729663e-04,  2.2145823e-04, ...,
3.8356509e-05, -7.3497440e-06, -2.1754686e-05], dtype=float32),
'path': '/root/.cache/huggingface/datasets/downloads/extracted/f14948e0e84be638dd7943ac36518a4cf3324e8b7aa331c5ab11541518e9368c/en-US~JOINT_ACCOUNT/602ba55abb1e6d0fbce92065.wav',
'sampling_rate': 16000}
```

**4**. ูู ุจุฅูุดุงุก ุฏุงูุฉ ููุนุงูุฌุฉ ูุตูููุฉ ุงูุตูุช ุจุงุณุชุฎุฏุงู ูุณุชุฎุฑุฌ ุงูููุฒุงุชุ ููุต ูุชูุณูุฏ ุงูุชุณูุณูุงุช ุฅูู ูุตูููุงุช ูุณุชุทููุฉ ูุฑุชุจุฉ. ุฃูู ุดูุก ูุฌุจ ุชุฐูุฑู ูู ุงุณุชุฏุนุงุก ูุตูููุฉ ุงูุตูุช ูู ูุณุชุฎุฑุฌ ุงูููุฒุงุช ูุฃู ุงููุตูููุฉ - ุฅุดุงุฑุฉ ุงูููุงู ุงููุนููุฉ - ูู ุฅุฏุฎุงู ุงููููุฐุฌ.

ุจูุฌุฑุฏ ุฃู ูููู ูุฏูู ุฏุงูุฉ ูุนุงูุฌุฉุ ุงุณุชุฎุฏู ุฏุงูุฉ [`~Dataset.map`] ูุชุณุฑูุน ุงููุนุงูุฌุฉ ุนู ุทุฑูู ุชุทุจูู ุงูุฏุงูุฉ ุนูู ุฏูุนุงุช ูู ุงูุฃูุซูุฉ ูู ูุฌููุนุฉ ุงูุจูุงูุงุช.

```py
>>> def preprocess_function(examples):
...     audio_arrays = [x["array"] for x in examples["audio"]]
...     inputs = feature_extractor(
...         audio_arrays,
...         sampling_rate=16000,
...         padding=True,
...         max_length=100000,
...         truncation=True,
...     )
...     return inputs

>>> dataset = dataset.map(preprocess_function, batched=True)
```

**5**. ุงุณุชุฎุฏู ุฏุงูุฉ [`~Dataset.rename_column`] ูุฅุนุงุฏุฉ ุชุณููุฉ ุนููุฏ "intent_class" ุฅูู "labels"ุ ููู ุงุณู ุงูุฅุฏุฎุงู ุงููุชููุน ูู [Wav2Vec2ForSequenceClassification](https://huggingface.co/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification):

```py
>>> dataset = dataset.rename_column("intent_class", "labels")
```

**6**. ูู ุจุชุนููู ุชูุณูู ูุฌููุนุฉ ุงูุจูุงูุงุช ููููุง ูุฅุทุงุฑ ุนูู ุงูุชุนูู ุงูุขูู ุงูุฐู ุชุณุชุฎุฏูู.

<frameworkcontent>
<pt>

ุงุณุชุฎุฏู ุฏุงูุฉ [`~Dataset.set_format`] ูุชุนููู ุชูุณูู ูุฌููุนุฉ ุงูุจูุงูุงุช ุฅูู "torch" ูุญุฏุฏ ุงูุฃุนูุฏุฉ ุงูุชู ุชุฑูุฏ ุชูุณูููุง. ุชุทุจู ูุฐู ุงูุฏุงูุฉ ุงูุชูุณูู ุฃุซูุงุก ุงูุชููู. ุจุนุฏ ุชุญููููุง ุฅูู ูุตูููุงุช PyTorchุ ูู ุจูู ูุฌููุนุฉ ุงูุจูุงูุงุช ูู [`torch.utils.data.DataLoader`](https://alband.github.io/doc_view/data.htmlุhighlight=torch%20utils%20data%20dataloader#torch.utils.data.DataLoader):

```py
>>> from torch.utils.data import DataLoader

>>> dataset.set_format(type="torch", columns=["input_values", "labels"])
>>> dataloader = DataLoader(dataset, batch_size=4)
```

</pt>
<tf>

ุงุณุชุฎุฏู ุทุฑููุฉ [`~transformers.TFPreTrainedModel.prepare_tf_dataset`] ูู ๐ค Transformers ูุฅุนุฏุงุฏ ูุฌููุนุฉ ุงูุจูุงูุงุช ูุชููู ูุชูุงููุฉ ูุน TensorFlowุ ูุฌุงูุฒุฉ ูุชุฏุฑูุจ/ุถุจุท ูููุฐุฌุ ุญูุซ ุชููู ุจุชุบููู ูุฌููุนุฉ ุจูุงูุงุช HuggingFace [`~datasets.Dataset`] ูู `tf.data.Dataset`

ูุน ุงูุฌูุน ูุงูุชุดุบููุ ุญุชู ุชุชููู ูู ุชูุฑูุฑู ูุจุงุดุฑุฉ ุฅูู ุฃุณุงููุจ Keras ูุซู `fit()` ุฏูู ุชุนุฏูู ุขุฎุฑ.

```py
>>> import tensorflow as tf

>>> tf_dataset = model.prepare_tf_dataset(
...     dataset,
...     batch_size=4,
...     shuffle=True,
... )
```

</tf>
</frameworkcontent>

**7**. ุงุจุฏุฃ ุงูุชุฏุฑูุจ ุจุงุณุชุฎุฏุงู ุฅุทุงุฑ ุนูู ุงูุชุนูู ุงูุขูู ุงูุฎุงุต ุจู! ุงุทูุน ุนูู ุฏููู ุชุตููู ุงูุตูุช ูู ๐ค Transformers ููุญุตูู ุนูู ูุซุงู ุดุงูู ุญูู ููููุฉ ุชุฏุฑูุจ ูููุฐุฌ ุนูู ูุฌููุนุฉ ุจูุงูุงุช ุตูุชูุฉ.

## ุงูุฑุคูุฉ

ูุชู ุชุญููู ูุฌููุนุงุช ุงูุจูุงูุงุช ุงูุตูุฑูุฉ ุชูุงููุง ูุซู ูุฌููุนุงุช ุงูุจูุงูุงุช ุงููุตูุฉ. ููุน ุฐููุ ุจุฏูุงู ูู ุฃุฏุงุฉ ุงูุชุนุฑู ุนูู ุงูููุงูุงุช ุงููุณูุงุฉุ ุณุชุญุชุงุฌ ุฅูู [ูุณุชุฎุฑุฌ ุงูููุฒุงุช](https://huggingface.co/docs/transformers/main_classes/feature_extractor#feature-extractor) ููุนุงูุฌุฉ ูุฌููุนุฉ ุงูุจูุงูุงุช. ูุนุฏ ุชุทุจูู ุฒูุงุฏุฉ ุงูุจูุงูุงุช ุนูู ุตูุฑุฉ ุฃูุฑูุง ุดุงุฆุนูุง ูู ุฑุคูุฉ ุงูููุจููุชุฑ ูุฌุนู ุงููููุฐุฌ ุฃูุซุฑ ููุฉ ุถุฏ ุงูุฅูุฑุงุท ูู ุงูุชุฎุตูุต. ููููู ุงุณุชุฎุฏุงู ุฃู ููุชุจุฉ ูุฒูุงุฏุฉ ุงูุจูุงูุงุช ุชุฑูุฏูุงุ ุซู ููููู ุชุทุจูู ุงูุฒูุงุฏุงุช ุจุงุณุชุฎุฏุงู ๐ค Datasets. ูู ูุฐู ุงูุจุฏุงูุฉ ุงูุณุฑูุนุฉุ ุณุชููู ุจุชุญููู ูุฌููุนุฉ ุจูุงูุงุช [Beans](https://huggingface.co/datasets/beans) ูุฌุนููุง ุฌุงูุฒุฉ ูููููุฐุฌ ูุชุฏุฑูุจ ูุชุญุฏูุฏ ุงููุฑุถ ูู ุตูุฑ ุงูุฃูุฑุงู.

**1**. ูู ุจุชุญููู ูุฌููุนุฉ ุจูุงูุงุช Beans ุนู ุทุฑูู ุชุฒููุฏ ุฏุงูุฉ [`load_dataset`] ุจุงุณู ูุฌููุนุฉ ุงูุจูุงูุงุช ูุงููุณุงู ูุฌููุนุฉ ุงูุจูุงูุงุช:

```py
>>> from datasets import load_dataset, Image

>>> dataset = load_dataset("beans", split="train")
```

ุชุนูู ูุนุธู ููุงุฐุฌ ุงูุตูุฑ ูุน ุตูุฑ RGB. ุฅุฐุง ูุงูุช ูุฌููุนุฉ ุงูุจูุงูุงุช ุงูุฎุงุตุฉ ุจู ุชุญุชูู ุนูู ุตูุฑ ูู ูุถุน ูุฎุชููุ ูููููู ุงุณุชุฎุฏุงู ุฏุงูุฉ [`~Dataset.cast_column`] ูุชุนููู ุงููุถุน ุฅูู RGB:

```py
>>> dataset = dataset.cast_column("image", Image(mode="RGB"))
```

ุชุญุชูู ูุฌููุนุฉ ุจูุงูุงุช Beans ุนูู ุตูุฑ RGB ููุทุ ูุฐุง ูุฅู ูุฐู ุงูุฎุทูุฉ ุบูุฑ ุถุฑูุฑูุฉ ููุง.

**2**. ุงูุขู ููููู ุฅุถุงูุฉ ุจุนุถ ุงูุฒูุงุฏุงุช ุจุงุณุชุฎุฏุงู ุฃู ููุชุจุฉ ([Albumentations](https://albumentations.ai/)ุ [imgaug](https://imgaug.readthedocs.io/en/latest/)ุ [Kornia](https://kornia.readthedocs.io/en/latest/)) ุงูุชู ุชุฑูุฏูุง. ููุงุ ุณุชุณุชุฎุฏู [torchvision](https://pytorch.org/vision/stable/transforms.html) ูุชุบููุฑ ุฎุตุงุฆุต ุงูููู ูู ุงูุตูุฑุฉ ุจุดูู ุนุดูุงุฆู:

```py
>>> from torchvision.transforms import Compose, ColorJitter, ToTensor

>>> jitter = Compose(
...     [ColorJitter(brightness=0.5, hue=0.5), ToTensor()]
... )
```

**3**. ูู ุจุฅูุดุงุก ุฏุงูุฉ ูุชุทุจูู ุชุญูููู ุนูู ูุฌููุนุฉ ุงูุจูุงูุงุช ูุชูููุฏ ุฅุฏุฎุงู ุงููููุฐุฌ: `pixel_values`.

```python
>>> def transforms(examples):
...     examples["pixel_values"] = [jitter(image.convert("RGB")) for image in examples["image"]]
...     return examples
```

**4**. ุงุณุชุฎุฏู ุฏุงูุฉ [`~Dataset.with_transform`] ูุชุทุจูู ุงูุฒูุงุฏุงุช ุฃุซูุงุก ุงูุชููู:

```py
>>> dataset = dataset.with_transform(transforms)
```

**5**. ูู ุจุชุนููู ุชูุณูู ูุฌููุนุฉ ุงูุจูุงูุงุช ููููุง ูุฅุทุงุฑ ุนูู ุงูุชุนูู ุงูุขูู ุงูุฐู ุชุณุชุฎุฏูู.

<frameworkcontent>
<pt>

ูู ุจุชุบููู ูุฌููุนุฉ ุงูุจูุงูุงุช ูู [`torch.utils.data.DataLoader`](https://alband.github.io/doc_view/data.htmlุhighlight=torch%20utils%20data%20dataloader#torch.utils.data.DataLoader). ุณุชุญุชุงุฌ ุฃูุถูุง ุฅูู ุฅูุดุงุก ุฏุงูุฉ ุชุฌููุน ูุชุฌููุน ุงูุนููุงุช ูู ุฏูุนุงุช:

```py
>>> from torch.utils.data import DataLoader

>>> def collate_fn(examples):
...     images = []
...     labels = []
...     for example in examples:
...         images.append((example["pixel_values"]))
...         labels.append(example["labels"])
...
...     pixel_values = torch.stack(images)
...     labels = torch.tensor(labels)
...     return {"pixel_values": pixel_values, "labels": labels}
>>> dataloader = DataLoader(dataset, collate_fn=collate_fn, batch_size=4)
```

</pt>
<tf>

ุงุณุชุฎุฏู ุทุฑููุฉ [`~transformers.TFPreTrainedModel.prepare_tf_dataset`] ูู ๐ค Transformers ูุฅุนุฏุงุฏ ูุฌููุนุฉ ุงูุจูุงูุงุช ูุชููู ูุชูุงููุฉ ูุน TensorFlowุ ูุฌุงูุฒุฉ ูุชุฏุฑูุจ/ุถุจุท ูููุฐุฌุ ุญูุซ ุชููู ุจุชุบููู ูุฌููุนุฉ ุจูุงูุงุช HuggingFace [`~datasets.Dataset`] ูู `tf.data.Dataset`

ูุน ุงูุฌูุน ูุงูุชุดุบููุ ุญุชู ุชุชููู ูู ุชูุฑูุฑู ูุจุงุดุฑุฉ ุฅูู ุฃุณุงููุจ Keras ูุซู `fit()` ุฏูู ุชุนุฏูู ุขุฎุฑ.

ูุจู ุงูุจุฏุกุ ุชุฃูุฏ ูู ุชุซุจูุช ุงูุฅุตุฏุงุฑุงุช ุงูุฃุญุฏุซ ูู `albumentations` ู`cv2`:

```bash
pip install -U albumentations opencv-python
```

```py
>>> import albumentations
>>> import numpy as np

>>> transform = albumentations.Compose([
...     albumentations.RandomCrop(width=256, height=256)ุ
...     albumentations.HorizontalFlip(p=0.5)ุ
...     albumentุงุกุงุช RandomBrightnessContrast (p=0.2)ุ
... ])

>>> def transforms(examples):
...     examples["pixel_values"] = [
...         transform(image=np.array(image))["image"] for image in examples["image"]
...     ]
...     return examples

>>> dataset.set_transform(transforms)
>>> tf_dataset = model.prepare_tf_dataset(
...     dataset,
...     batch_size=4,
...     shuffle=True,
... )
```

</tf>
</frameworkcontent>

**6**. ุงุจุฏุฃ ุงูุชุฏุฑูุจ ุจุงุณุชุฎุฏุงู ุฅุทุงุฑ ุนูู ุงูุชุนูู ุงูุขูู ุงูุฎุงุต ุจู! ุงุทูุน ุนูู ุฏููู ุชุตููู ุงูุตูุฑ ูู ๐ค Transformers ููุญุตูู ุนูู ูุซุงู ุดุงูู ุญูู ููููุฉ ุชุฏุฑูุจ ูููุฐุฌ ุนูู ูุฌููุนุฉ ุจูุงูุงุช ุตูุฑูุฉ.
## NLP

ูุฌุจ ุชููููุฒ ุงููุต ุฅูู ุฑููุฒ ูุฑุฏูุฉ ุจูุงุณุทุฉ [ุชูููููุฒุฑ](https://huggingface.co/docs/transformers/main_classes/tokenizer). ุจุงููุณุจุฉ ููุจุฏุก ุงูุณุฑูุนุ ุณุชููู ุจุชุญููู ูุฌููุนุฉ ุจูุงูุงุช ุงูุชุฏุฑูุจ [Microsoft Research Paraphrase Corpus (MRPC)](https://huggingface.co/datasets/glue/viewer/mrpc) ูุชุฏุฑูุจ ูููุฐุฌ ูุชุญุฏูุฏ ูุง ุฅุฐุง ูุงู ุฒูุฌ ูู ุงูุฌูู ูุนูู ููุณ ุงูุดูุก.

**1**. ูู ุจุชุญููู ูุฌููุนุฉ ุจูุงูุงุช MRPC ุนู ุทุฑูู ุชุฒููุฏ ุงูุฏุงูุฉ [`load_dataset`] ุจุงุณู ูุฌููุนุฉ ุงูุจูุงูุงุชุ ูุชูููู ูุฌููุนุฉ ุงูุจูุงูุงุช (ููุณ ุฌููุน ูุฌููุนุงุช ุงูุจูุงูุงุช ุณูููู ููุง ุชูููู)ุ ูุชูุณูู ูุฌููุนุฉ ุงูุจูุงูุงุช:

```py
>>> from datasets import load_dataset

>>> dataset = load_dataset("glue", "mrpc", split="train")
```

**2**. ุจุนุฏ ุฐููุ ูู ุจุชุญููู ูููุฐุฌ BERT ูุณุจู ุงูุชุฏุฑูุจ ู tokenizer ุงูููุงุจู ูู ููุชุจุฉ [๐ค Transformers](https://huggingface.co/transformers/). ูู ุงูุทุจูุนู ุชูุงููุง ุฃู ุชุฑู ุชุญุฐูุฑูุง ุจุนุฏ ุชุญููู ุงููููุฐุฌ ุญูู ุจุนุถ ุงูุฃูุฒุงู ุงูุชู ูู ูุชู ุชููุฆุชูุง. ูุฐุง ูุชููุน ูุฃูู ุชููู ุจุชุญููู ููุทุฉ ุชูุชูุด ูุฐุง ุงููููุฐุฌ ููุชุฏุฑูุจ ูุน ูููุฉ ุฃุฎุฑู.

```py
>>> from transformers import AutoModelForSequenceClassification, AutoTokenizer

>>> model = AutoModelForSequenceClassification.from_pretrained("bert-base-uncased")
>>> tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")
===PT-TF-SPLIT===
>>> from transformers import TFAutoModelForSequenceClassification, AutoTokenizer

>>> model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-uncased")
>>> tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")
```

**3**. ูู ุจุฅูุดุงุก ุฏุงูุฉ ูุชููููุฒ ูุฌููุนุฉ ุงูุจูุงูุงุชุ ููุฌุจ ุฃูุถูุง ุชูููู ูุณุงุฏุฉ ุงููุต ูู ุงูููุณูุฌุงุช ุงููุณุชุทููุฉ ุงูุฃูููุฉ. ูููู tokenizer ุจุฅูุดุงุก ุซูุงุซุฉ ุฃุนูุฏุฉ ุฌุฏูุฏุฉ ูู ูุฌููุนุฉ ุงูุจูุงูุงุช: `input_ids`ุ ู`token_type_ids`ุ ู`attention_mask`. ูุฐู ูู ูุฏุฎูุงุช ุงููููุฐุฌ.

ุงุณุชุฎุฏู ูุธููุฉ [`~Dataset.map`] ูุชุณุฑูุน ุงููุนุงูุฌุฉ ุนู ุทุฑูู ุชุทุจูู ุฏุงูุฉ tokenization ุนูู ุฏูุนุงุช ูู ุงูุฃูุซูุฉ ูู ูุฌููุนุฉ ุงูุจูุงูุงุช:

```py
>>> def encode(examples):
...     return tokenizer(examples["sentence1"], examples["sentence2"], truncation=True, padding="max_length")

>>> dataset = dataset.map(encode, batched=True)
>>> dataset[0]
{'sentence1': 'Amrozi accused his brother , whom he called " the witness " , of deliberately distorting his evidence .',
'sentence2': 'Referring to him as only " the witness " , Amrozi accused his brother of deliberately distorting his evidence .',
'label': 1,
'idx': 0,
'input_ids': array([  101,  7277,  2180,  5303,  4806,  1117,  1711,   117,  2292, 1119,  1270,   107,  1103,  7737,   107,   117,  1104,  9938, 4267, 12223, 21811,  1117,  2554,   119,   102, 11336,  6732, 3384,  1106,  1140,  1112,  1178,   107,  1103,  7737,   107, 117,  7277,  2180,  5303,  4806,  1117,  1711,  1104,  9938, 4267, 12223, 21811,  1117,  2554,   119,   102]),
'token_type_ids': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),
'attention_mask': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}
```

**4**. ุฃุนูุฏ ุชุณููุฉ ุนููุฏ `label` ุฅูู `labels`ุ ููู ุงุณู ุงูุฅุฏุฎุงู ุงููุชููุน ูู [BertForSequenceClassification](https://huggingface.co/docs/transformers/main/en/model_doc/bert#transformers.BertForSequenceClassification):

```py
>>> dataset = dataset.map(lambda examples: {"labels": examples["label"]}, batched=True)
```

**5**. ูู ุจุชุนููู ุชูุณูู ูุฌููุนุฉ ุงูุจูุงูุงุช ููููุง ูุฅุทุงุฑ ุนูู ุงูุชุนูู ุงูุขูู ุงูุฐู ุชุณุชุฎุฏูู.

<frameworkcontent>
<pt>
ุงุณุชุฎุฏู ูุธููุฉ [`~Dataset.set_format`] ูุชุนููู ุชูุณูู ูุฌููุนุฉ ุงูุจูุงูุงุช ุฅูู `torch` ูุญุฏุฏ ุงูุฃุนูุฏุฉ ุงูุชู ุชุฑูุฏ ุชูุณูููุง. ุชุทุจู ูุฐู ุงูุฏุงูุฉ ุงูุชูุณูู ุฃุซูุงุก ุงูุชููู. ุจุนุฏ ุชุญููููุง ุฅูู ุชูุณูุฑุงุช PyTorchุ ูู ุจูู ูุฌููุนุฉ ุงูุจูุงูุงุช ูู [`torch.utils.data.DataLoader`](https://alband.github.io/doc_view/data.html?highlight=torch%20utils%20data%20dataloader#torch.utils.data.DataLoader):

```py
>>> import torch

>>> dataset.set_format(type="torch", columns=["input_ids", "token_type_ids", "attention_mask", "labels"])
>>> dataloader = torch.utils.data.DataLoader(dataset, batch_size=32)
```

</pt>
<tf>

ุงุณุชุฎุฏู ุทุฑููุฉ [`~transformers.TFPreTrainedModel.prepare_tf_dataset`] ูู ููุชุจุฉ ๐ค Transformers ูุฅุนุฏุงุฏ ูุฌููุนุฉ ุงูุจูุงูุงุช ูุชููู ูุชูุงููุฉ ูุน TensorFlowุ ูุฌุงูุฒุฉ ูุชุฏุฑูุจ/ุถุจุท ูููุฐุฌ ุฏูููุ ุญูุซ ุชููู ุจูู ูุฌููุนุฉ ุจูุงูุงุช HuggingFace [`~datasets.Dataset`] ูู `tf.data.Dataset` ูุน ุงูุชุฌููุน ูุงูุฏูุนุงุชุ ูุฐุง ููููู ุชูุฑูุฑูุง ูุจุงุดุฑุฉ ุฅูู ุฃุณุงููุจ Keras ูุซู `fit()` ุจุฏูู ุชุนุฏูู ุฅุถุงูู.

```py
>>> import tensorflow as tf

>>> tf_dataset = model.prepare_tf_dataset(
...     dataset,
...     batch_size=4,
...     shuffle=True,
... )
```

</tf>
</frameworkcontent>

**6**. ุงุจุฏุฃ ุงูุชุฏุฑูุจ ุจุงุณุชุฎุฏุงู ุฅุทุงุฑ ุนูู ุงูุชุนูู ุงูุขูู ุงูุฎุงุต ุจู! ุชุญูู ูู ุฏููู ุชุตููู ุงููุต ูู ๐ค Transformers ููุญุตูู ุนูู ูุซุงู ุดุงูู ุญูู ููููุฉ ุชุฏุฑูุจ ูููุฐุฌ ุนูู ูุฌููุนุฉ ุจูุงูุงุช ูุตูุฉ.

## ูุง ูู ุงูุชุงููุ

ูุฐุง ูููู ุฏููู ุงูุจุฏุก ุงูุณุฑูุน ูู ๐ค Datasets! ููููู ุชุญููู ุฃู ูุต ุฃู ุตูุช ุฃู ุตูุฑุฉ ูุฌููุนุฉ ุจูุงูุงุช ุจุงุณุชุฎุฏุงู ุฏุงูุฉ ูุงุญุฏุฉ ูุฌุนููุง ุฌุงูุฒุฉ ูุชุฏุฑูุจ ูููุฐุฌู ุนูููุง.

ุจุงููุณุจุฉ ูุฎุทูุงุชู ุงูุชุงููุฉุ ุงุทูุน ุนูู ุฃุฏูุฉ ููููุฉ ุงูููุงู ุจุฐูู ูุชุนุฑู ุนูู ููููุฉ ุงูููุงู ุจุฃุดูุงุก ุฃูุซุฑ ุชุญุฏูุฏูุง ูุซู ุชุญููู ุชูุณููุงุช ูุฌููุนุงุช ุจูุงูุงุช ูุฎุชููุฉุ ูููุงุกูุฉ ุงูุชุณููุงุชุ ูุจุซ ูุฌููุนุงุช ุงูุจูุงูุงุช ุงููุจูุฑุฉ. ุฅุฐุง ููุช ููุชููุง ุจูุนุฑูุฉ ุงููุฒูุฏ ุนู ุงูููุงููู ุงูุฃุณุงุณูุฉ ูู ๐ค Datasetsุ ูุงุญุตู ุนูู ููุฌุงู ูู ุงููููุฉ ูุงูุฑุฃ ุฃุฏูุฉ ุงูููุงููู ูุฏููุง!