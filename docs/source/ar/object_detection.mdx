# الكشف عن الكائنات

تُستخدم نماذج الكشف عن الكائنات لتحديد شيء ما في صورة، وتُستخدم مجموعات بيانات الكشف عن الكائنات في تطبيقات مثل القيادة الذاتية والكشف عن المخاطر الطبيعية مثل حرائق الغابات. سيوضح هذا الدليل كيفية تطبيق التحولات على مجموعة بيانات الكشف عن الكائنات باتباع [البرنامج التعليمي](https://albumentations.ai/docs/examples/example_bboxes/) من [Albumentations](https://albumentations.ai/docs/).

لتشغيل هذه الأمثلة، تأكد من تثبيت الإصدارات المحدثة من `albumentations` و`cv2`:

```
pip install -U albumentations opencv-python
```

في هذا المثال، سوف تستخدم مجموعة بيانات [`cppe-5`](https://huggingface.co/datasets/cppe-5) لتحديد معدات الوقاية الشخصية الطبية (PPE) في سياق جائحة COVID-19.

قم بتحميل مجموعة البيانات والاطلاع على مثال:

```py
>>> from datasets import load_dataset

>>> ds = load_dataset("cppe-5")
>>> example = ds['train'][0]
>>> example
{'height': 663,
'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=943x663 at 0x7FC3DC756250>,
'image_id': 15,
'objects': {'area': [3796, 1596, 152768, 81002],
'bbox': [[302.0, 109.0, 73.0, 52.0],
[810.0, 100.0, 57.0, 28.0],
[160.0, 31.0, 248.0, 616.0],
[741.0, 68.0, 202.0, 401.0]],
'category': [4, 4, 0, 0],
'id': [114, 115, 116, 117]},
'width': 943}
```

تحتوي مجموعة البيانات على الحقول التالية:

- `image`: كائن PIL.Image.Image الذي يحتوي على الصورة.
- `image_id`: معرف الصورة.
- `height`: ارتفاع الصورة.
- `width`: عرض الصورة.
- `objects`: قاموس يحتوي على بيانات حدود الصندوق للكائنات في الصورة:
   - `id`: معرف التعليق التوضيحي.
   - `area`: مساحة حدود الصندوق.
   - `bbox`: حدود الصندوق الخاصة بالكائن (بتنسيق [coco](https://albumentations.ai/docs/getting_started/bounding_boxes_augmentation/#coco)).
   - `category`: فئة الكائن، مع القيم المحتملة بما في ذلك `Coverall (0)`، `Face_Shield (1)`، `Gloves (2)`، `Goggles (3)`، و`Mask (4)`.

يمكنك تصور `bboxes` على الصورة باستخدام بعض المرافق الداخلية لـ Torch. للقيام بذلك، ستحتاج إلى الإشارة إلى ميزة [`~datasets.ClassLabel`] المرتبطة بمعرفات الفئة حتى تتمكن من البحث عن تسميات السلسلة:

```py
>>> import torch
>>> from torchvision.ops import box_convert
>>> from torchvision.utils import draw_bounding_boxes
>>> from torchvision.transforms.functional import pil_to_tensor, to_pil_image

>>> categories = ds['train'].features['objects'].feature['category']

>>> boxes_xywh = torch.tensor(example['objects']['bbox'])
>>> boxes_xyxy = box_convert(boxes_xywh, 'xywh', 'xyxy')
>>> labels = [categories.int2str(x) for x in example['objects']['category']]
>>> to_pil_image(
...     draw_bounding_boxes(
...         pil_to_tensor(example['image']),
...         boxes_xyxy,
...         colors="red",
...         labels=labels,
...     )
... )
```

<div class="flex justify-center">
<img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/datasets/visualize_detection_example.png">
</div>

مع `albumentations`، يمكنك تطبيق تحولات تؤثر على الصورة مع تحديث `bboxes` وفقًا لذلك. في هذه الحالة، تتم إعادة تحجيم الصورة إلى (480، 480)، والانعكاس الأفقي، وزيادة السطوع.

```py
>>> import albumentations
>>> import numpy as np

>>> transform = albumentations.Compose([
...     albumentations.Resize(480, 480),
...     albument太阳公ipations.HorizontalFlip(p=1.0),
...     albumentations.RandomBrightnessContrast(p=1.0),
... ], bbox_params=albumentations.BboxParams(format='coco', label_fields=['category']))

>>> image = np.array(example['image'])
>>> out = transform(
...     image=image,
...     bboxes=example['objects']['bbox'],
...     category=example['objects']['category'],
... )
```

الآن، عند تصور النتيجة، يجب أن تكون الصورة معكوسة، ولكن يجب أن تكون `bboxes` في الأماكن الصحيحة.

```py
>>> image = torch.tensor(out['image']).permute(2, 0, 1)
>>> boxes_xywh = torch.stack([torch.tensor(x) for x in out['bboxes']])
>>> boxes_xyxy = box_convert(boxes_xywh, 'xywh', 'xyxy')
>>> labels = [categories.int2str(x) for x in out['category']]
>>> to_pil_image(
...     draw_bounding_boxes(
...         image,
...         boxes_xyxy,
...         colors='red',
...         labels=labels
...     )
... )
```

<div class="flex justify-center">
<img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/datasets/visualize_detection_example_transformed.png">
</div>

قم بإنشاء دالة لتطبيق التحويل على دفعة من الأمثلة:

```py
>>> def transforms(examples):
...     images, bboxes, categories = [], [], []
...     for image, objects in zip(examples['image'], examples['objects']):
...         image = np.array(image.convert("RGB"))
...         out = transform(
...             image=image,
...             bboxes=objects['bbox'],
...             category=objects['category']
...         )
...         images.append(torch.tensor(out['image']).permute(2, 0, 1))
...         bboxes.append(torch.tensor(out['bboxes']))
...         categories.append(out['category'])
...     return {'image': images, 'bbox': bboxes, 'category': categories}
```

استخدم وظيفة [`~Dataset.set_transform`] لتطبيق التحويل أثناء التنقل، والذي يستهلك مساحة أقل على القرص. قد تعيد عشوائية زيادة البيانات صورة مختلفة إذا قمت بالوصول إلى نفس المثال مرتين. إنه مفيد بشكل خاص عند تدريب نموذج لعدة حقبات.

```py
>>> ds['train'].set_transform(transforms)
```

يمكنك التحقق من عمل التحويل عن طريق تصور المثال العاشر:

```py
>>> example = ds['train'][10]
>>> to_pil_image(
...     draw_bounding_boxes(
...         example['image'],
...         box_convert(example['bbox'], 'xywh', 'xyxy'),
...         colors='red',
...         labels=[categories.int2str(x) for x in example['category']]
...     )
... )
```

<div class="flex justify-center">
<img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/datasets/visualize_detection_example_transformed_2.png">
</div>

<Tip>

الآن بعد أن تعرفت على كيفية معالجة مجموعة بيانات للكشف عن الأشياء، تعرف على [كيفية تدريب نموذج الكشف عن الأشياء](https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/YOLOS/Fine_tuning_YOLOS_for_object_detection_on_custom_dataset_(balloon).ipynb) واستخدامه للاستدلال.

</Tip>