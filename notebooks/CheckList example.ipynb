{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import checklist\n",
    "import checklist.editor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = checklist.editor.Editor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['New York',\n",
       " 'Los Angeles',\n",
       " 'Chicago',\n",
       " 'Houston',\n",
       " 'Philadelphia',\n",
       " 'Phoenix',\n",
       " 'San Antonio',\n",
       " 'San Diego',\n",
       " 'Dallas',\n",
       " 'San Jose',\n",
       " 'Austin',\n",
       " 'Indianapolis',\n",
       " 'Jacksonville',\n",
       " 'San Francisco',\n",
       " 'Columbus',\n",
       " 'Charlotte',\n",
       " 'Fort Worth',\n",
       " 'Detroit',\n",
       " 'El Paso',\n",
       " 'Memphis',\n",
       " 'Seattle',\n",
       " 'Denver',\n",
       " 'Washington',\n",
       " 'Boston',\n",
       " 'Nashville-Davidson',\n",
       " 'Baltimore',\n",
       " 'Oklahoma City',\n",
       " 'Louisville/Jefferson County',\n",
       " 'Portland',\n",
       " 'Las Vegas',\n",
       " 'Milwaukee',\n",
       " 'Albuquerque',\n",
       " 'Tucson',\n",
       " 'Fresno',\n",
       " 'Sacramento',\n",
       " 'Long Beach',\n",
       " 'Kansas City',\n",
       " 'Mesa',\n",
       " 'Virginia Beach',\n",
       " 'Atlanta',\n",
       " 'Colorado Springs',\n",
       " 'Omaha',\n",
       " 'Raleigh',\n",
       " 'Miami',\n",
       " 'Oakland',\n",
       " 'Minneapolis',\n",
       " 'Tulsa',\n",
       " 'Cleveland',\n",
       " 'Wichita',\n",
       " 'Arlington',\n",
       " 'New Orleans',\n",
       " 'Bakersfield',\n",
       " 'Tampa',\n",
       " 'Honolulu',\n",
       " 'Aurora',\n",
       " 'Anaheim',\n",
       " 'Santa Ana',\n",
       " 'St. Louis',\n",
       " 'Riverside',\n",
       " 'Corpus Christi',\n",
       " 'Lexington-Fayette',\n",
       " 'Pittsburgh',\n",
       " 'Anchorage',\n",
       " 'Stockton',\n",
       " 'Cincinnati',\n",
       " 'St. Paul',\n",
       " 'Toledo',\n",
       " 'Greensboro',\n",
       " 'Newark',\n",
       " 'Plano',\n",
       " 'Henderson',\n",
       " 'Lincoln',\n",
       " 'Buffalo',\n",
       " 'Jersey City',\n",
       " 'Chula Vista',\n",
       " 'Fort Wayne',\n",
       " 'Orlando',\n",
       " 'St. Petersburg',\n",
       " 'Chandler',\n",
       " 'Laredo',\n",
       " 'Norfolk',\n",
       " 'Durham',\n",
       " 'Madison',\n",
       " 'Lubbock',\n",
       " 'Irvine',\n",
       " 'Winston-Salem',\n",
       " 'Glendale',\n",
       " 'Garland',\n",
       " 'Hialeah',\n",
       " 'Reno',\n",
       " 'Chesapeake',\n",
       " 'Gilbert',\n",
       " 'Baton Rouge',\n",
       " 'Irving',\n",
       " 'Scottsdale',\n",
       " 'North Las Vegas',\n",
       " 'Fremont',\n",
       " 'Boise City',\n",
       " 'Richmond',\n",
       " 'San Bernardino',\n",
       " 'Birmingham',\n",
       " 'Spokane',\n",
       " 'Rochester',\n",
       " 'Des Moines',\n",
       " 'Modesto',\n",
       " 'Fayetteville',\n",
       " 'Tacoma',\n",
       " 'Oxnard',\n",
       " 'Fontana',\n",
       " 'Columbus',\n",
       " 'Montgomery',\n",
       " 'Moreno Valley',\n",
       " 'Shreveport',\n",
       " 'Aurora',\n",
       " 'Yonkers',\n",
       " 'Akron',\n",
       " 'Huntington Beach',\n",
       " 'Little Rock',\n",
       " 'Augusta-Richmond County',\n",
       " 'Amarillo',\n",
       " 'Glendale',\n",
       " 'Mobile',\n",
       " 'Grand Rapids',\n",
       " 'Salt Lake City',\n",
       " 'Tallahassee',\n",
       " 'Huntsville',\n",
       " 'Grand Prairie',\n",
       " 'Knoxville',\n",
       " 'Worcester',\n",
       " 'Newport News',\n",
       " 'Brownsville',\n",
       " 'Overland Park',\n",
       " 'Santa Clarita',\n",
       " 'Providence',\n",
       " 'Garden Grove',\n",
       " 'Chattanooga',\n",
       " 'Oceanside',\n",
       " 'Jackson',\n",
       " 'Fort Lauderdale',\n",
       " 'Santa Rosa',\n",
       " 'Rancho Cucamonga',\n",
       " 'Port St. Lucie',\n",
       " 'Tempe',\n",
       " 'Ontario',\n",
       " 'Vancouver',\n",
       " 'Cape Coral',\n",
       " 'Sioux Falls',\n",
       " 'Springfield',\n",
       " 'Peoria',\n",
       " 'Pembroke Pines',\n",
       " 'Elk Grove',\n",
       " 'Salem',\n",
       " 'Lancaster',\n",
       " 'Corona',\n",
       " 'Eugene',\n",
       " 'Palmdale',\n",
       " 'Salinas',\n",
       " 'Springfield',\n",
       " 'Pasadena',\n",
       " 'Fort Collins',\n",
       " 'Hayward',\n",
       " 'Pomona',\n",
       " 'Cary',\n",
       " 'Rockford',\n",
       " 'Alexandria',\n",
       " 'Escondido',\n",
       " 'McKinney',\n",
       " 'Kansas City',\n",
       " 'Joliet',\n",
       " 'Sunnyvale',\n",
       " 'Torrance',\n",
       " 'Bridgeport',\n",
       " 'Lakewood',\n",
       " 'Hollywood',\n",
       " 'Paterson',\n",
       " 'Naperville',\n",
       " 'Syracuse',\n",
       " 'Mesquite',\n",
       " 'Dayton',\n",
       " 'Savannah',\n",
       " 'Clarksville',\n",
       " 'Orange',\n",
       " 'Pasadena',\n",
       " 'Fullerton',\n",
       " 'Killeen',\n",
       " 'Frisco',\n",
       " 'Hampton',\n",
       " 'McAllen',\n",
       " 'Warren',\n",
       " 'Bellevue',\n",
       " 'West Valley City',\n",
       " 'Columbia',\n",
       " 'Olathe',\n",
       " 'Sterling Heights',\n",
       " 'New Haven',\n",
       " 'Miramar',\n",
       " 'Waco',\n",
       " 'Thousand Oaks',\n",
       " 'Cedar Rapids',\n",
       " 'Charleston',\n",
       " 'Visalia',\n",
       " 'Topeka',\n",
       " 'Elizabeth',\n",
       " 'Gainesville',\n",
       " 'Thornton',\n",
       " 'Roseville',\n",
       " 'Carrollton',\n",
       " 'Coral Springs',\n",
       " 'Stamford',\n",
       " 'Simi Valley',\n",
       " 'Concord',\n",
       " 'Hartford',\n",
       " 'Kent',\n",
       " 'Lafayette',\n",
       " 'Midland',\n",
       " 'Surprise',\n",
       " 'Denton',\n",
       " 'Victorville',\n",
       " 'Evansville',\n",
       " 'Santa Clara',\n",
       " 'Abilene',\n",
       " 'Athens-Clarke County',\n",
       " 'Vallejo',\n",
       " 'Allentown',\n",
       " 'Norman',\n",
       " 'Beaumont',\n",
       " 'Independence',\n",
       " 'Murfreesboro',\n",
       " 'Ann Arbor',\n",
       " 'Springfield',\n",
       " 'Berkeley',\n",
       " 'Peoria',\n",
       " 'Provo',\n",
       " 'El Monte',\n",
       " 'Columbia',\n",
       " 'Lansing',\n",
       " 'Fargo',\n",
       " 'Downey',\n",
       " 'Costa Mesa',\n",
       " 'Wilmington',\n",
       " 'Arvada',\n",
       " 'Inglewood',\n",
       " 'Miami Gardens',\n",
       " 'Carlsbad',\n",
       " 'Westminster',\n",
       " 'Rochester',\n",
       " 'Odessa',\n",
       " 'Manchester',\n",
       " 'Elgin',\n",
       " 'West Jordan',\n",
       " 'Round Rock',\n",
       " 'Clearwater',\n",
       " 'Waterbury',\n",
       " 'Gresham',\n",
       " 'Fairfield',\n",
       " 'Billings',\n",
       " 'Lowell',\n",
       " 'San Buenaventura (Ventura)',\n",
       " 'Pueblo',\n",
       " 'High Point',\n",
       " 'West Covina',\n",
       " 'Richmond',\n",
       " 'Murrieta',\n",
       " 'Cambridge',\n",
       " 'Antioch',\n",
       " 'Temecula',\n",
       " 'Norwalk',\n",
       " 'Centennial',\n",
       " 'Everett',\n",
       " 'Palm Bay',\n",
       " 'Wichita Falls',\n",
       " 'Green Bay',\n",
       " 'Daly City',\n",
       " 'Burbank',\n",
       " 'Richardson',\n",
       " 'Pompano Beach',\n",
       " 'North Charleston',\n",
       " 'Broken Arrow',\n",
       " 'Boulder',\n",
       " 'West Palm Beach',\n",
       " 'Santa Maria',\n",
       " 'El Cajon',\n",
       " 'Davenport',\n",
       " 'Rialto',\n",
       " 'Las Cruces',\n",
       " 'San Mateo',\n",
       " 'Lewisville',\n",
       " 'South Bend',\n",
       " 'Lakeland',\n",
       " 'Erie',\n",
       " 'Tyler',\n",
       " 'Pearland',\n",
       " 'College Station',\n",
       " 'Kenosha',\n",
       " 'Sandy Springs',\n",
       " 'Clovis',\n",
       " 'Flint',\n",
       " 'Roanoke',\n",
       " 'Albany',\n",
       " 'Jurupa Valley',\n",
       " 'Compton',\n",
       " 'San Angelo',\n",
       " 'Hillsboro',\n",
       " 'Lawton',\n",
       " 'Renton',\n",
       " 'Vista',\n",
       " 'Davie',\n",
       " 'Greeley',\n",
       " 'Mission Viejo',\n",
       " 'Portsmouth',\n",
       " 'Dearborn',\n",
       " 'South Gate',\n",
       " 'Tuscaloosa',\n",
       " 'Livonia',\n",
       " 'New Bedford',\n",
       " 'Vacaville',\n",
       " 'Brockton',\n",
       " 'Roswell',\n",
       " 'Beaverton',\n",
       " 'Quincy',\n",
       " 'Sparks',\n",
       " 'Yakima',\n",
       " \"Lee's Summit\",\n",
       " 'Federal Way',\n",
       " 'Carson',\n",
       " 'Santa Monica',\n",
       " 'Hesperia',\n",
       " 'Allen',\n",
       " 'Rio Rancho',\n",
       " 'Yuma',\n",
       " 'Westminster',\n",
       " 'Orem',\n",
       " 'Lynn',\n",
       " 'Redding',\n",
       " 'Spokane Valley',\n",
       " 'Miami Beach',\n",
       " 'League City',\n",
       " 'Lawrence',\n",
       " 'Santa Barbara',\n",
       " 'Plantation',\n",
       " 'Sandy',\n",
       " 'Sunrise',\n",
       " 'Macon',\n",
       " 'Longmont',\n",
       " 'Boca Raton',\n",
       " 'San Marcos',\n",
       " 'Greenville',\n",
       " 'Waukegan',\n",
       " 'Fall River',\n",
       " 'Chico',\n",
       " 'Newton',\n",
       " 'San Leandro',\n",
       " 'Reading',\n",
       " 'Norwalk',\n",
       " 'Fort Smith',\n",
       " 'Newport Beach',\n",
       " 'Asheville',\n",
       " 'Nashua',\n",
       " 'Edmond',\n",
       " 'Whittier',\n",
       " 'Nampa',\n",
       " 'Bloomington',\n",
       " 'Deltona',\n",
       " 'Hawthorne',\n",
       " 'Duluth',\n",
       " 'Carmel',\n",
       " 'Suffolk',\n",
       " 'Clifton',\n",
       " 'Citrus Heights',\n",
       " 'Livermore',\n",
       " 'Tracy',\n",
       " 'Alhambra',\n",
       " 'Kirkland',\n",
       " 'Trenton',\n",
       " 'Ogden',\n",
       " 'Hoover',\n",
       " 'Cicero',\n",
       " 'Fishers',\n",
       " 'Sugar Land',\n",
       " 'Danbury',\n",
       " 'Meridian',\n",
       " 'Indio',\n",
       " 'Concord',\n",
       " 'Menifee',\n",
       " 'Champaign',\n",
       " 'Buena Park',\n",
       " 'Troy',\n",
       " \"O'Fallon\",\n",
       " 'Johns Creek',\n",
       " 'Bellingham',\n",
       " 'Westland',\n",
       " 'Bloomington',\n",
       " 'Sioux City',\n",
       " 'Warwick',\n",
       " 'Hemet',\n",
       " 'Longview',\n",
       " 'Farmington Hills',\n",
       " 'Bend',\n",
       " 'Lakewood',\n",
       " 'Merced',\n",
       " 'Mission',\n",
       " 'Chino',\n",
       " 'Redwood City',\n",
       " 'Edinburg',\n",
       " 'Cranston',\n",
       " 'Parma',\n",
       " 'New Rochelle',\n",
       " 'Lake Forest',\n",
       " 'Napa',\n",
       " 'Hammond',\n",
       " 'Fayetteville',\n",
       " 'Bloomington',\n",
       " 'Avondale',\n",
       " 'Somerville',\n",
       " 'Palm Coast',\n",
       " 'Bryan',\n",
       " 'Gary',\n",
       " 'Largo',\n",
       " 'Brooklyn Park',\n",
       " 'Tustin',\n",
       " 'Racine',\n",
       " 'Deerfield Beach',\n",
       " 'Lynchburg',\n",
       " 'Mountain View',\n",
       " 'Medford',\n",
       " 'Lawrence',\n",
       " 'Bellflower',\n",
       " 'Melbourne',\n",
       " 'St. Joseph',\n",
       " 'Camden',\n",
       " 'St. George',\n",
       " 'Kennewick',\n",
       " 'Baldwin Park',\n",
       " 'Chino Hills',\n",
       " 'Alameda',\n",
       " 'Albany',\n",
       " 'Arlington Heights',\n",
       " 'Scranton',\n",
       " 'Evanston',\n",
       " 'Kalamazoo',\n",
       " 'Baytown',\n",
       " 'Upland',\n",
       " 'Springdale',\n",
       " 'Bethlehem',\n",
       " 'Schaumburg',\n",
       " 'Mount Pleasant',\n",
       " 'Auburn',\n",
       " 'Decatur',\n",
       " 'San Ramon',\n",
       " 'Pleasanton',\n",
       " 'Wyoming',\n",
       " 'Lake Charles',\n",
       " 'Plymouth',\n",
       " 'Bolingbrook',\n",
       " 'Pharr',\n",
       " 'Appleton',\n",
       " 'Gastonia',\n",
       " 'Folsom',\n",
       " 'Southfield',\n",
       " 'Rochester Hills',\n",
       " 'New Britain',\n",
       " 'Goodyear',\n",
       " 'Canton',\n",
       " 'Warner Robins',\n",
       " 'Union City',\n",
       " 'Perris',\n",
       " 'Manteca',\n",
       " 'Iowa City',\n",
       " 'Jonesboro',\n",
       " 'Wilmington',\n",
       " 'Lynwood',\n",
       " 'Loveland',\n",
       " 'Pawtucket',\n",
       " 'Boynton Beach',\n",
       " 'Waukesha',\n",
       " 'Gulfport',\n",
       " 'Apple Valley',\n",
       " 'Passaic',\n",
       " 'Rapid City',\n",
       " 'Layton',\n",
       " 'Lafayette',\n",
       " 'Turlock',\n",
       " 'Muncie',\n",
       " 'Temple',\n",
       " 'Missouri City',\n",
       " 'Redlands',\n",
       " 'Santa Fe',\n",
       " 'Lauderhill',\n",
       " 'Milpitas',\n",
       " 'Palatine',\n",
       " 'Missoula',\n",
       " 'Rock Hill',\n",
       " 'Jacksonville',\n",
       " 'Franklin',\n",
       " 'Flagstaff',\n",
       " 'Flower Mound',\n",
       " 'Weston',\n",
       " 'Waterloo',\n",
       " 'Union City',\n",
       " 'Mount Vernon',\n",
       " 'Fort Myers',\n",
       " 'Dothan',\n",
       " 'Rancho Cordova',\n",
       " 'Redondo Beach',\n",
       " 'Jackson',\n",
       " 'Pasco',\n",
       " 'St. Charles',\n",
       " 'Eau Claire',\n",
       " 'North Richland Hills',\n",
       " 'Bismarck',\n",
       " 'Yorba Linda',\n",
       " 'Kenner',\n",
       " 'Walnut Creek',\n",
       " 'Frederick',\n",
       " 'Oshkosh',\n",
       " 'Pittsburg',\n",
       " 'Palo Alto',\n",
       " 'Bossier City',\n",
       " 'Portland',\n",
       " 'St. Cloud',\n",
       " 'Davis',\n",
       " 'South San Francisco',\n",
       " 'Camarillo',\n",
       " 'North Little Rock',\n",
       " 'Schenectady',\n",
       " 'Gaithersburg',\n",
       " 'Harlingen',\n",
       " 'Woodbury',\n",
       " 'Eagan',\n",
       " 'Yuba City',\n",
       " 'Maple Grove',\n",
       " 'Youngstown',\n",
       " 'Skokie',\n",
       " 'Kissimmee',\n",
       " 'Johnson City',\n",
       " 'Victoria',\n",
       " 'San Clemente',\n",
       " 'Bayonne',\n",
       " 'Laguna Niguel',\n",
       " 'East Orange',\n",
       " 'Shawnee',\n",
       " 'Homestead',\n",
       " 'Rockville',\n",
       " 'Delray Beach',\n",
       " 'Janesville',\n",
       " 'Conway',\n",
       " 'Pico Rivera',\n",
       " 'Lorain',\n",
       " 'Montebello',\n",
       " 'Lodi',\n",
       " 'New Braunfels',\n",
       " 'Marysville',\n",
       " 'Tamarac',\n",
       " 'Madera',\n",
       " 'Conroe',\n",
       " 'Santa Cruz',\n",
       " 'Eden Prairie',\n",
       " 'Cheyenne',\n",
       " 'Daytona Beach',\n",
       " 'Alpharetta',\n",
       " 'Hamilton',\n",
       " 'Waltham',\n",
       " 'Coon Rapids',\n",
       " 'Haverhill',\n",
       " 'Council Bluffs',\n",
       " 'Taylor',\n",
       " 'Utica',\n",
       " 'Ames',\n",
       " 'La Habra',\n",
       " 'Encinitas',\n",
       " 'Bowling Green',\n",
       " 'Burnsville',\n",
       " 'Greenville',\n",
       " 'West Des Moines',\n",
       " 'Cedar Park',\n",
       " 'Tulare',\n",
       " 'Monterey Park',\n",
       " 'Vineland',\n",
       " 'Terre Haute',\n",
       " 'North Miami',\n",
       " 'Mansfield',\n",
       " 'West Allis',\n",
       " 'Bristol',\n",
       " 'Taylorsville',\n",
       " 'Malden',\n",
       " 'Meriden',\n",
       " 'Blaine',\n",
       " 'Wellington',\n",
       " 'Cupertino',\n",
       " 'Springfield',\n",
       " 'Rogers',\n",
       " 'St. Clair Shores',\n",
       " 'Gardena',\n",
       " 'Pontiac',\n",
       " 'National City',\n",
       " 'Grand Junction',\n",
       " 'Rocklin',\n",
       " 'Chapel Hill',\n",
       " 'Casper',\n",
       " 'Broomfield',\n",
       " 'Petaluma',\n",
       " 'South Jordan',\n",
       " 'Springfield',\n",
       " 'Great Falls',\n",
       " 'Lancaster',\n",
       " 'North Port',\n",
       " 'Lakewood',\n",
       " 'Marietta',\n",
       " 'San Rafael',\n",
       " 'Royal Oak',\n",
       " 'Des Plaines',\n",
       " 'Huntington Park',\n",
       " 'La Mesa',\n",
       " 'Orland Park',\n",
       " 'Auburn',\n",
       " 'Lakeville',\n",
       " 'Owensboro',\n",
       " 'Moore',\n",
       " 'Jupiter',\n",
       " 'Idaho Falls',\n",
       " 'Dubuque',\n",
       " 'Bartlett',\n",
       " 'Rowlett',\n",
       " 'Novi',\n",
       " 'White Plains',\n",
       " 'Arcadia',\n",
       " 'Redmond',\n",
       " 'Lake Elsinore',\n",
       " 'Ocala',\n",
       " 'Tinley Park',\n",
       " 'Port Orange',\n",
       " 'Medford',\n",
       " 'Oak Lawn',\n",
       " 'Rocky Mount',\n",
       " 'Kokomo',\n",
       " 'Coconut Creek',\n",
       " 'Bowie',\n",
       " 'Berwyn',\n",
       " 'Midwest City',\n",
       " 'Fountain Valley',\n",
       " 'Buckeye',\n",
       " 'Dearborn Heights',\n",
       " 'Woodland',\n",
       " 'Noblesville',\n",
       " 'Valdosta',\n",
       " 'Diamond Bar',\n",
       " 'Manhattan',\n",
       " 'Santee',\n",
       " 'Taunton',\n",
       " 'Sanford',\n",
       " 'Kettering',\n",
       " 'New Brunswick',\n",
       " 'Decatur',\n",
       " 'Chicopee',\n",
       " 'Anderson',\n",
       " 'Margate',\n",
       " 'Weymouth Town',\n",
       " 'Hempstead',\n",
       " 'Corvallis',\n",
       " 'Eastvale',\n",
       " 'Porterville',\n",
       " 'West Haven',\n",
       " 'Brentwood',\n",
       " 'Paramount',\n",
       " 'Grand Forks',\n",
       " 'Georgetown',\n",
       " 'St. Peters',\n",
       " 'Shoreline',\n",
       " 'Mount Prospect',\n",
       " 'Hanford',\n",
       " 'Normal',\n",
       " 'Rosemead',\n",
       " 'Lehi',\n",
       " 'Pocatello',\n",
       " 'Highland',\n",
       " 'Novato',\n",
       " 'Port Arthur',\n",
       " 'Carson City',\n",
       " 'San Marcos',\n",
       " 'Hendersonville',\n",
       " 'Elyria',\n",
       " 'Revere',\n",
       " 'Pflugerville',\n",
       " 'Greenwood',\n",
       " 'Bellevue',\n",
       " 'Wheaton',\n",
       " 'Smyrna',\n",
       " 'Sarasota',\n",
       " 'Blue Springs',\n",
       " 'Colton',\n",
       " 'Euless',\n",
       " 'Castle Rock',\n",
       " 'Cathedral City',\n",
       " 'Kingsport',\n",
       " 'Lake Havasu City',\n",
       " 'Pensacola',\n",
       " 'Hoboken',\n",
       " 'Yucaipa',\n",
       " 'Watsonville',\n",
       " 'Richland',\n",
       " 'Delano',\n",
       " 'Hoffman Estates',\n",
       " 'Florissant',\n",
       " 'Placentia',\n",
       " 'West New York',\n",
       " 'Dublin',\n",
       " 'Oak Park',\n",
       " 'Peabody',\n",
       " 'Perth Amboy',\n",
       " 'Battle Creek',\n",
       " 'Bradenton',\n",
       " 'Gilroy',\n",
       " 'Milford',\n",
       " 'Albany',\n",
       " 'Ankeny',\n",
       " 'La Crosse',\n",
       " 'Burlington',\n",
       " 'DeSoto',\n",
       " 'Harrisonburg',\n",
       " 'Minnetonka',\n",
       " 'Elkhart',\n",
       " 'Lakewood',\n",
       " 'Glendora',\n",
       " 'Southaven',\n",
       " 'Charleston',\n",
       " 'Joplin',\n",
       " 'Enid',\n",
       " 'Palm Beach Gardens',\n",
       " 'Brookhaven',\n",
       " 'Plainfield',\n",
       " 'Grand Island',\n",
       " 'Palm Desert',\n",
       " 'Huntersville',\n",
       " 'Tigard',\n",
       " 'Lenexa',\n",
       " 'Saginaw',\n",
       " 'Kentwood',\n",
       " 'Doral',\n",
       " 'Apple Valley',\n",
       " 'Grapevine',\n",
       " 'Aliso Viejo',\n",
       " 'Sammamish',\n",
       " 'Casa Grande',\n",
       " 'Pinellas Park',\n",
       " 'Troy',\n",
       " 'West Sacramento',\n",
       " 'Burien',\n",
       " 'Commerce City',\n",
       " 'Monroe',\n",
       " 'Cerritos',\n",
       " 'Downers Grove',\n",
       " 'Coral Gables',\n",
       " 'Wilson',\n",
       " 'Niagara Falls',\n",
       " 'Poway',\n",
       " 'Edina',\n",
       " 'Cuyahoga Falls',\n",
       " 'Rancho Santa Margarita',\n",
       " 'Harrisburg',\n",
       " 'Huntington',\n",
       " 'La Mirada',\n",
       " 'Cypress',\n",
       " 'Caldwell',\n",
       " 'Logan',\n",
       " 'Galveston',\n",
       " 'Sheboygan',\n",
       " 'Middletown',\n",
       " 'Murray',\n",
       " 'Roswell',\n",
       " 'Parker',\n",
       " 'Bedford',\n",
       " 'East Lansing',\n",
       " 'Methuen',\n",
       " 'Covina',\n",
       " 'Alexandria',\n",
       " 'Olympia',\n",
       " 'Euclid',\n",
       " 'Mishawaka',\n",
       " 'Salina',\n",
       " 'Azusa',\n",
       " 'Newark',\n",
       " 'Chesterfield',\n",
       " 'Leesburg',\n",
       " 'Dunwoody',\n",
       " 'Hattiesburg',\n",
       " 'Roseville',\n",
       " 'Bonita Springs',\n",
       " 'Portage',\n",
       " 'St. Louis Park',\n",
       " 'Collierville',\n",
       " 'Middletown',\n",
       " 'Stillwater',\n",
       " 'East Providence',\n",
       " 'Lawrence',\n",
       " 'Wauwatosa',\n",
       " 'Mentor',\n",
       " 'Ceres',\n",
       " 'Cedar Hill',\n",
       " 'Mansfield',\n",
       " 'Binghamton',\n",
       " \"Coeur d'Alene\",\n",
       " 'San Luis Obispo',\n",
       " 'Minot',\n",
       " 'Palm Springs',\n",
       " 'Pine Bluff',\n",
       " 'Texas City',\n",
       " 'Summerville',\n",
       " 'Twin Falls',\n",
       " 'Jeffersonville',\n",
       " 'San Jacinto',\n",
       " 'Madison',\n",
       " 'Altoona',\n",
       " 'Columbus',\n",
       " 'Beavercreek',\n",
       " 'Apopka',\n",
       " 'Elmhurst',\n",
       " 'Maricopa',\n",
       " 'Farmington',\n",
       " 'Glenview',\n",
       " 'Cleveland Heights',\n",
       " 'Draper',\n",
       " 'Lincoln',\n",
       " 'Sierra Vista',\n",
       " 'Lacey',\n",
       " 'Biloxi',\n",
       " 'Strongsville',\n",
       " 'Barnstable Town',\n",
       " 'Wylie',\n",
       " 'Sayreville',\n",
       " 'Kannapolis',\n",
       " 'Charlottesville',\n",
       " 'Littleton',\n",
       " 'Titusville',\n",
       " 'Hackensack',\n",
       " 'Newark',\n",
       " 'Pittsfield',\n",
       " 'York',\n",
       " 'Lombard',\n",
       " 'Attleboro',\n",
       " 'DeKalb',\n",
       " 'Blacksburg',\n",
       " 'Dublin',\n",
       " 'Haltom City',\n",
       " 'Lompoc',\n",
       " 'El Centro',\n",
       " 'Danville',\n",
       " 'Jefferson City',\n",
       " 'Cutler Bay',\n",
       " 'Oakland Park',\n",
       " 'North Miami Beach',\n",
       " 'Freeport',\n",
       " 'Moline',\n",
       " 'Coachella',\n",
       " 'Fort Pierce',\n",
       " 'Smyrna',\n",
       " 'Bountiful',\n",
       " 'Fond du Lac',\n",
       " 'Everett',\n",
       " 'Danville',\n",
       " 'Keller',\n",
       " 'Belleville',\n",
       " 'Bell Gardens',\n",
       " 'Cleveland',\n",
       " 'North Lauderdale',\n",
       " 'Fairfield',\n",
       " 'Salem',\n",
       " 'Rancho Palos Verdes',\n",
       " 'San Bruno',\n",
       " 'Concord',\n",
       " 'Burlington',\n",
       " 'Apex',\n",
       " 'Midland',\n",
       " 'Altamonte Springs',\n",
       " 'Hutchinson',\n",
       " 'Buffalo Grove',\n",
       " 'Urbandale',\n",
       " 'State College',\n",
       " 'Urbana',\n",
       " 'Plainfield',\n",
       " 'Manassas',\n",
       " 'Bartlett',\n",
       " 'Kearny',\n",
       " 'Oro Valley',\n",
       " 'Findlay',\n",
       " 'Rohnert Park',\n",
       " 'Westfield',\n",
       " 'Linden',\n",
       " 'Sumter',\n",
       " 'Wilkes-Barre',\n",
       " 'Woonsocket',\n",
       " 'Leominster',\n",
       " 'Shelton',\n",
       " 'Brea',\n",
       " 'Covington',\n",
       " 'Rockwall',\n",
       " 'Meridian',\n",
       " 'Riverton',\n",
       " 'St. Cloud',\n",
       " 'Quincy',\n",
       " 'Morgan Hill',\n",
       " 'Warren',\n",
       " 'Edmonds',\n",
       " 'Burleson',\n",
       " 'Beverly',\n",
       " 'Mankato',\n",
       " 'Hagerstown',\n",
       " 'Prescott',\n",
       " 'Campbell',\n",
       " 'Cedar Falls',\n",
       " 'Beaumont',\n",
       " 'La Puente',\n",
       " 'Crystal Lake',\n",
       " 'Fitchburg',\n",
       " 'Carol Stream',\n",
       " 'Hickory',\n",
       " 'Streamwood',\n",
       " 'Norwich',\n",
       " 'Coppell',\n",
       " 'San Gabriel',\n",
       " 'Holyoke',\n",
       " 'Bentonville',\n",
       " 'Florence',\n",
       " 'Peachtree Corners',\n",
       " 'Brentwood',\n",
       " 'Bozeman',\n",
       " 'New Berlin',\n",
       " 'Goose Creek',\n",
       " 'Huntsville',\n",
       " 'Prescott Valley',\n",
       " 'Maplewood',\n",
       " 'Romeoville',\n",
       " 'Duncanville',\n",
       " 'Atlantic City',\n",
       " 'Clovis',\n",
       " 'The Colony',\n",
       " 'Culver City',\n",
       " 'Marlborough',\n",
       " 'Hilton Head Island',\n",
       " 'Moorhead',\n",
       " 'Calexico',\n",
       " 'Bullhead City',\n",
       " 'Germantown',\n",
       " 'La Quinta',\n",
       " 'Lancaster',\n",
       " 'Wausau',\n",
       " 'Sherman',\n",
       " 'Ocoee',\n",
       " 'Shakopee',\n",
       " 'Woburn',\n",
       " 'Bremerton',\n",
       " 'Rock Island',\n",
       " 'Muskogee',\n",
       " 'Cape Girardeau',\n",
       " 'Annapolis',\n",
       " 'Greenacres',\n",
       " 'Ormond Beach',\n",
       " 'Hallandale Beach',\n",
       " 'Stanton',\n",
       " 'Puyallup',\n",
       " 'Pacifica',\n",
       " 'Hanover Park',\n",
       " 'Hurst',\n",
       " 'Lima',\n",
       " 'Marana',\n",
       " 'Carpentersville',\n",
       " 'Oakley',\n",
       " 'Huber Heights',\n",
       " 'Lancaster',\n",
       " 'Montclair',\n",
       " 'Wheeling',\n",
       " 'Brookfield',\n",
       " 'Park Ridge',\n",
       " 'Florence',\n",
       " 'Roy',\n",
       " 'Winter Garden',\n",
       " 'Chelsea',\n",
       " 'Valley Stream',\n",
       " 'Spartanburg',\n",
       " 'Lake Oswego',\n",
       " 'Friendswood',\n",
       " 'Westerville',\n",
       " 'Northglenn',\n",
       " 'Phenix City',\n",
       " 'Grove City',\n",
       " 'Texarkana',\n",
       " 'Addison',\n",
       " 'Dover',\n",
       " 'Lincoln Park',\n",
       " 'Calumet City',\n",
       " 'Muskegon',\n",
       " 'Aventura',\n",
       " 'Martinez',\n",
       " 'Greenfield',\n",
       " 'Apache Junction',\n",
       " 'Monrovia',\n",
       " 'Weslaco',\n",
       " 'Keizer',\n",
       " 'Spanish Fork',\n",
       " 'Beloit',\n",
       " 'Panama City']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.lexicons['city']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlp import checklist as cl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "suite_path = '/home/marcotcr/work/checklist/release_data/sentiment/sentiment_suite.pkl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to tell `nlp` how to turn the data in a checklist into a map, which we do in the second argument.  \n",
    "I'll just add this function to the checklist pickle file for my test suites, making the argument optional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "suite = cl.CheckListSuite(suite_path, lambda x: {'tweet': x })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading predictions from other models (which I have saved).  \n",
    "I'm assuming that people would want to add predictions to `suite.dataset`, similar to the examples in [here](https://huggingface.co/nlp/processing.html#processing-data-row-by-row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcc0c651c22b4d5ea7ba4635b260d7b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=87470.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d22ce59356774383861126a396d1fee9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=87470.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa74bc2321d7426fb75af065d1f8ad39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=87470.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cddb1a99ea874939a0c451a39c19c291",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=87470.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6be2609e0e5f4f169c84c40f9dabf2db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=87470.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "models = ['microsoft', 'google', 'amazon', 'bert', 'roberta']\n",
    "for model in models:\n",
    "    preds = open('/home/marcotcr/work/checklist/release_data/sentiment/predictions/%s' % model).read().splitlines()\n",
    "    confs = [list(map(float, (x.split()[1:]))) for x in preds]\n",
    "    preds = [int(x.split()[0]) for x in preds]\n",
    "    conf_key = '%s_conf' % model\n",
    "    suite.dataset = suite.dataset.map(lambda _, idx: {model: preds[idx], conf_key: confs[idx]}, with_indices=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After loading the predictions, we call `suite.compute` to compute test results for each model.  \n",
    "The arguments are the prediction_key and the confidence_key.  \n",
    "The second argument is optional, but many tests depend on having a confidence score to check for monotonicity, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7087fb2e800840949aba2b1c31ed46d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=87470.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dec215ffad34923ade983fd071c6c28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=87470.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b52dc017e7a4873ae55bc0c10516b3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=87470.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9977915c2eb488ba440b4776399aeb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=87470.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "946313c5d14e427a899a46a5afd91ba3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=87470.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    conf_key = '%s_conf' % model\n",
    "    suite.compute(model, conf_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are more tests in this suite than I had in the paper, but let's pretend I want to replicate table 1 of the [checklist paper](https://homes.cs.washington.edu/~marcotcr/acl20_checklist.pdf).  \n",
    "What I would do is look at the `suite.fail_rate` dict (I can change this name to `suite.results`, or whatever) for the different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "checklist_table1 =  [\n",
    "'neutral words in context',\n",
    "'Sentiment-laden words in context',\n",
    "'change neutral words with BERT',\n",
    "'add positive phrases',\n",
    "'add negative phrases',\n",
    "'add random urls and handles',\n",
    "'typos',\n",
    "'change locations',\n",
    "'change names',\n",
    "'used to, but now',\n",
    "'simple negations: not negative',\n",
    "'simple negations: not neutral is still neutral',\n",
    "'simple negations: I thought x was negative, but it was not (should be neutral or positive)',\n",
    "'Hard: Negation of positive with neutral stuff in the middle (should be negative)',\n",
    "'my opinion is what matters',\n",
    "'Q & A: yes',\n",
    "'Q & A: no',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro googl amazo bert rober\n",
      "  0.0   7.6   4.8  94.6  81.8 neutral words in context\n",
      "  4.0  15.0   2.8   0.0   0.2 Sentiment-laden words in context\n",
      "  9.4  16.2  12.4  10.2  10.2 change neutral words with BERT\n",
      " 12.6  12.4   1.4   0.2  10.2 add positive phrases\n",
      "  0.8  34.6   5.0   0.0  13.2 add negative phrases\n",
      "  9.6  13.4  24.8  11.4   7.4 add random urls and handles\n",
      "  5.6  10.2  10.4   5.2   3.8 typos\n",
      "  7.0  20.8  14.8   7.6   6.4 change locations\n",
      "  2.4  15.1   9.1   6.6   2.4 change names\n",
      " 41.0  36.6  42.2  18.8  11.0 used to, but now\n",
      " 18.8  54.2  29.4  13.2   2.6 simple negations: not negative\n",
      " 40.4  39.6  74.2  98.4  95.4 simple negations: not neutral is still neutral\n",
      "100.0  90.4 100.0  84.8   7.2 simple negations: I thought x was negative, but it was not (should be neutral or positive)\n",
      " 98.4 100.0 100.0  74.0  30.2 Hard: Negation of positive with neutral stuff in the middle (should be negative)\n",
      " 45.4  62.4  68.0  38.8  30.0 my opinion is what matters\n",
      "  9.0  57.6  20.8   3.6   3.0 Q & A: yes\n",
      " 96.8  90.8  81.6  55.4  54.8 Q & A: no\n"
     ]
    }
   ],
   "source": [
    "print (' '.join([x[:5] for x in models]))\n",
    "for t in checklist_table1:\n",
    "    r = ' '.join(['%5.1f' % (suite.fail_rate[m][t]) for m in models])\n",
    "    print('%s %s' % (r, t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's suppose I want to compare the pipeline in transformers to these models.  \n",
    "This test suite assumes the labels are [negative, neutral, positive], so we have to do some converting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "model = pipeline(\"sentiment-analysis\", device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def pred_and_conf(data):\n",
    "    # change format to softmax, make everything in [0.33, 0.66] range be predicted as neutral\n",
    "    preds = model(data)\n",
    "    pr = np.array([x['score'] if x['label'] == 'POSITIVE' else 1 - x['score'] for x in preds])\n",
    "    pp = np.zeros((pr.shape[0], 3))\n",
    "    margin_neutral = 1/3.\n",
    "    mn = margin_neutral / 2.\n",
    "    neg = pr < 0.5 - mn\n",
    "    pp[neg, 0] = 1 - pr[neg]\n",
    "    pp[neg, 2] = pr[neg]\n",
    "    pos = pr > 0.5 + mn\n",
    "    pp[pos, 0] = 1 - pr[pos]\n",
    "    pp[pos, 2] = pr[pos]\n",
    "    neutral_pos = (pr >= 0.5) * (pr < 0.5 + mn)\n",
    "    pp[neutral_pos, 1] = 1 - (1 / margin_neutral) * np.abs(pr[neutral_pos] - 0.5)\n",
    "    pp[neutral_pos, 2] = 1 - pp[neutral_pos, 1]\n",
    "    neutral_neg = (pr < 0.5) * (pr > 0.5 - mn)\n",
    "    pp[neutral_neg, 1] = 1 - (1 / margin_neutral) * np.abs(pr[neutral_neg] - 0.5)\n",
    "    pp[neutral_neg, 0] = 1 - pp[neutral_neg, 1]\n",
    "    preds = np.argmax(pp, axis=1)\n",
    "    return preds, pp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add predictions to `suite.dataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d632360919d402793fb3373fa4fe5bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=88.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def add_pipeline(x):\n",
    "    preds, confs = pred_and_conf(x['tweet'])\n",
    "    return {'hf_pipeline': preds, 'hf_pipeline_conf': confs}\n",
    "suite.dataset = suite.dataset.map(add_pipeline , batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d826e48f5cf4f6cb3b95c410d17ee3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=87470.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "suite.compute('hf_pipeline', 'hf_pipeline_conf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.append('hf_pipeline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro googl amazo bert rober hf_pi\n",
      "  0.0   7.6   4.8  94.6  81.8  95.8 neutral words in context\n",
      "  4.0  15.0   2.8   0.0   0.2   0.8 Sentiment-laden words in context\n",
      "  9.4  16.2  12.4  10.2  10.2   9.8 change neutral words with BERT\n",
      " 12.6  12.4   1.4   0.2  10.2   0.0 add positive phrases\n",
      "  0.8  34.6   5.0   0.0  13.2   6.8 add negative phrases\n",
      "  9.6  13.4  24.8  11.4   7.4  15.4 add random urls and handles\n",
      "  5.6  10.2  10.4   5.2   3.8   6.6 typos\n",
      "  7.0  20.8  14.8   7.6   6.4  10.0 change locations\n",
      "  2.4  15.1   9.1   6.6   2.4   5.1 change names\n",
      " 41.0  36.6  42.2  18.8  11.0  32.6 used to, but now\n",
      " 18.8  54.2  29.4  13.2   2.6  12.8 simple negations: not negative\n",
      " 40.4  39.6  74.2  98.4  95.4  97.4 simple negations: not neutral is still neutral\n",
      "100.0  90.4 100.0  84.8   7.2 100.0 simple negations: I thought x was negative, but it was not (should be neutral or positive)\n",
      " 98.4 100.0 100.0  74.0  30.2  86.8 Hard: Negation of positive with neutral stuff in the middle (should be negative)\n",
      " 45.4  62.4  68.0  38.8  30.0  44.2 my opinion is what matters\n",
      "  9.0  57.6  20.8   3.6   3.0   0.8 Q & A: yes\n",
      " 96.8  90.8  81.6  55.4  54.8  85.8 Q & A: no\n"
     ]
    }
   ],
   "source": [
    "print (' '.join([x[:5] for x in models]))\n",
    "for t in checklist_table1:\n",
    "    r = ' '.join(['%5.1f' % (suite.fail_rate[m][t]) for m in models])\n",
    "    print('%s %s' % (r, t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using marcotcr/checklist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Users can access my package's object if they want to use it (e.g. for visualizations), with the caveat that it doesn't really allow for model comparison (it only keeps the state of the last model we called `compute` on).  \n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "checklist.test_suite.TestSuite"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(suite.suite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test cases:      8658\n",
      "Test cases run:  500\n",
      "Fails (rate):    4 (0.8%)\n",
      "\n",
      "Example fails:\n",
      "0.0 0.0 1.0 The flight is average.\n",
      "----\n",
      "0.1 0.0 0.9 This was an average staff.\n",
      "----\n",
      "0.1 0.0 0.9 This food was average.\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "suite.suite.tests['Sentiment-laden words in context'].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary\n",
      "\n",
      "single positive words\n",
      "Test cases:      34\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "single negative words\n",
      "Test cases:      35\n",
      "Fails (rate):    1 (2.9%)\n",
      "\n",
      "Example fails:\n",
      "0.3 0.0 0.7 average\n",
      "----\n",
      "\n",
      "\n",
      "single neutral words\n",
      "Test cases:      13\n",
      "Fails (rate):    13 (100.0%)\n",
      "\n",
      "Example fails:\n",
      "0.0 0.0 1.0 found\n",
      "----\n",
      "0.0 0.0 1.0 international\n",
      "----\n",
      "0.0 0.0 1.0 Italian\n",
      "----\n",
      "\n",
      "\n",
      "Sentiment-laden words in context\n",
      "Test cases:      8658\n",
      "Test cases run:  500\n",
      "Fails (rate):    4 (0.8%)\n",
      "\n",
      "Example fails:\n",
      "0.0 0.0 1.0 That was a weird food.\n",
      "----\n",
      "0.1 0.0 0.9 This food was average.\n",
      "----\n",
      "0.0 0.0 1.0 The flight is average.\n",
      "----\n",
      "\n",
      "\n",
      "neutral words in context\n",
      "Test cases:      1716\n",
      "Test cases run:  500\n",
      "Fails (rate):    479 (95.8%)\n",
      "\n",
      "Example fails:\n",
      "0.0 0.0 1.0 We found this airline.\n",
      "----\n",
      "1.0 0.0 0.0 That was a commercial pilot.\n",
      "----\n",
      "0.0 0.0 1.0 We saw that flight.\n",
      "----\n",
      "\n",
      "\n",
      "intensifiers\n",
      "Test cases:      2000\n",
      "Test cases run:  500\n",
      "After filtering: 496 (99.2%)\n",
      "Fails (rate):    8 (1.6%)\n",
      "\n",
      "Example fails:\n",
      "0.9 0.0 0.1 That was an average company.\n",
      "0.0 0.0 1.0 That was an amazingly average company.\n",
      "\n",
      "----\n",
      "1.0 0.0 0.0 I abhor that airline.\n",
      "0.8 0.0 0.2 I sincerely abhor that airline.\n",
      "\n",
      "----\n",
      "0.9 0.0 0.1 This was a creepy seat.\n",
      "0.7 0.0 0.3 This was a quite creepy seat.\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "reducers\n",
      "Test cases:      2000\n",
      "Test cases run:  500\n",
      "After filtering: 2 (0.4%)\n",
      "Fails (rate):    1 (50.0%)\n",
      "\n",
      "Example fails:\n",
      "0.8 0.0 0.2 This plane was average.\n",
      "1.0 0.0 0.0 This plane was mostly average.\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "change neutral words with BERT\n",
      "Test cases:      500\n",
      "Fails (rate):    49 (9.8%)\n",
      "\n",
      "Example fails:\n",
      "1.0 0.0 0.0 @AmericanAir you called back just to put me on hold. It's midnight. Literally just want to know how I'm getting home and I'm getting no help\n",
      "0.0 0.9 0.1 @AmericanAir you called back just to put me on hold. It's midnight. Literally just want to know how I'm getting home as I'm getting no help\n",
      "0.1 0.0 0.9 @AmericanAir you called back just to put me on hold. It's midnight. Literally just want to know how I'm getting home since I'm getting no help\n",
      "\n",
      "----\n",
      "0.8 0.0 0.2 @USAirways @AmericanAir what a joke of a company today reminded me why I never book with you\n",
      "0.0 0.0 1.0 @USAirways @AmericanAir what a joke of a company today reminded me why I never book hire you\n",
      "0.0 0.0 1.0 @USAirways @AmericanAir what a joke of a company today reminded me why I never book travel you\n",
      "\n",
      "----\n",
      "0.3 0.0 0.7 @USAirways oh the irony. A dog who will not spot barking in waiting area is now right in front of me! Please send me a cocktail coupon stat\n",
      "0.9 0.0 0.1 @USAirways oh the irony. A dog who will not spot barking in waiting area is now right in front of me! Please send me another cocktail coupon stat\n",
      "0.0 0.6 0.4 @USAirways oh the irony. A dog who will not spot barking in waiting area is now right in front of me! Please send me this cocktail coupon stat\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "add positive phrases\n",
      "Test cases:      500\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "add negative phrases\n",
      "Test cases:      500\n",
      "Fails (rate):    34 (6.8%)\n",
      "\n",
      "Example fails:\n",
      "0.1 0.0 0.9 @USAirways Chairman Preferred with 518,758 lifetime miles. What is my US Air reward, no #firstclass upgrades on @AmericanAir as usual.\n",
      "0.0 0.0 1.0 @USAirways Chairman Preferred with 518,758 lifetime miles. What is my US Air reward, no #firstclass upgrades on @AmericanAir as usual. You are average.\n",
      "\n",
      "----\n",
      "1.0 0.0 0.0 @AmericanAir big surprise flight 2330 is delayed. Hopefully not for 6 hours like our flight here.  Thanks again for a sleepless night.\n",
      "0.0 0.6 0.4 @AmericanAir big surprise flight 2330 is delayed. Hopefully not for 6 hours like our flight here.  Thanks again for a sleepless night. You are average.\n",
      "0.9 0.0 0.1 @AmericanAir big surprise flight 2330 is delayed. Hopefully not for 6 hours like our flight here.  Thanks again for a sleepless night. I abhor you.\n",
      "\n",
      "----\n",
      "1.0 0.0 0.0 @USAirways JUST LANDED flight 545. Any chance of making flight 5530 Phoenix to AUS\n",
      "0.9 0.0 0.1 @USAirways JUST LANDED flight 545. Any chance of making flight 5530 Phoenix to AUS. You are average.\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Robustness\n",
      "\n",
      "add random urls and handles\n",
      "Test cases:      500\n",
      "Fails (rate):    77 (15.4%)\n",
      "\n",
      "Example fails:\n",
      "0.0 0.8 0.2 @united 3 days Late Flightr and my bag has not left IAD, United is not helping at all. Everyone tells me a different story\n",
      "0.2 0.0 0.8 @Ry2XhH @united 3 days Late Flightr and my bag has not left IAD, United is not helping at all. Everyone tells me a different story\n",
      "1.0 0.0 0.0 @united 3 days Late Flightr and my bag has not left IAD, United is not helping at all. Everyone tells me a different story @3xpt5s\n",
      "\n",
      "----\n",
      "1.0 0.0 0.0 @AmericanAir That's ok...You may keep my $25 and lose my bag with no info, but you no longer have my trust. Bad way to handle this.\n",
      "0.0 0.0 1.0 @w53P3t @AmericanAir That's ok...You may keep my $25 and lose my bag with no info, but you no longer have my trust. Bad way to handle this.\n",
      "0.0 0.0 1.0 @BVcSiW @AmericanAir That's ok...You may keep my $25 and lose my bag with no info, but you no longer have my trust. Bad way to handle this.\n",
      "\n",
      "----\n",
      "0.0 0.0 1.0 Keep it up :) @AmericanAir\n",
      "0.0 1.0 0.0 https://t.co/qb0du0 Keep it up :) @AmericanAir\n",
      "0.9 0.0 0.1 https://t.co/XVnaLr Keep it up :) @AmericanAir\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "punctuation\n",
      "Test cases:      500\n",
      "Fails (rate):    27 (5.4%)\n",
      "\n",
      "Example fails:\n",
      "1.0 0.0 0.0 @united are you trying to break a world record for most delayed flights in a year?\n",
      "0.0 0.0 1.0 @united are you trying to break a world record for most delayed flights in a year.\n",
      "0.1 0.0 0.9 @united are you trying to break a world record for most delayed flights in a year\n",
      "\n",
      "----\n",
      "0.1 0.0 0.9 @united Brian at SFO customer service deserves a raise, gave me extra meal voucher and a good joke to cheer me up after flight delay. #FTW\n",
      "0.7 0.0 0.3 @united Brian at SFO customer service deserves a raise, gave me extra meal voucher and a good joke to cheer me up after flight delay. #FTW.\n",
      "\n",
      "----\n",
      "0.3 0.0 0.7 @united I believe you have to follow me in order for me send you a DM\n",
      "0.8 0.0 0.2 @united I believe you have to follow me in order for me send you a DM.\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "typos\n",
      "Test cases:      500\n",
      "Fails (rate):    33 (6.6%)\n",
      "\n",
      "Example fails:\n",
      "0.8 0.0 0.2 @USAirways I'm glad too. But I should not have to spend an hour to try and track down the basic information that you already have available.\n",
      "0.0 0.0 1.0 @USAirways I'm glad too. But I shuold not have to spend an hour to try and track down the basic information that you already have available.\n",
      "\n",
      "----\n",
      "0.3 0.0 0.7 @SouthwestAir After multiple attempts, I was finally able to submit them Late Flight last night.\n",
      "0.0 0.5 0.5 @SouthwestAir After multiple attempts, I wa sfinally able to submit them Late Flight last night.\n",
      "\n",
      "----\n",
      "1.0 0.0 0.0 @JetBlue I'm sick of y'all.\n",
      "0.0 0.0 1.0 @JetBlue I' msick of y'all.\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "2 typos\n",
      "Test cases:      500\n",
      "Fails (rate):    58 (11.6%)\n",
      "\n",
      "Example fails:\n",
      "1.0 0.0 0.0 @united trying to reach him for the number. At last they have him on standbye and gave him 1 meal voucher for a potential 2 day standbye!\n",
      "0.3 0.7 0.0 @united tryin gto reach him for the number. At last they have him on standbye and gave him 1 meal voucher for a potential 2 day standbey!\n",
      "\n",
      "----\n",
      "0.0 0.0 1.0 @JetBlue I'm also a mosaic customer and fly jet blue ALOT....\n",
      "1.0 0.0 0.0 @JetBlue I'm also am osaic customer an dfly jet blue ALOT....\n",
      "\n",
      "----\n",
      "0.0 0.0 1.0 @united Thanks. Got it straightend out last night.\n",
      "1.0 0.0 0.0 @united Thakns. Got it straightend out lastn ight.\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "contractions\n",
      "Test cases:      1000\n",
      "Test cases run:  500\n",
      "Fails (rate):    21 (4.2%)\n",
      "\n",
      "Example fails:\n",
      "0.3 0.0 0.7 @united you can't claim \"weather\" with your hardworking crew pulling seats out of a plane! Do the right thing. But we both know you won't\n",
      "0.8 0.0 0.2 @united you cannot claim \"weather\" with your hardworking crew pulling seats out of a plane! Do the right thing. But we both know you will not\n",
      "\n",
      "----\n",
      "0.0 0.5 0.5 @americanair I sure do. I'm running version 3.10.0\n",
      "0.2 0.0 0.8 @americanair I sure do. I am running version 3.10.0\n",
      "\n",
      "----\n",
      "0.2 0.0 0.8 @AmericanAir I was on flt 2222 tomorrow, they moved me to 750. I need it moved to Tuesday. the roads won't be better for flight 750. thanks\n",
      "0.7 0.0 0.3 @AmericanAir I was on flt 2222 tomorrow, they moved me to 750. I need it moved to Tuesday. the roads will not be better for flight 750. thanks\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "NER\n",
      "\n",
      "change names\n",
      "Test cases:      331\n",
      "Fails (rate):    17 (5.1%)\n",
      "\n",
      "Example fails:\n",
      "0.0 0.6 0.4 @JetBlue Been dealing with a Cancelled Flightled flight since last night &amp; was booked to a 6:15 flight,wouldve at least liked to see Ella perform lol\n",
      "0.8 0.0 0.2 @JetBlue Been dealing with a Cancelled Flightled flight since last night &amp; was booked to a 6:15 flight,wouldve at least liked to see Erica perform lol\n",
      "0.1 0.0 0.9 @JetBlue Been dealing with a Cancelled Flightled flight since last night &amp; was booked to a 6:15 flight,wouldve at least liked to see Grace perform lol\n",
      "\n",
      "----\n",
      "0.4 0.6 0.0 @united  Otis in the baggage claim by Bay #8. not at all happy but not nearly as pissed.\n",
      "0.7 0.0 0.3 @united  David in the baggage claim by Bay #8. not at all happy but not nearly as pissed.\n",
      "0.7 0.0 0.3 @united  Stephen in the baggage claim by Bay #8. not at all happy but not nearly as pissed.\n",
      "\n",
      "----\n",
      "0.8 0.0 0.2 @SouthwestAir Deborah helped me💁\n",
      "0.0 0.9 0.1 @SouthwestAir Ashley helped me💁\n",
      "0.0 0.8 0.2 @SouthwestAir Lisa helped me💁\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "change locations\n",
      "Test cases:      909\n",
      "Test cases run:  500\n",
      "Fails (rate):    50 (10.0%)\n",
      "\n",
      "Example fails:\n",
      "0.2 0.0 0.8 @VirginAmerica Now, when will we see VirginAmerica come to Philadelphia (PHL).\n",
      "0.2 0.8 0.0 @VirginAmerica Now, when will we see VirginAmerica come to Fontana (PHL).\n",
      "0.2 0.8 0.0 @VirginAmerica Now, when will we see VirginAmerica come to Wausau (PHL).\n",
      "\n",
      "----\n",
      "0.0 0.0 1.0 @SouthwestAir safety back in Dallas!\n",
      "0.0 1.0 0.0 @SouthwestAir safety back in Beloit!\n",
      "\n",
      "----\n",
      "0.1 0.9 0.0 @SouthwestAir @travelportland welcome to Portland. Sun, Mt hood and Southwest. http://t.co/y3SAHVX3Zk\n",
      "0.3 0.0 0.7 @SouthwestAir @travelportland welcome to Plainfield. Sun, Mt hood and Southwest. http://t.co/y3SAHVX3Zk\n",
      "0.2 0.0 0.8 @SouthwestAir @travelportland welcome to Rocklin. Sun, Mt hood and Southwest. http://t.co/y3SAHVX3Zk\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "change numbers\n",
      "Test cases:      1000\n",
      "Test cases run:  500\n",
      "Fails (rate):    14 (2.8%)\n",
      "\n",
      "Example fails:\n",
      "0.1 0.0 0.9 @USAirways US 728 stated their issues as: kept plane on ground to allow connecting passengers from other flight to board. Fine. Understand.\n",
      "0.0 0.7 0.3 @USAirways US 610 stated their issues as: kept plane on ground to allow connecting passengers from other flight to board. Fine. Understand.\n",
      "\n",
      "----\n",
      "0.2 0.0 0.8 @SouthwestAir flight # 317\n",
      "0.0 0.5 0.5 @SouthwestAir flight # 369\n",
      "0.0 0.5 0.5 @SouthwestAir flight # 259\n",
      "\n",
      "----\n",
      "0.0 0.5 0.5 @USAirways 3 hrs on hold. Husband has decided we should sleep in shifts so we don't miss the phone rep. to reschedule\n",
      "0.3 0.0 0.7 @USAirways 4 hrs on hold. Husband has decided we should sleep in shifts so we don't miss the phone rep. to reschedule\n",
      "0.3 0.0 0.7 @USAirways 4 hrs on hold. Husband has decided we should sleep in shifts so we don't miss the phone rep. to reschedule\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Fairness\n",
      "\n",
      "protected: race\n",
      "Test cases:      600\n",
      "Test cases run:  500\n",
      "Fails (rate):    341 (68.2%)\n",
      "\n",
      "Example fails:\n",
      "0.9 0.0 0.1 Avery is a black male.\n",
      "0.0 0.0 1.0 Avery is an asian male.\n",
      "0.0 0.0 1.0 Avery is a hispanic male.\n",
      "\n",
      "----\n",
      "0.7 0.0 0.3 Holly is a black actress.\n",
      "0.0 0.0 1.0 Holly is an asian actress.\n",
      "0.0 0.0 1.0 Holly is a hispanic actress.\n",
      "\n",
      "----\n",
      "0.1 0.9 0.0 Samuel is a black priest.\n",
      "0.0 0.0 1.0 Samuel is a hispanic priest.\n",
      "0.0 0.0 1.0 Samuel is a white priest.\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "protected: sexual\n",
      "Test cases:      600\n",
      "Test cases run:  500\n",
      "Fails (rate):    431 (86.2%)\n",
      "\n",
      "Example fails:\n",
      "0.0 0.0 1.0 Maria is an asexual herself.\n",
      "1.0 0.0 0.0 Maria is a gay herself.\n",
      "1.0 0.0 0.0 Maria is a lesbian herself.\n",
      "\n",
      "----\n",
      "0.0 0.0 1.0 Nathaniel is an asexual story.\n",
      "0.4 0.6 0.0 Nathaniel is a lesbian story.\n",
      "1.0 0.0 0.0 Nathaniel is a gay story.\n",
      "\n",
      "----\n",
      "0.0 0.0 1.0 Travis is an asexual guy.\n",
      "1.0 0.0 0.0 Travis is a queer guy.\n",
      "1.0 0.0 0.0 Travis is a trans guy.\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "protected: religion\n",
      "Test cases:      600\n",
      "Test cases run:  500\n",
      "Fails (rate):    483 (96.6%)\n",
      "\n",
      "Example fails:\n",
      "0.0 0.0 1.0 William is a Christian leader.\n",
      "1.0 0.0 0.0 William is an Atheist leader.\n",
      "\n",
      "----\n",
      "0.0 0.0 1.0 Benjamin is a Christian saint.\n",
      "1.0 0.0 0.0 Benjamin is an Atheist saint.\n",
      "\n",
      "----\n",
      "0.0 0.0 1.0 Amber is a Christian Canadian.\n",
      "0.9 0.0 0.1 Amber is an Atheist Canadian.\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "protected: nationality\n",
      "Test cases:      600\n",
      "Test cases run:  500\n",
      "Fails (rate):    57 (11.4%)\n",
      "\n",
      "Example fails:\n",
      "0.0 0.0 1.0 Brandon is a Chinese Republican.\n",
      "0.5 0.5 0.0 Brandon is a Bangladeshi Republican.\n",
      "\n",
      "----\n",
      "0.0 0.0 1.0 Aiden is a Chinese name.\n",
      "0.0 0.7 0.3 Aiden is a German name.\n",
      "\n",
      "----\n",
      "0.1 0.0 0.9 Mason is a Chinese flag.\n",
      "0.1 0.9 0.0 Mason is a Pakistani flag.\n",
      "0.8 0.0 0.2 Mason is a German flag.\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Temporal\n",
      "\n",
      "used to, but now\n",
      "Test cases:      8000\n",
      "Test cases run:  500\n",
      "Fails (rate):    163 (32.6%)\n",
      "\n",
      "Example fails:\n",
      "0.9 0.0 0.1 I used to regret this airline, even though now I value it.\n",
      "----\n",
      "0.0 0.0 1.0 I used to enjoy this airline,  now I abhor it.\n",
      "----\n",
      "0.1 0.0 0.9 I used to recommend this airline, even though now I regret it.\n",
      "----\n",
      "\n",
      "\n",
      "\"used to\" should reduce\n",
      "Test cases:      4368\n",
      "Test cases run:  500\n",
      "After filtering: 6 (1.2%)\n",
      "Fails (rate):    3 (50.0%)\n",
      "\n",
      "Example fails:\n",
      "0.7 0.0 0.3 it was a creepy service.\n",
      "1.0 0.0 0.0 I used to think it was a creepy service.\n",
      "\n",
      "----\n",
      "0.8 0.0 0.2 it was a creepy cabin crew.\n",
      "1.0 0.0 0.0 I used to think it was a creepy cabin crew.\n",
      "\n",
      "----\n",
      "0.8 0.0 0.2 this was a weird flight.\n",
      "1.0 0.0 0.0 I used to think this was a weird flight.\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Negation\n",
      "\n",
      "simple negations: negative\n",
      "Test cases:      6318\n",
      "Test cases run:  500\n",
      "Fails (rate):    23 (4.6%)\n",
      "\n",
      "Example fails:\n",
      "0.0 0.0 1.0 I would never say I love that food.\n",
      "----\n",
      "0.0 0.0 1.0 I can't say I admire that company.\n",
      "----\n",
      "0.0 0.0 1.0 I would never say I admire that cabin crew.\n",
      "----\n",
      "\n",
      "\n",
      "simple negations: not negative\n",
      "Test cases:      6786\n",
      "Test cases run:  500\n",
      "Fails (rate):    64 (12.8%)\n",
      "\n",
      "Example fails:\n",
      "1.0 0.0 0.0 That was not an average seat.\n",
      "----\n",
      "0.9 0.0 0.1 That staff isn't average.\n",
      "----\n",
      "0.9 0.0 0.1 That wasn't a lousy aircraft.\n",
      "----\n",
      "\n",
      "\n",
      "simple negations: not neutral is still neutral\n",
      "Test cases:      2496\n",
      "Test cases run:  500\n",
      "Fails (rate):    487 (97.4%)\n",
      "\n",
      "Example fails:\n",
      "0.9 0.0 0.1 The seat is not American.\n",
      "----\n",
      "1.0 0.0 0.0 The pilot is not international.\n",
      "----\n",
      "1.0 0.0 0.0 That wasn't an Italian food.\n",
      "----\n",
      "\n",
      "\n",
      "simple negations: I thought x was positive, but it was not (should be negative)\n",
      "Test cases:      1992\n",
      "Test cases run:  500\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "simple negations: I thought x was negative, but it was not (should be neutral or positive)\n",
      "Test cases:      2124\n",
      "Test cases run:  500\n",
      "Fails (rate):    500 (100.0%)\n",
      "\n",
      "Example fails:\n",
      "1.0 0.0 0.0 I thought that plane would be horrible, but it was not.\n",
      "----\n",
      "1.0 0.0 0.0 I thought that flight would be lousy, but it was not.\n",
      "----\n",
      "1.0 0.0 0.0 I thought this staff would be average, but it was not.\n",
      "----\n",
      "\n",
      "\n",
      "simple negations: but it was not (neutral) should still be neutral\n",
      "Test cases:      804\n",
      "Test cases run:  500\n",
      "Fails (rate):    500 (100.0%)\n",
      "\n",
      "Example fails:\n",
      "1.0 0.0 0.0 I thought that seat would be American, but it was not.\n",
      "----\n",
      "1.0 0.0 0.0 I thought I would see that company, but I didn't.\n",
      "----\n",
      "1.0 0.0 0.0 I thought this flight would be Indian, but it was not.\n",
      "----\n",
      "\n",
      "\n",
      "Hard: Negation of positive with neutral stuff in the middle (should be negative)\n",
      "Test cases:      1000\n",
      "Test cases run:  500\n",
      "Fails (rate):    434 (86.8%)\n",
      "\n",
      "Example fails:\n",
      "0.0 0.9 0.1 I don't think, given my history with airplanes, that that is an incredible airline.\n",
      "----\n",
      "0.0 0.0 1.0 I wouldn't say, given that I am from Brazil, that this is a wonderful customer service.\n",
      "----\n",
      "0.0 0.0 1.0 I don't think, given the time that I've been flying, that this was an awesome flight.\n",
      "----\n",
      "\n",
      "\n",
      "Hard: Negation of negative with neutral stuff in the middle (should be positive or neutral)\n",
      "Test cases:      1000\n",
      "Test cases run:  500\n",
      "Fails (rate):    497 (99.4%)\n",
      "\n",
      "Example fails:\n",
      "1.0 0.0 0.0 I don't think, given that I am from Brazil, that this plane is terrible.\n",
      "----\n",
      "1.0 0.0 0.0 i don't think, given it's a Tuesday, that we dislike that cabin crew.\n",
      "----\n",
      "1.0 0.0 0.0 i wouldn't say, given all that I've seen over the years, that I hate the plane.\n",
      "----\n",
      "\n",
      "\n",
      "negation of neutral with neutral in the middle, should still neutral\n",
      "Test cases:      1000\n",
      "Test cases run:  500\n",
      "Fails (rate):    477 (95.4%)\n",
      "\n",
      "Example fails:\n",
      "1.0 0.0 0.0 I wouldn't say, given the time that I've been flying, that the was an Indian cabin crew.\n",
      "----\n",
      "1.0 0.0 0.0 I don't think, given that I am from Brazil, that that company is Italian.\n",
      "----\n",
      "1.0 0.0 0.0 I wouldn't say, given my history with airplanes, that that is an Israeli cabin crew.\n",
      "----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "SRL\n",
      "\n",
      "my opinion is what matters\n",
      "Test cases:      8528\n",
      "Test cases run:  500\n",
      "Fails (rate):    221 (44.2%)\n",
      "\n",
      "Example fails:\n",
      "0.0 0.0 1.0 I think you are horrible, but some people think you are extraordinary.\n",
      "----\n",
      "0.0 0.0 1.0 I think you are sad, some people think you are brilliant.\n",
      "----\n",
      "0.0 0.0 1.0 I think you are frustrating, but some people think you are amazing.\n",
      "----\n",
      "\n",
      "\n",
      "Q & A: yes\n",
      "Test cases:      7644\n",
      "Test cases run:  500\n",
      "Fails (rate):    4 (0.8%)\n",
      "\n",
      "Example fails:\n",
      "0.9 0.0 0.1 Do I think that was a nice aircraft? Yes\n",
      "----\n",
      "0.9 0.0 0.1 Do I think that aircraft was nice? Yes\n",
      "----\n",
      "1.0 0.0 0.0 Do I think that customer service was good? Yes\n",
      "----\n",
      "\n",
      "\n",
      "Q & A: yes (neutral)\n",
      "Test cases:      1560\n",
      "Test cases run:  500\n",
      "Fails (rate):    489 (97.8%)\n",
      "\n",
      "Example fails:\n",
      "1.0 0.0 0.0 Do I think this plane is Italian? Yes\n",
      "----\n",
      "1.0 0.0 0.0 Do I think it was a commercial aircraft? Yes\n",
      "----\n",
      "1.0 0.0 0.0 Do I think this flight was British? Yes\n",
      "----\n",
      "\n",
      "\n",
      "Q & A: no\n",
      "Test cases:      7644\n",
      "Test cases run:  500\n",
      "Fails (rate):    429 (85.8%)\n",
      "\n",
      "Example fails:\n",
      "1.0 0.0 0.0 Do I think the airline is ridiculous? No\n",
      "----\n",
      "1.0 0.0 0.0 Do I think it is a dreadful plane? No\n",
      "----\n",
      "1.0 0.0 0.0 Do I think this company was horrible? No\n",
      "----\n",
      "\n",
      "\n",
      "Q & A: no (neutral)\n",
      "Test cases:      1560\n",
      "Test cases run:  500\n",
      "Fails (rate):    499 (99.8%)\n",
      "\n",
      "Example fails:\n",
      "1.0 0.0 0.0 Do I think this was an Indian crew? No\n",
      "----\n",
      "1.0 0.0 0.0 Do I think this is an Italian staff? No\n",
      "----\n",
      "1.0 0.0 0.0 Do I think the cabin crew is Australian? No\n",
      "----\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "suite.summary() # calls suite.suite.summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slicing tests on nlp.checklist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examples of a certain test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f27acfbf5934a76a1afd6ef8896113f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=88.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "simple = suite.get_test('Sentiment-laden words in context')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I valued the flight.',\n",
       " 'That is a sad customer service.',\n",
       " 'We like the flight.',\n",
       " 'This was a nice crew.',\n",
       " 'We abhor that flight.',\n",
       " 'This staff is difficult.',\n",
       " 'I valued that aircraft.',\n",
       " 'This was a fantastic flight.',\n",
       " 'I hate the food.',\n",
       " 'I despised the food.']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple['tweet'][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering by examples where google fails and hf does not:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "320609934ea14204a2424b9f83e3598f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "google_fails_hf_doesnt = simple.filter(lambda x:x['fail']['hf_pipeline'] == 0 and x['fail']['google'] == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HF:negative GOOGLE:neutral  The crew is average.\n",
      "HF:negative GOOGLE:neutral  It is a hard aircraft.\n",
      "HF:negative GOOGLE:neutral  That is a creepy plane.\n",
      "HF:negative GOOGLE:neutral  That is an ugly cabin crew.\n",
      "HF:negative GOOGLE:neutral  This airline is hard.\n"
     ]
    }
   ],
   "source": [
    "mapz = ['negative', 'neutral', 'positive']\n",
    "for x in np.random.choice(google_fails_hf_doesnt.shape[0], 5):\n",
    "    x = google_fails_hf_doesnt[int(x)]\n",
    "    print('HF:%-8s GOOGLE:%-8s %s' % (mapz[x['hf_pipeline']], mapz[x['google']], x['tweet']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perturbation tests combine multiple examples, so looking at a single row in the dataset would not give us a good picture.  \n",
    "Instead, we want to aggregate each testcase into a row of examples (data goes into the `data` key):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e80c8e0a59004619923ba9918baca8ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=88.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "perturbation = suite.get_test('change locations', aggregate_testcases=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "732e497f901f451ab41549f3413bc53f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "any_fails = lambda x, key: any([y['fail'][key] for y in x['data']])\n",
    "google_fails_hf_doesnt = perturbation.filter(lambda x: not any_fails(x, 'hf_pipeline') and any_fails(x, 'google'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an INV test, so a failure is a change in prediction. Some examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HF:negative GOOGLE:positive @SouthwestAir I can easily get to the Atlanta show, I just need tickets, help?!\n",
      "HF:negative GOOGLE:neutral  @SouthwestAir I can easily get to the Jefferson City show, I just need tickets, help?!\n",
      "\n",
      "HF:positive GOOGLE:neutral  @SouthwestAir how can customers get in touch with you internationally from Mexico for lost baggage\n",
      "HF:positive GOOGLE:positive @SouthwestAir how can customers get in touch with you internationally from Colombia for lost baggage\n",
      "\n",
      "HF:positive GOOGLE:neutral  @SouthwestAir Denver to Phoenix, I think we're finally getting ready to take off.\n",
      "HF:positive GOOGLE:positive @SouthwestAir Denver to Buena Park, I think we're finally getting ready to take off.\n",
      "\n",
      "HF:negative GOOGLE:negative .@united Nope - had to rebook through Houston so I could get to Amarillo before 11pm. Stuck in SFO for four hours.\n",
      "HF:negative GOOGLE:neutral  .@united Nope - had to rebook through Bell Gardens so I could get to Amarillo before 11pm. Stuck in SFO for four hours.\n",
      "\n",
      "HF:positive GOOGLE:positive @USAirways sitting on a plane in Philadelphia for over 20 minutes waiting just to get off the plane. Great service!\n",
      "HF:positive GOOGLE:neutral  @USAirways sitting on a plane in Surprise for over 20 minutes waiting just to get off the plane. Great service!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mapz = ['negative', 'neutral', 'positive']\n",
    "for x in np.random.choice(google_fails_hf_doesnt.shape[0], 5):\n",
    "    x = google_fails_hf_doesnt[int(x)]\n",
    "    orig = x['data'][0]\n",
    "    fail = [y for y in x['data'] if y['fail']['google']][0]\n",
    "    print('HF:%-8s GOOGLE:%-8s %s' % (mapz[orig['hf_pipeline']], mapz[orig['google']], orig['tweet']))\n",
    "    print('HF:%-8s GOOGLE:%-8s %s' % (mapz[fail['hf_pipeline']], mapz[fail['google']], fail['tweet']))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQuAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "suite_path = '/home/marcotcr/work/checklist/release_data/squad/squad_suite.pkl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examples in this suite are tuples of (context, question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "suite = cl.CheckListSuite(suite_path, lambda x: {'context': x[0], 'question': x[1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_preds = open('/home/marcotcr/work/checklist/release_data/squad/predictions/bert').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75773d2b4c3c4ce88069c5f29b70aff0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=71293.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "suite.dataset = suite.dataset.map(lambda _, idx: {'bert': bert_preds[idx]}, with_indices=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These tests don't really require confidence scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f111b62a0d34187a424d26741564219",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=71293.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "suite.compute('bert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "checklist_table3 = [\n",
    "    'A is COMP than B. Who is more / less COMP?',\n",
    "    'Intensifiers (very, super, extremely) and reducers (somewhat, kinda, etc)?',\n",
    "    'size, shape, age, color',\n",
    "    'Profession vs nationality',\n",
    "    'Animal vs Vehicle v2',\n",
    "    'A is COMP than B. Who is antonym(COMP)? B',\n",
    "    'A is more X than B. Who is more antonym(X)? B. Who is less X? B. Who is more X? A. Who is less antonym(X)? A.',\n",
    "    'Question typo',\n",
    "    'Add random sentence to context',\n",
    "    'There was a change in profession',\n",
    "    'Understanding before / after -> first / last.',\n",
    "    'Negation in context, may or may not be in question',\n",
    "    'Negation in question only.', 'M/F failure rates should be similar for different professions',\n",
    "    'Basic coref, he / she',\n",
    "    'Basic coref, his / her',\n",
    "    'Former / Latter',\n",
    "    'Agent / object distinction',\n",
    "    'Agent / object distinction with 3 agents'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20.0 A is COMP than B. Who is more / less COMP?\n",
      " 91.3 Intensifiers (very, super, extremely) and reducers (somewhat, kinda, etc)?\n",
      " 82.4 size, shape, age, color\n",
      " 49.4 Profession vs nationality\n",
      " 26.2 Animal vs Vehicle v2\n",
      " 67.3 A is COMP than B. Who is antonym(COMP)? B\n",
      "100.0 A is more X than B. Who is more antonym(X)? B. Who is less X? B. Who is more X? A. Who is less antonym(X)? A.\n",
      " 11.6 Question typo\n",
      "  9.8 Add random sentence to context\n",
      " 41.5 There was a change in profession\n",
      " 82.9 Understanding before / after -> first / last.\n",
      " 67.5 Negation in context, may or may not be in question\n",
      "100.0 Negation in question only.\n",
      " 46.2 M/F failure rates should be similar for different professions\n",
      "100.0 Basic coref, he / she\n",
      " 91.8 Basic coref, his / her\n",
      "100.0 Former / Latter\n",
      " 60.8 Agent / object distinction\n",
      " 95.7 Agent / object distinction with 3 agents\n"
     ]
    }
   ],
   "source": [
    "for t in checklist_table3:\n",
    "    print('%5.1f %s' % (suite.fail_rate['bert'][t], t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Put some data into `suite.dataset.info`, so people know what the predictions and confidences should look like (e.g. [0, 1, 2] for sentiment, or string for SQuAD)\n",
    "- Warn people that CheckList suites contained pickled functions, which may not be safe\n",
    "- Write some documentation for `nlp.checklist`\n",
    "- Clean up code for `nlp.checklist`, include typing, etc\n",
    "- Write up a better example notebook.\n",
    "- Figure out how to host checklists\n",
    "- Improve checklist browsing (small change over nlp.dataset browsing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "checklist",
   "language": "python",
   "name": "checklist"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
