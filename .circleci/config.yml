version: 2.1

orbs:
    win: circleci/windows@2.2.0

jobs:
    run_dataset_script_tests_pyarrow_0p17:
        working_directory: ~/datasets
        docker:
            - image: circleci/python:3.6
        resource_class: medium
        steps:
            - checkout
            - run: python -m venv venv
            - run: source venv/bin/activate
            - run: pip install .[tests]
            - run: pip install pyarrow==0.17.1
            - run: HF_SCRIPTS_VERSION=master python -m pytest -sv ./tests/

    run_dataset_script_tests_pyarrow_1:
        working_directory: ~/datasets
        docker:
            - image: circleci/python:3.6
        resource_class: medium
        steps:
            - checkout
            - run: python -m venv venv
            - run: source venv/bin/activate
            - run: pip install .[tests]
            - run: pip install pyarrow==1.0.0
            - run: HF_SCRIPTS_VERSION=master python -m pytest -sv ./tests/


    run_dataset_script_tests_pyarrow_0p17_WIN:
        working_directory: ~/datasets
        executor:
            name: win/default
            shell: powershell
        steps:
            - checkout
            - run: conda install python=3.6 --yes
            - run: conda install pytorch --yes
            - run: pip install virtualenv
            - run: python -m virtualenv venv --system-site-packages
            - run: "& venv/Scripts/activate.ps1"
            - run: pip install .[tests]
            - run: pip install pyarrow==0.17.1
            - run: $env:HF_SCRIPTS_VERSION="master"
            - run: python -m pytest -sv ./tests/

    run_dataset_script_tests_pyarrow_1_WIN:
        working_directory: ~/datasets
        executor:
            name: win/default
            shell: powershell
        steps:
            - checkout
            - run: conda install python=3.6 --yes
            - run: conda install pytorch --yes
            - run: pip install virtualenv
            - run: python -m virtualenv venv --system-site-packages
            - run: "& venv/Scripts/activate.ps1"
            - run: pip install .[tests]
            - run: pip install pyarrow==1.0.0
            - run: $env:HF_SCRIPTS_VERSION="master"
            - run: python -m pytest -sv ./tests/

    check_code_quality:
        working_directory: ~/datasets
        docker:
            - image: circleci/python:3.6
        resource_class: medium
        parallelism: 1
        steps:
            - checkout
            - run: sudo pip install .[quality]
            - run: black --check --line-length 119 --target-version py36 tests src benchmarks datasets metrics
            - run: isort --check-only tests src benchmarks datasets metrics
            - run: flake8 tests src benchmarks datasets metrics

    build_doc:
        working_directory: ~/datasets
        docker:
            - image: circleci/python:3.6
        steps:
            - checkout
            - run: sudo pip install .[docs]
            - run: cd docs && make html SPHINXOPTS="-W"
            - store_artifacts:
                  path: ./docs/_build

    deploy_doc:
        working_directory: ~/datasets
        docker:
            - image: circleci/python:3.6
        steps:
            - add_ssh_keys:
                fingerprints:
                    - "5b:7a:95:18:07:8c:aa:76:4c:60:35:88:ad:60:56:71"
            - checkout
            - run: sudo pip install .[docs]
            - run: ./.circleci/deploy.sh

workflow_filters: &workflow_filters
    filters:
        branches:
            only:
                - master

workflows:
    version: 2
    build_and_test:
        jobs:
            - check_code_quality
            - run_dataset_script_tests_pyarrow_0p17
            - run_dataset_script_tests_pyarrow_1
            - run_dataset_script_tests_pyarrow_0p17_WIN
            - run_dataset_script_tests_pyarrow_1_WIN
            - build_doc
            - deploy_doc: *workflow_filters
