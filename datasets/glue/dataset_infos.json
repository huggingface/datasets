{
    "cola": {
        "description": "GLUE, the General Language Understanding Evaluation benchmark\n(https://gluebenchmark.com/) is a collection of resources for training,\nevaluating, and analyzing natural language understanding systems.\n\n",
        "citation": "@article{warstadt2018neural,\n  title={Neural Network Acceptability Judgments},\n  author={Warstadt, Alex and Singh, Amanpreet and Bowman, Samuel R},\n  journal={arXiv preprint arXiv:1805.12471},\n  year={2018}\n}\n@inproceedings{wang2019glue,\n  title={{GLUE}: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding},\n  author={Wang, Alex and Singh, Amanpreet and Michael, Julian and Hill, Felix and Levy, Omer and Bowman, Samuel R.},\n  note={In the Proceedings of ICLR.},\n  year={2019}\n}\n\nNote that each GLUE dataset has its own citation. Please see the source to see\nthe correct citation for each contained dataset.",
        "homepage": "https://nyu-mll.github.io/CoLA/",
        "license": "",
        "features": {
            "sentence": {
                "dtype": "string",
                "id": null,
                "_type": "Value"
            },
            "label": {
                "num_classes": 2,
                "names": [
                    "unacceptable",
                    "acceptable"
                ],
                "names_file": null,
                "id": null,
                "_type": "ClassLabel"
            },
            "idx": {
                "dtype": "int32",
                "id": null,
                "_type": "Value"
            }
        },
        "post_processed": null,
        "supervised_keys": null,
        "builder_name": "glue",
        "config_name": "cola",
        "version": {
            "version_str": "1.0.0",
            "description": "",
            "major": 1,
            "minor": 0,
            "patch": 0
        },
        "splits": {
            "test": {
                "name": "test",
                "num_bytes": 61049,
                "num_examples": 1063,
                "dataset_name": "glue"
            },
            "train": {
                "name": "train",
                "num_bytes": 489149,
                "num_examples": 8551,
                "dataset_name": "glue"
            },
            "validation": {
                "name": "validation",
                "num_bytes": 60850,
                "num_examples": 1043,
                "dataset_name": "glue"
            }
        },
        "download_checksums": {
            "https://dl.fbaipublicfiles.com/glue/data/CoLA.zip": {
                "num_bytes": 376971,
                "checksum": "f212fcd832b8f7b435fb991f101abf89f96b933ab400603bf198960dfc32cbff"
            }
        },
        "download_size": 376971,
        "post_processing_size": null,
        "dataset_size": 611048,
        "size_in_bytes": 988019
    },
    "sst2": {
        "description": "GLUE, the General Language Understanding Evaluation benchmark\n(https://gluebenchmark.com/) is a collection of resources for training,\nevaluating, and analyzing natural language understanding systems.\n\n",
        "citation": "@inproceedings{socher2013recursive,\n  title={Recursive deep models for semantic compositionality over a sentiment treebank},\n  author={Socher, Richard and Perelygin, Alex and Wu, Jean and Chuang, Jason and Manning, Christopher D and Ng, Andrew and Potts, Christopher},\n  booktitle={Proceedings of the 2013 conference on empirical methods in natural language processing},\n  pages={1631--1642},\n  year={2013}\n}\n@inproceedings{wang2019glue,\n  title={{GLUE}: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding},\n  author={Wang, Alex and Singh, Amanpreet and Michael, Julian and Hill, Felix and Levy, Omer and Bowman, Samuel R.},\n  note={In the Proceedings of ICLR.},\n  year={2019}\n}\n\nNote that each GLUE dataset has its own citation. Please see the source to see\nthe correct citation for each contained dataset.",
        "homepage": "https://nlp.stanford.edu/sentiment/index.html",
        "license": "",
        "features": {
            "sentence": {
                "dtype": "string",
                "id": null,
                "_type": "Value"
            },
            "label": {
                "num_classes": 2,
                "names": [
                    "negative",
                    "positive"
                ],
                "names_file": null,
                "id": null,
                "_type": "ClassLabel"
            },
            "idx": {
                "dtype": "int32",
                "id": null,
                "_type": "Value"
            }
        },
        "post_processed": null,
        "supervised_keys": null,
        "builder_name": "glue",
        "config_name": "sst2",
        "version": {
            "version_str": "1.0.0",
            "description": "",
            "major": 1,
            "minor": 0,
            "patch": 0
        },
        "splits": {
            "test": {
                "name": "test",
                "num_bytes": 217556,
                "num_examples": 1821,
                "dataset_name": "glue"
            },
            "train": {
                "name": "train",
                "num_bytes": 4715283,
                "num_examples": 67349,
                "dataset_name": "glue"
            },
            "validation": {
                "name": "validation",
                "num_bytes": 106692,
                "num_examples": 872,
                "dataset_name": "glue"
            }
        },
        "download_checksums": {
            "https://dl.fbaipublicfiles.com/glue/data/SST-2.zip": {
                "num_bytes": 7439277,
                "checksum": "d67e16fb55739c1b32cdce9877596db1c127dc322d93c082281f64057c16deaa"
            }
        },
        "download_size": 7439277,
        "post_processing_size": null,
        "dataset_size": 5039531,
        "size_in_bytes": 12478808
    },
    "mrpc": {
        "description": "GLUE, the General Language Understanding Evaluation benchmark\n(https://gluebenchmark.com/) is a collection of resources for training,\nevaluating, and analyzing natural language understanding systems.\n\n",
        "citation": "@inproceedings{dolan2005automatically,\n  title={Automatically constructing a corpus of sentential paraphrases},\n  author={Dolan, William B and Brockett, Chris},\n  booktitle={Proceedings of the Third International Workshop on Paraphrasing (IWP2005)},\n  year={2005}\n}\n@inproceedings{wang2019glue,\n  title={{GLUE}: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding},\n  author={Wang, Alex and Singh, Amanpreet and Michael, Julian and Hill, Felix and Levy, Omer and Bowman, Samuel R.},\n  note={In the Proceedings of ICLR.},\n  year={2019}\n}\n\nNote that each GLUE dataset has its own citation. Please see the source to see\nthe correct citation for each contained dataset.",
        "homepage": "https://www.microsoft.com/en-us/download/details.aspx?id=52398",
        "license": "",
        "features": {
            "sentence1": {
                "dtype": "string",
                "id": null,
                "_type": "Value"
            },
            "sentence2": {
                "dtype": "string",
                "id": null,
                "_type": "Value"
            },
            "label": {
                "num_classes": 2,
                "names": [
                    "not_equivalent",
                    "equivalent"
                ],
                "names_file": null,
                "id": null,
                "_type": "ClassLabel"
            },
            "idx": {
                "dtype": "int32",
                "id": null,
                "_type": "Value"
            }
        },
        "post_processed": null,
        "supervised_keys": null,
        "builder_name": "glue",
        "config_name": "mrpc",
        "version": {
            "version_str": "1.0.0",
            "description": "",
            "major": 1,
            "minor": 0,
            "patch": 0
        },
        "splits": {
            "test": {
                "name": "test",
                "num_bytes": 443498,
                "num_examples": 1725,
                "dataset_name": "glue"
            },
            "train": {
                "name": "train",
                "num_bytes": 946146,
                "num_examples": 3668,
                "dataset_name": "glue"
            },
            "validation": {
                "name": "validation",
                "num_bytes": 106142,
                "num_examples": 408,
                "dataset_name": "glue"
            }
        },
        "download_checksums": {
            "https://dl.fbaipublicfiles.com/glue/data/mrpc_dev_ids.tsv": {
                "num_bytes": 6222,
                "checksum": "971d7767d81b997fd9060ade0ec23c4fc31cbb226a55d1bd4a1bac474eb81dc7"
            },
            "https://dl.fbaipublicfiles.com/senteval/senteval_data/msr_paraphrase_train.txt": {
                "num_bytes": 1047044,
                "checksum": "60a9b09084528f0673eedee2b69cb941920f0b8cd0eeccefc464a98768457f89"
            },
            "https://dl.fbaipublicfiles.com/senteval/senteval_data/msr_paraphrase_test.txt": {
                "num_bytes": 441275,
                "checksum": "a04e271090879aaba6423d65b94950c089298587d9c084bf9cd7439bd785f784"
            }
        },
        "download_size": 1494541,
        "post_processing_size": null,
        "dataset_size": 1495786,
        "size_in_bytes": 2990327
    },
    "qqp": {
        "description": "GLUE, the General Language Understanding Evaluation benchmark\n(https://gluebenchmark.com/) is a collection of resources for training,\nevaluating, and analyzing natural language understanding systems.\n\n",
        "citation": "@online{WinNT,\n  author = {Iyer, Shankar and Dandekar, Nikhil and Csernai, Kornel},\n  title = {First Quora Dataset Release: Question Pairs},\n  year = {2017},\n  url = {https://data.quora.com/First-Quora-Dataset-Release-Question-Pairs},\n  urldate = {2019-04-03}\n}\n@inproceedings{wang2019glue,\n  title={{GLUE}: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding},\n  author={Wang, Alex and Singh, Amanpreet and Michael, Julian and Hill, Felix and Levy, Omer and Bowman, Samuel R.},\n  note={In the Proceedings of ICLR.},\n  year={2019}\n}\n",
        "homepage": "https://data.quora.com/First-Quora-Dataset-Release-Question-Pairs",
        "license": "",
        "features": {
            "question1": {
                "dtype": "string",
                "id": null,
                "_type": "Value"
            },
            "question2": {
                "dtype": "string",
                "id": null,
                "_type": "Value"
            },
            "label": {
                "num_classes": 2,
                "names": [
                    "not_duplicate",
                    "duplicate"
                ],
                "names_file": null,
                "id": null,
                "_type": "ClassLabel"
            },
            "idx": {
                "dtype": "int32",
                "id": null,
                "_type": "Value"
            }
        },
        "post_processed": null,
        "supervised_keys": null,
        "builder_name": "glue",
        "config_name": "qqp",
        "version": {
            "version_str": "1.0.0",
            "description": "",
            "major": 1,
            "minor": 0,
            "patch": 0
        },
        "splits": {
            "train": {
                "name": "train",
                "num_bytes": 50901116,
                "num_examples": 363846,
                "dataset_name": "glue"
            },
            "validation": {
                "name": "validation",
                "num_bytes": 5653794,
                "num_examples": 40430,
                "dataset_name": "glue"
            },
            "test": {
                "name": "test",
                "num_bytes": 55171431,
                "num_examples": 390965,
                "dataset_name": "glue"
            }
        },
        "download_checksums": {
            "https://dl.fbaipublicfiles.com/glue/data/QQP-clean.zip": {
                "num_bytes": 41696084,
                "checksum": "40e7c862c04eb26ee04b67fd900e76c45c6ba8e6d8fab4f8f1f8072a1a3fbae0"
            }
        },
        "download_size": 41696084,
        "post_processing_size": null,
        "dataset_size": 111726341,
        "size_in_bytes": 153422425
    },
    "stsb": {
        "description": "GLUE, the General Language Understanding Evaluation benchmark\n(https://gluebenchmark.com/) is a collection of resources for training,\nevaluating, and analyzing natural language understanding systems.\n\n",
        "citation": "@article{cer2017semeval,\n  title={Semeval-2017 task 1: Semantic textual similarity-multilingual and cross-lingual focused evaluation},\n  author={Cer, Daniel and Diab, Mona and Agirre, Eneko and Lopez-Gazpio, Inigo and Specia, Lucia},\n  journal={arXiv preprint arXiv:1708.00055},\n  year={2017}\n}\n@inproceedings{wang2019glue,\n  title={{GLUE}: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding},\n  author={Wang, Alex and Singh, Amanpreet and Michael, Julian and Hill, Felix and Levy, Omer and Bowman, Samuel R.},\n  note={In the Proceedings of ICLR.},\n  year={2019}\n}\n\nNote that each GLUE dataset has its own citation. Please see the source to see\nthe correct citation for each contained dataset.",
        "homepage": "http://ixa2.si.ehu.es/stswiki/index.php/STSbenchmark",
        "license": "",
        "features": {
            "sentence1": {
                "dtype": "string",
                "id": null,
                "_type": "Value"
            },
            "sentence2": {
                "dtype": "string",
                "id": null,
                "_type": "Value"
            },
            "label": {
                "dtype": "float32",
                "id": null,
                "_type": "Value"
            },
            "idx": {
                "dtype": "int32",
                "id": null,
                "_type": "Value"
            }
        },
        "post_processed": null,
        "supervised_keys": null,
        "builder_name": "glue",
        "config_name": "stsb",
        "version": {
            "version_str": "1.0.0",
            "description": "",
            "major": 1,
            "minor": 0,
            "patch": 0
        },
        "splits": {
            "test": {
                "name": "test",
                "num_bytes": 170847,
                "num_examples": 1379,
                "dataset_name": "glue"
            },
            "train": {
                "name": "train",
                "num_bytes": 758394,
                "num_examples": 5749,
                "dataset_name": "glue"
            },
            "validation": {
                "name": "validation",
                "num_bytes": 217012,
                "num_examples": 1500,
                "dataset_name": "glue"
            }
        },
        "download_checksums": {
            "https://dl.fbaipublicfiles.com/glue/data/STS-B.zip": {
                "num_bytes": 802872,
                "checksum": "e60a6393de5a8b5b9bac5020a1554b54e3691f9d600b775bd131e613ac179c85"
            }
        },
        "download_size": 802872,
        "post_processing_size": null,
        "dataset_size": 1146253,
        "size_in_bytes": 1949125
    },
    "mnli": {
        "description": "GLUE, the General Language Understanding Evaluation benchmark\n(https://gluebenchmark.com/) is a collection of resources for training,\nevaluating, and analyzing natural language understanding systems.\n\n",
        "citation": "@InProceedings{N18-1101,\n  author = \"Williams, Adina\n            and Nangia, Nikita\n            and Bowman, Samuel\",\n  title = \"A Broad-Coverage Challenge Corpus for\n           Sentence Understanding through Inference\",\n  booktitle = \"Proceedings of the 2018 Conference of\n               the North American Chapter of the\n               Association for Computational Linguistics:\n               Human Language Technologies, Volume 1 (Long\n               Papers)\",\n  year = \"2018\",\n  publisher = \"Association for Computational Linguistics\",\n  pages = \"1112--1122\",\n  location = \"New Orleans, Louisiana\",\n  url = \"http://aclweb.org/anthology/N18-1101\"\n}\n@article{bowman2015large,\n  title={A large annotated corpus for learning natural language inference},\n  author={Bowman, Samuel R and Angeli, Gabor and Potts, Christopher and Manning, Christopher D},\n  journal={arXiv preprint arXiv:1508.05326},\n  year={2015}\n}\n@inproceedings{wang2019glue,\n  title={{GLUE}: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding},\n  author={Wang, Alex and Singh, Amanpreet and Michael, Julian and Hill, Felix and Levy, Omer and Bowman, Samuel R.},\n  note={In the Proceedings of ICLR.},\n  year={2019}\n}\n\nNote that each GLUE dataset has its own citation. Please see the source to see\nthe correct citation for each contained dataset.",
        "homepage": "http://www.nyu.edu/projects/bowman/multinli/",
        "license": "",
        "features": {
            "premise": {
                "dtype": "string",
                "id": null,
                "_type": "Value"
            },
            "hypothesis": {
                "dtype": "string",
                "id": null,
                "_type": "Value"
            },
            "label": {
                "num_classes": 3,
                "names": [
                    "entailment",
                    "neutral",
                    "contradiction"
                ],
                "names_file": null,
                "id": null,
                "_type": "ClassLabel"
            },
            "idx": {
                "dtype": "int32",
                "id": null,
                "_type": "Value"
            }
        },
        "post_processed": null,
        "supervised_keys": null,
        "builder_name": "glue",
        "config_name": "mnli",
        "version": {
            "version_str": "1.0.0",
            "description": "",
            "major": 1,
            "minor": 0,
            "patch": 0
        },
        "splits": {
            "test_matched": {
                "name": "test_matched",
                "num_bytes": 1854787,
                "num_examples": 9796,
                "dataset_name": "glue"
            },
            "test_mismatched": {
                "name": "test_mismatched",
                "num_bytes": 1956866,
                "num_examples": 9847,
                "dataset_name": "glue"
            },
            "train": {
                "name": "train",
                "num_bytes": 74865118,
                "num_examples": 392702,
                "dataset_name": "glue"
            },
            "validation_matched": {
                "name": "validation_matched",
                "num_bytes": 1839926,
                "num_examples": 9815,
                "dataset_name": "glue"
            },
            "validation_mismatched": {
                "name": "validation_mismatched",
                "num_bytes": 1955384,
                "num_examples": 9832,
                "dataset_name": "glue"
            }
        },
        "download_checksums": {
            "https://dl.fbaipublicfiles.com/glue/data/MNLI.zip": {
                "num_bytes": 312783507,
                "checksum": "e7c1d896d26ed6caf700110645df426cc2d8ebf02a5ab743d5a5c68ac1c83633"
            }
        },
        "download_size": 312783507,
        "post_processing_size": null,
        "dataset_size": 82472081,
        "size_in_bytes": 395255588
    },
    "mnli_mismatched": {
        "description": "GLUE, the General Language Understanding Evaluation benchmark\n(https://gluebenchmark.com/) is a collection of resources for training,\nevaluating, and analyzing natural language understanding systems.\n\n",
        "citation": "@InProceedings{N18-1101,\n  author = \"Williams, Adina\n            and Nangia, Nikita\n            and Bowman, Samuel\",\n  title = \"A Broad-Coverage Challenge Corpus for\n           Sentence Understanding through Inference\",\n  booktitle = \"Proceedings of the 2018 Conference of\n               the North American Chapter of the\n               Association for Computational Linguistics:\n               Human Language Technologies, Volume 1 (Long\n               Papers)\",\n  year = \"2018\",\n  publisher = \"Association for Computational Linguistics\",\n  pages = \"1112--1122\",\n  location = \"New Orleans, Louisiana\",\n  url = \"http://aclweb.org/anthology/N18-1101\"\n}\n@article{bowman2015large,\n  title={A large annotated corpus for learning natural language inference},\n  author={Bowman, Samuel R and Angeli, Gabor and Potts, Christopher and Manning, Christopher D},\n  journal={arXiv preprint arXiv:1508.05326},\n  year={2015}\n}\n@inproceedings{wang2019glue,\n  title={{GLUE}: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding},\n  author={Wang, Alex and Singh, Amanpreet and Michael, Julian and Hill, Felix and Levy, Omer and Bowman, Samuel R.},\n  note={In the Proceedings of ICLR.},\n  year={2019}\n}\n\nNote that each GLUE dataset has its own citation. Please see the source to see\nthe correct citation for each contained dataset.",
        "homepage": "http://www.nyu.edu/projects/bowman/multinli/",
        "license": "",
        "features": {
            "premise": {
                "dtype": "string",
                "id": null,
                "_type": "Value"
            },
            "hypothesis": {
                "dtype": "string",
                "id": null,
                "_type": "Value"
            },
            "label": {
                "num_classes": 3,
                "names": [
                    "entailment",
                    "neutral",
                    "contradiction"
                ],
                "names_file": null,
                "id": null,
                "_type": "ClassLabel"
            },
            "idx": {
                "dtype": "int32",
                "id": null,
                "_type": "Value"
            }
        },
        "post_processed": null,
        "supervised_keys": null,
        "builder_name": "glue",
        "config_name": "mnli_mismatched",
        "version": {
            "version_str": "1.0.0",
            "description": "",
            "major": 1,
            "minor": 0,
            "patch": 0
        },
        "splits": {
            "test": {
                "name": "test",
                "num_bytes": 1956866,
                "num_examples": 9847,
                "dataset_name": "glue"
            },
            "validation": {
                "name": "validation",
                "num_bytes": 1955384,
                "num_examples": 9832,
                "dataset_name": "glue"
            }
        },
        "download_checksums": {
            "https://dl.fbaipublicfiles.com/glue/data/MNLI.zip": {
                "num_bytes": 312783507,
                "checksum": "e7c1d896d26ed6caf700110645df426cc2d8ebf02a5ab743d5a5c68ac1c83633"
            }
        },
        "download_size": 312783507,
        "post_processing_size": null,
        "dataset_size": 3912250,
        "size_in_bytes": 316695757
    },
    "mnli_matched": {
        "description": "GLUE, the General Language Understanding Evaluation benchmark\n(https://gluebenchmark.com/) is a collection of resources for training,\nevaluating, and analyzing natural language understanding systems.\n\n",
        "citation": "@InProceedings{N18-1101,\n  author = \"Williams, Adina\n            and Nangia, Nikita\n            and Bowman, Samuel\",\n  title = \"A Broad-Coverage Challenge Corpus for\n           Sentence Understanding through Inference\",\n  booktitle = \"Proceedings of the 2018 Conference of\n               the North American Chapter of the\n               Association for Computational Linguistics:\n               Human Language Technologies, Volume 1 (Long\n               Papers)\",\n  year = \"2018\",\n  publisher = \"Association for Computational Linguistics\",\n  pages = \"1112--1122\",\n  location = \"New Orleans, Louisiana\",\n  url = \"http://aclweb.org/anthology/N18-1101\"\n}\n@article{bowman2015large,\n  title={A large annotated corpus for learning natural language inference},\n  author={Bowman, Samuel R and Angeli, Gabor and Potts, Christopher and Manning, Christopher D},\n  journal={arXiv preprint arXiv:1508.05326},\n  year={2015}\n}\n@inproceedings{wang2019glue,\n  title={{GLUE}: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding},\n  author={Wang, Alex and Singh, Amanpreet and Michael, Julian and Hill, Felix and Levy, Omer and Bowman, Samuel R.},\n  note={In the Proceedings of ICLR.},\n  year={2019}\n}\n\nNote that each GLUE dataset has its own citation. Please see the source to see\nthe correct citation for each contained dataset.",
        "homepage": "http://www.nyu.edu/projects/bowman/multinli/",
        "license": "",
        "features": {
            "premise": {
                "dtype": "string",
                "id": null,
                "_type": "Value"
            },
            "hypothesis": {
                "dtype": "string",
                "id": null,
                "_type": "Value"
            },
            "label": {
                "num_classes": 3,
                "names": [
                    "entailment",
                    "neutral",
                    "contradiction"
                ],
                "names_file": null,
                "id": null,
                "_type": "ClassLabel"
            },
            "idx": {
                "dtype": "int32",
                "id": null,
                "_type": "Value"
            }
        },
        "post_processed": null,
        "supervised_keys": null,
        "builder_name": "glue",
        "config_name": "mnli_matched",
        "version": {
            "version_str": "1.0.0",
            "description": "",
            "major": 1,
            "minor": 0,
            "patch": 0
        },
        "splits": {
            "test": {
                "name": "test",
                "num_bytes": 1854787,
                "num_examples": 9796,
                "dataset_name": "glue"
            },
            "validation": {
                "name": "validation",
                "num_bytes": 1839926,
                "num_examples": 9815,
                "dataset_name": "glue"
            }
        },
        "download_checksums": {
            "https://dl.fbaipublicfiles.com/glue/data/MNLI.zip": {
                "num_bytes": 312783507,
                "checksum": "e7c1d896d26ed6caf700110645df426cc2d8ebf02a5ab743d5a5c68ac1c83633"
            }
        },
        "download_size": 312783507,
        "post_processing_size": null,
        "dataset_size": 3694713,
        "size_in_bytes": 316478220
    },
    "qnli": {
        "description": "GLUE, the General Language Understanding Evaluation benchmark\n(https://gluebenchmark.com/) is a collection of resources for training,\nevaluating, and analyzing natural language understanding systems.\n\n",
        "citation": "@article{rajpurkar2016squad,\n  title={Squad: 100,000+ questions for machine comprehension of text},\n  author={Rajpurkar, Pranav and Zhang, Jian and Lopyrev, Konstantin and Liang, Percy},\n  journal={arXiv preprint arXiv:1606.05250},\n  year={2016}\n}\n@inproceedings{wang2019glue,\n  title={{GLUE}: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding},\n  author={Wang, Alex and Singh, Amanpreet and Michael, Julian and Hill, Felix and Levy, Omer and Bowman, Samuel R.},\n  note={In the Proceedings of ICLR.},\n  year={2019}\n}\n\nNote that each GLUE dataset has its own citation. Please see the source to see\nthe correct citation for each contained dataset.",
        "homepage": "https://rajpurkar.github.io/SQuAD-explorer/",
        "license": "",
        "features": {
            "question": {
                "dtype": "string",
                "id": null,
                "_type": "Value"
            },
            "sentence": {
                "dtype": "string",
                "id": null,
                "_type": "Value"
            },
            "label": {
                "num_classes": 2,
                "names": [
                    "entailment",
                    "not_entailment"
                ],
                "names_file": null,
                "id": null,
                "_type": "ClassLabel"
            },
            "idx": {
                "dtype": "int32",
                "id": null,
                "_type": "Value"
            }
        },
        "post_processed": null,
        "supervised_keys": null,
        "builder_name": "glue",
        "config_name": "qnli",
        "version": {
            "version_str": "1.0.0",
            "description": "",
            "major": 1,
            "minor": 0,
            "patch": 0
        },
        "splits": {
            "test": {
                "name": "test",
                "num_bytes": 1376516,
                "num_examples": 5463,
                "dataset_name": "glue"
            },
            "train": {
                "name": "train",
                "num_bytes": 25677924,
                "num_examples": 104743,
                "dataset_name": "glue"
            },
            "validation": {
                "name": "validation",
                "num_bytes": 1371727,
                "num_examples": 5463,
                "dataset_name": "glue"
            }
        },
        "download_checksums": {
            "https://dl.fbaipublicfiles.com/glue/data/QNLIv2.zip": {
                "num_bytes": 10627589,
                "checksum": "e634e78627a29adaecd4f955359b22bf5e70f2cbd93b493f2d624138a0c0e5f5"
            }
        },
        "download_size": 10627589,
        "post_processing_size": null,
        "dataset_size": 28426167,
        "size_in_bytes": 39053756
    },
    "rte": {
        "description": "GLUE, the General Language Understanding Evaluation benchmark\n(https://gluebenchmark.com/) is a collection of resources for training,\nevaluating, and analyzing natural language understanding systems.\n\n",
        "citation": "@inproceedings{dagan2005pascal,\n  title={The PASCAL recognising textual entailment challenge},\n  author={Dagan, Ido and Glickman, Oren and Magnini, Bernardo},\n  booktitle={Machine Learning Challenges Workshop},\n  pages={177--190},\n  year={2005},\n  organization={Springer}\n}\n@inproceedings{bar2006second,\n  title={The second pascal recognising textual entailment challenge},\n  author={Bar-Haim, Roy and Dagan, Ido and Dolan, Bill and Ferro, Lisa and Giampiccolo, Danilo and Magnini, Bernardo and Szpektor, Idan},\n  booktitle={Proceedings of the second PASCAL challenges workshop on recognising textual entailment},\n  volume={6},\n  number={1},\n  pages={6--4},\n  year={2006},\n  organization={Venice}\n}\n@inproceedings{giampiccolo2007third,\n  title={The third pascal recognizing textual entailment challenge},\n  author={Giampiccolo, Danilo and Magnini, Bernardo and Dagan, Ido and Dolan, Bill},\n  booktitle={Proceedings of the ACL-PASCAL workshop on textual entailment and paraphrasing},\n  pages={1--9},\n  year={2007},\n  organization={Association for Computational Linguistics}\n}\n@inproceedings{bentivogli2009fifth,\n  title={The Fifth PASCAL Recognizing Textual Entailment Challenge.},\n  author={Bentivogli, Luisa and Clark, Peter and Dagan, Ido and Giampiccolo, Danilo},\n  booktitle={TAC},\n  year={2009}\n}\n@inproceedings{wang2019glue,\n  title={{GLUE}: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding},\n  author={Wang, Alex and Singh, Amanpreet and Michael, Julian and Hill, Felix and Levy, Omer and Bowman, Samuel R.},\n  note={In the Proceedings of ICLR.},\n  year={2019}\n}\n\nNote that each GLUE dataset has its own citation. Please see the source to see\nthe correct citation for each contained dataset.",
        "homepage": "https://aclweb.org/aclwiki/Recognizing_Textual_Entailment",
        "license": "",
        "features": {
            "sentence1": {
                "dtype": "string",
                "id": null,
                "_type": "Value"
            },
            "sentence2": {
                "dtype": "string",
                "id": null,
                "_type": "Value"
            },
            "label": {
                "num_classes": 2,
                "names": [
                    "entailment",
                    "not_entailment"
                ],
                "names_file": null,
                "id": null,
                "_type": "ClassLabel"
            },
            "idx": {
                "dtype": "int32",
                "id": null,
                "_type": "Value"
            }
        },
        "post_processed": null,
        "supervised_keys": null,
        "builder_name": "glue",
        "config_name": "rte",
        "version": {
            "version_str": "1.0.0",
            "description": "",
            "major": 1,
            "minor": 0,
            "patch": 0
        },
        "splits": {
            "test": {
                "name": "test",
                "num_bytes": 975936,
                "num_examples": 3000,
                "dataset_name": "glue"
            },
            "train": {
                "name": "train",
                "num_bytes": 848888,
                "num_examples": 2490,
                "dataset_name": "glue"
            },
            "validation": {
                "name": "validation",
                "num_bytes": 90911,
                "num_examples": 277,
                "dataset_name": "glue"
            }
        },
        "download_checksums": {
            "https://dl.fbaipublicfiles.com/glue/data/RTE.zip": {
                "num_bytes": 697150,
                "checksum": "6bf86de103ecd335f3441bd43574d23fef87ecc695977a63b82d5efb206556ee"
            }
        },
        "download_size": 697150,
        "post_processing_size": null,
        "dataset_size": 1915735,
        "size_in_bytes": 2612885
    },
    "wnli": {
        "description": "GLUE, the General Language Understanding Evaluation benchmark\n(https://gluebenchmark.com/) is a collection of resources for training,\nevaluating, and analyzing natural language understanding systems.\n\n",
        "citation": "@inproceedings{levesque2012winograd,\n  title={The winograd schema challenge},\n  author={Levesque, Hector and Davis, Ernest and Morgenstern, Leora},\n  booktitle={Thirteenth International Conference on the Principles of Knowledge Representation and Reasoning},\n  year={2012}\n}\n@inproceedings{wang2019glue,\n  title={{GLUE}: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding},\n  author={Wang, Alex and Singh, Amanpreet and Michael, Julian and Hill, Felix and Levy, Omer and Bowman, Samuel R.},\n  note={In the Proceedings of ICLR.},\n  year={2019}\n}\n\nNote that each GLUE dataset has its own citation. Please see the source to see\nthe correct citation for each contained dataset.",
        "homepage": "https://cs.nyu.edu/faculty/davise/papers/WinogradSchemas/WS.html",
        "license": "",
        "features": {
            "sentence1": {
                "dtype": "string",
                "id": null,
                "_type": "Value"
            },
            "sentence2": {
                "dtype": "string",
                "id": null,
                "_type": "Value"
            },
            "label": {
                "num_classes": 2,
                "names": [
                    "not_entailment",
                    "entailment"
                ],
                "names_file": null,
                "id": null,
                "_type": "ClassLabel"
            },
            "idx": {
                "dtype": "int32",
                "id": null,
                "_type": "Value"
            }
        },
        "post_processed": null,
        "supervised_keys": null,
        "builder_name": "glue",
        "config_name": "wnli",
        "version": {
            "version_str": "1.0.0",
            "description": "",
            "major": 1,
            "minor": 0,
            "patch": 0
        },
        "splits": {
            "test": {
                "name": "test",
                "num_bytes": 37992,
                "num_examples": 146,
                "dataset_name": "glue"
            },
            "train": {
                "name": "train",
                "num_bytes": 107517,
                "num_examples": 635,
                "dataset_name": "glue"
            },
            "validation": {
                "name": "validation",
                "num_bytes": 12215,
                "num_examples": 71,
                "dataset_name": "glue"
            }
        },
        "download_checksums": {
            "https://dl.fbaipublicfiles.com/glue/data/WNLI.zip": {
                "num_bytes": 28999,
                "checksum": "ae0e8e4d16f4d46d4a0a566ec7ecceccfd3fbfaa4a7a4b4e02848c0f2561ac46"
            }
        },
        "download_size": 28999,
        "post_processing_size": null,
        "dataset_size": 157724,
        "size_in_bytes": 186723
    },
    "ax": {
        "description": "GLUE, the General Language Understanding Evaluation benchmark\n(https://gluebenchmark.com/) is a collection of resources for training,\nevaluating, and analyzing natural language understanding systems.\n\n",
        "citation": "\n@inproceedings{wang2019glue,\n  title={{GLUE}: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding},\n  author={Wang, Alex and Singh, Amanpreet and Michael, Julian and Hill, Felix and Levy, Omer and Bowman, Samuel R.},\n  note={In the Proceedings of ICLR.},\n  year={2019}\n}\n\nNote that each GLUE dataset has its own citation. Please see the source to see\nthe correct citation for each contained dataset.",
        "homepage": "https://gluebenchmark.com/diagnostics",
        "license": "",
        "features": {
            "premise": {
                "dtype": "string",
                "id": null,
                "_type": "Value"
            },
            "hypothesis": {
                "dtype": "string",
                "id": null,
                "_type": "Value"
            },
            "label": {
                "num_classes": 3,
                "names": [
                    "entailment",
                    "neutral",
                    "contradiction"
                ],
                "names_file": null,
                "id": null,
                "_type": "ClassLabel"
            },
            "idx": {
                "dtype": "int32",
                "id": null,
                "_type": "Value"
            }
        },
        "post_processed": null,
        "supervised_keys": null,
        "builder_name": "glue",
        "config_name": "ax",
        "version": {
            "version_str": "1.0.0",
            "description": "",
            "major": 1,
            "minor": 0,
            "patch": 0
        },
        "splits": {
            "test": {
                "name": "test",
                "num_bytes": 238392,
                "num_examples": 1104,
                "dataset_name": "glue"
            }
        },
        "download_checksums": {
            "https://dl.fbaipublicfiles.com/glue/data/AX.tsv": {
                "num_bytes": 222257,
                "checksum": "0e13510b1bb14436ff7e2ee82338f0efb0133ecf2e73507a697dc210db3f05fd"
            }
        },
        "download_size": 222257,
        "post_processing_size": null,
        "dataset_size": 238392,
        "size_in_bytes": 460649
    }
}