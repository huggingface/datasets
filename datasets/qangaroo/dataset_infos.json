{"medhop": {"description": "  We have created two new Reading Comprehension datasets focussing on multi-hop (alias multi-step) inference.\n\nSeveral pieces of information often jointly imply another fact. In multi-hop inference, a new fact is derived by combining facts via a chain of multiple steps.\n\nOur aim is to build Reading Comprehension methods that perform multi-hop inference on text, where individual facts are spread out across different documents.\n\nThe two QAngaroo datasets provide a training and evaluation resource for such methods.\n", "citation": "\n", "homepage": "http://qangaroo.cs.ucl.ac.uk/index.html", "license": "", "features": {"query": {"dtype": "string", "id": null, "_type": "Value"}, "supports": {"feature": {"support": {"dtype": "string", "id": null, "_type": "Value"}}, "length": -1, "id": null, "_type": "Sequence"}, "candidates": {"feature": {"candidate": {"dtype": "string", "id": null, "_type": "Value"}}, "length": -1, "id": null, "_type": "Sequence"}, "answer": {"dtype": "string", "id": null, "_type": "Value"}, "id": {"dtype": "string", "id": null, "_type": "Value"}}, "supervised_keys": null, "builder_name": "qangaroo", "config_name": "medhop", "version": {"version_str": "1.0.0", "description": "New split API (https://tensorflow.org/datasets/splits)", "nlp_version_to_prepare": null, "major": 1, "minor": 0, "patch": 0}, "splits": {"train": {"name": "train", "num_bytes": 93948131, "num_examples": 1620, "dataset_name": "qangaroo"}, "validation": {"name": "validation", "num_bytes": 16463641, "num_examples": 342, "dataset_name": "qangaroo"}}, "download_checksums": {"https://drive.google.com/uc?export=download&id=1ytVZ4AhubFDOEL7o7XrIRIyhU8g9wvKA": {"num_bytes": 339843061, "checksum": "2f512869760cdad76a022a1465f025b486ae79dc5b8f0bf3ad901a4caf2d3050"}}, "download_size": 339843061, "dataset_size": 110411772, "size_in_bytes": 450254833}, "masked_medhop": {"description": "  We have created two new Reading Comprehension datasets focussing on multi-hop (alias multi-step) inference.\n\nSeveral pieces of information often jointly imply another fact. In multi-hop inference, a new fact is derived by combining facts via a chain of multiple steps.\n\nOur aim is to build Reading Comprehension methods that perform multi-hop inference on text, where individual facts are spread out across different documents.\n\nThe two QAngaroo datasets provide a training and evaluation resource for such methods.\n", "citation": "\n", "homepage": "http://qangaroo.cs.ucl.ac.uk/index.html", "license": "", "features": {"query": {"dtype": "string", "id": null, "_type": "Value"}, "supports": {"feature": {"support": {"dtype": "string", "id": null, "_type": "Value"}}, "length": -1, "id": null, "_type": "Sequence"}, "candidates": {"feature": {"candidate": {"dtype": "string", "id": null, "_type": "Value"}}, "length": -1, "id": null, "_type": "Sequence"}, "answer": {"dtype": "string", "id": null, "_type": "Value"}, "id": {"dtype": "string", "id": null, "_type": "Value"}}, "supervised_keys": null, "builder_name": "qangaroo", "config_name": "masked_medhop", "version": {"version_str": "1.0.0", "description": "New split API (https://tensorflow.org/datasets/splits)", "nlp_version_to_prepare": null, "major": 1, "minor": 0, "patch": 0}, "splits": {"train": {"name": "train", "num_bytes": 95824392, "num_examples": 1620, "dataset_name": "qangaroo"}, "validation": {"name": "validation", "num_bytes": 16802570, "num_examples": 342, "dataset_name": "qangaroo"}}, "download_checksums": {"https://drive.google.com/uc?export=download&id=1ytVZ4AhubFDOEL7o7XrIRIyhU8g9wvKA": {"num_bytes": 339843061, "checksum": "2f512869760cdad76a022a1465f025b486ae79dc5b8f0bf3ad901a4caf2d3050"}}, "download_size": 339843061, "dataset_size": 112626962, "size_in_bytes": 452470023}, "wikihop": {"description": "  We have created two new Reading Comprehension datasets focussing on multi-hop (alias multi-step) inference.\n\nSeveral pieces of information often jointly imply another fact. In multi-hop inference, a new fact is derived by combining facts via a chain of multiple steps.\n\nOur aim is to build Reading Comprehension methods that perform multi-hop inference on text, where individual facts are spread out across different documents.\n\nThe two QAngaroo datasets provide a training and evaluation resource for such methods.\n", "citation": "\n", "homepage": "http://qangaroo.cs.ucl.ac.uk/index.html", "license": "", "features": {"query": {"dtype": "string", "id": null, "_type": "Value"}, "supports": {"feature": {"support": {"dtype": "string", "id": null, "_type": "Value"}}, "length": -1, "id": null, "_type": "Sequence"}, "candidates": {"feature": {"candidate": {"dtype": "string", "id": null, "_type": "Value"}}, "length": -1, "id": null, "_type": "Sequence"}, "answer": {"dtype": "string", "id": null, "_type": "Value"}, "id": {"dtype": "string", "id": null, "_type": "Value"}}, "supervised_keys": null, "builder_name": "qangaroo", "config_name": "wikihop", "version": {"version_str": "1.0.0", "description": "New split API (https://tensorflow.org/datasets/splits)", "nlp_version_to_prepare": null, "major": 1, "minor": 0, "patch": 0}, "splits": {"train": {"name": "train", "num_bytes": 326004849, "num_examples": 43738, "dataset_name": "qangaroo"}, "validation": {"name": "validation", "num_bytes": 40870918, "num_examples": 5129, "dataset_name": "qangaroo"}}, "download_checksums": {"https://drive.google.com/uc?export=download&id=1ytVZ4AhubFDOEL7o7XrIRIyhU8g9wvKA": {"num_bytes": 339843061, "checksum": "2f512869760cdad76a022a1465f025b486ae79dc5b8f0bf3ad901a4caf2d3050"}}, "download_size": 339843061, "dataset_size": 366875767, "size_in_bytes": 706718828}, "masked_wikihop": {"description": "  We have created two new Reading Comprehension datasets focussing on multi-hop (alias multi-step) inference.\n\nSeveral pieces of information often jointly imply another fact. In multi-hop inference, a new fact is derived by combining facts via a chain of multiple steps.\n\nOur aim is to build Reading Comprehension methods that perform multi-hop inference on text, where individual facts are spread out across different documents.\n\nThe two QAngaroo datasets provide a training and evaluation resource for such methods.\n", "citation": "\n", "homepage": "http://qangaroo.cs.ucl.ac.uk/index.html", "license": "", "features": {"query": {"dtype": "string", "id": null, "_type": "Value"}, "supports": {"feature": {"support": {"dtype": "string", "id": null, "_type": "Value"}}, "length": -1, "id": null, "_type": "Sequence"}, "candidates": {"feature": {"candidate": {"dtype": "string", "id": null, "_type": "Value"}}, "length": -1, "id": null, "_type": "Sequence"}, "answer": {"dtype": "string", "id": null, "_type": "Value"}, "id": {"dtype": "string", "id": null, "_type": "Value"}}, "supervised_keys": null, "builder_name": "qangaroo", "config_name": "masked_wikihop", "version": {"version_str": "1.0.0", "description": "New split API (https://tensorflow.org/datasets/splits)", "nlp_version_to_prepare": null, "major": 1, "minor": 0, "patch": 0}, "splits": {"train": {"name": "train", "num_bytes": 348301300, "num_examples": 43738, "dataset_name": "qangaroo"}, "validation": {"name": "validation", "num_bytes": 43691094, "num_examples": 5129, "dataset_name": "qangaroo"}}, "download_checksums": {"https://drive.google.com/uc?export=download&id=1ytVZ4AhubFDOEL7o7XrIRIyhU8g9wvKA": {"num_bytes": 339843061, "checksum": "2f512869760cdad76a022a1465f025b486ae79dc5b8f0bf3ad901a4caf2d3050"}}, "download_size": 339843061, "dataset_size": 391992394, "size_in_bytes": 731835455}}