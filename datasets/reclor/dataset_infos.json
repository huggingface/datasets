{"default": {"description": "Logical reasoning is an important ability to examine, analyze, and critically evaluate arguments as they occur in ordinary\nlanguage as the definition from LSAC. ReClor is a dataset extracted from logical reasoning questions of standardized graduate\nadmission examinations. Empirical results show that the state-of-the-art models struggle on ReClor with poor performance\nindicating more research is needed to essentially enhance the logical reasoning ability of current models. We hope this\ndataset could help push Machine Reading Comprehension (MRC) towards more complicated reasonin\n", "citation": "@inproceedings{yu2020reclor,\n        author = {Yu, Weihao and Jiang, Zihang and Dong, Yanfei and Feng, Jiashi},\n        title = {ReClor: A Reading Comprehension Dataset Requiring Logical Reasoning},\n        booktitle = {International Conference on Learning Representations (ICLR)},\n        month = {April},\n        year = {2020}\n    }\n\n", "homepage": "http://whyu.me/reclor/", "license": "", "features": {"context": {"dtype": "string", "_type": "Value"}, "question": {"dtype": "string", "_type": "Value"}, "answers": {"feature": {"dtype": "string", "_type": "Value"}, "_type": "Sequence"}, "label": {"dtype": "string", "_type": "Value"}, "id_string": {"dtype": "string", "_type": "Value"}}, "builder_name": "reclor", "config_name": "default", "version": {"version_str": "0.1.0", "major": 0, "minor": 1, "patch": 0}, "splits": {"train": {"name": "train", "num_bytes": 4711114, "num_examples": 4638, "dataset_name": "reclor"}, "test": {"name": "test", "num_bytes": 1017354, "num_examples": 1000, "dataset_name": "reclor"}, "validation": {"name": "validation", "num_bytes": 518604, "num_examples": 500, "dataset_name": "reclor"}}, "download_checksums": {}, "download_size": 0, "dataset_size": 6247072, "size_in_bytes": 6247072}}