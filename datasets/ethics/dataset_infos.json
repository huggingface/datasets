{"commonsense": {"description": "The dataset is based in natural language scenarios, which enables us to construct diverse \nsituations involving interpersonal relationships, everyday events, and thousands of objects. \nThis means models must connect diverse facts about the world to their ethical consequences. \nThe ETHICS: Justice dataset contains 27K examples, and has models perform binary classification \nto predict whether each given claim about desert, merit, or entitlement is reasonable or unreasonable.\n", "citation": "@article{hendrycksethics2021,\n  title={Aligning {AI} With Shared Human Values},\n  author={Dan Hendrycks\n    and Collin Burns\n    and Steven Basart\n    and Andrew Critch\n    and Jerry Li\n    and Dawn Song\n    and Jacob Steinhardt},\n  journal={arXiv preprint arXiv:2008.02275},\n  year={2021}\n}\n", "homepage": "https://github.com/hendrycks/ethics", "license": "https://github.com/hendrycks/ethics/blob/master/LICENSE", "features": {"label": {"num_classes": 2, "names": ["0", "1"], "names_file": null, "id": null, "_type": "ClassLabel"}, "input": {"dtype": "string", "id": null, "_type": "Value"}, "is_short": {"num_classes": 2, "names": ["True", "False"], "names_file": null, "id": null, "_type": "ClassLabel"}, "edited": {"num_classes": 2, "names": ["True", "False"], "names_file": null, "id": null, "_type": "ClassLabel"}}, "post_processed": null, "supervised_keys": null, "task_templates": null, "builder_name": "new_dataset", "config_name": "commonsense", "version": {"version_str": "1.0.0", "description": null, "major": 1, "minor": 0, "patch": 0}, "splits": {"train": {"name": "train", "num_bytes": 14708129, "num_examples": 13910, "dataset_name": "new_dataset"}, "test": {"name": "test", "num_bytes": 3226320, "num_examples": 3885, "dataset_name": "new_dataset"}, "test_hard": {"name": "test_hard", "num_bytes": 3942352, "num_examples": 3964, "dataset_name": "new_dataset"}}, "download_checksums": {"https://people.eecs.berkeley.edu/~hendrycks/ethics.tar": {"num_bytes": 35585024, "checksum": "40acbf1ac0da79a2aabef394d58889136b8d38b05be09482006de2453fb06333"}}, "download_size": 35585024, "post_processing_size": null, "dataset_size": 21876801, "size_in_bytes": 57461825}, "deontology": {"description": "The ETHICS dataset tests a machine learning system's ability to predict basic human ethical judgements in open-world settings. The dataset is based in natural language scenarios, which enables us to construct diverse situations involving interpersonal relationships, everyday events, and thousands of objects. This means models must connect diverse facts about the world to their ethical consequences. For instance, taking a penny lying on the street is usually acceptable, whereas taking cash from a wallet lying on the street is not.\n\nThe ETHICS dataset has contextualized scenarios about justice, deontology, virtue ethics, utilitarianism, and commonsense moral intuitions. To do well on the ETHICS dataset, models must know about the morally relevant factors emphasized by each of these ethical systems.\n", "citation": "@article{hendrycksethics2021,\n  title={Aligning {AI} With Shared Human Values},\n  author={Dan Hendrycks\n    and Collin Burns\n    and Steven Basart\n    and Andrew Critch\n    and Jerry Li\n    and Dawn Song\n    and Jacob Steinhardt},\n  journal={arXiv preprint arXiv:2008.02275},\n  year={2021}\n}\n", "homepage": "https://github.com/hendrycks/ethics", "license": "https://github.com/hendrycks/ethics/blob/master/LICENSE", "features": {"label": {"num_classes": 2, "names": ["0", "1"], "names_file": null, "id": null, "_type": "ClassLabel"}, "scenario": {"dtype": "string", "id": null, "_type": "Value"}, "excuse": {"dtype": "string", "id": null, "_type": "Value"}}, "post_processed": null, "supervised_keys": null, "task_templates": null, "builder_name": "new_dataset", "config_name": "deontology", "version": {"version_str": "1.0.0", "description": null, "major": 1, "minor": 0, "patch": 0}, "splits": {"train": {"name": "train", "num_bytes": 1926949, "num_examples": 18164, "dataset_name": "new_dataset"}, "test": {"name": "test", "num_bytes": 383710, "num_examples": 3596, "dataset_name": "new_dataset"}, "test_hard": {"name": "test_hard", "num_bytes": 373420, "num_examples": 3536, "dataset_name": "new_dataset"}}, "download_checksums": {"https://people.eecs.berkeley.edu/~hendrycks/ethics.tar": {"num_bytes": 35585024, "checksum": "40acbf1ac0da79a2aabef394d58889136b8d38b05be09482006de2453fb06333"}}, "download_size": 35585024, "post_processing_size": null, "dataset_size": 2684079, "size_in_bytes": 38269103}, "justice": {"description": "The ETHICS dataset tests a machine learning system's ability to predict basic human ethical judgements in open-world settings. The dataset is based in natural language scenarios, which enables us to construct diverse situations involving interpersonal relationships, everyday events, and thousands of objects. This means models must connect diverse facts about the world to their ethical consequences. For instance, taking a penny lying on the street is usually acceptable, whereas taking cash from a wallet lying on the street is not.\n\nThe ETHICS dataset has contextualized scenarios about justice, deontology, virtue ethics, utilitarianism, and commonsense moral intuitions. To do well on the ETHICS dataset, models must know about the morally relevant factors emphasized by each of these ethical systems.\n", "citation": "@article{hendrycksethics2021,\n  title={Aligning {AI} With Shared Human Values},\n  author={Dan Hendrycks\n    and Collin Burns\n    and Steven Basart\n    and Andrew Critch\n    and Jerry Li\n    and Dawn Song\n    and Jacob Steinhardt},\n  journal={arXiv preprint arXiv:2008.02275},\n  year={2021}\n}\n", "homepage": "https://github.com/hendrycks/ethics", "license": "https://github.com/hendrycks/ethics/blob/master/LICENSE", "features": {"label": {"num_classes": 2, "names": ["0", "1"], "names_file": null, "id": null, "_type": "ClassLabel"}, "scenario": {"dtype": "string", "id": null, "_type": "Value"}}, "post_processed": null, "supervised_keys": null, "task_templates": null, "builder_name": "new_dataset", "config_name": "justice", "version": {"version_str": "1.0.0", "description": null, "major": 1, "minor": 0, "patch": 0}, "splits": {"train": {"name": "train", "num_bytes": 2511065, "num_examples": 21791, "dataset_name": "new_dataset"}, "test": {"name": "test", "num_bytes": 308755, "num_examples": 2704, "dataset_name": "new_dataset"}, "test_hard": {"name": "test_hard", "num_bytes": 236220, "num_examples": 2052, "dataset_name": "new_dataset"}}, "download_checksums": {"https://people.eecs.berkeley.edu/~hendrycks/ethics.tar": {"num_bytes": 35585024, "checksum": "40acbf1ac0da79a2aabef394d58889136b8d38b05be09482006de2453fb06333"}}, "download_size": 35585024, "post_processing_size": null, "dataset_size": 3056040, "size_in_bytes": 38641064}, "utilitarianism": {"description": "The ETHICS dataset tests a machine learning system's ability to predict basic human ethical judgements in open-world settings. The dataset is based in natural language scenarios, which enables us to construct diverse situations involving interpersonal relationships, everyday events, and thousands of objects. This means models must connect diverse facts about the world to their ethical consequences. For instance, taking a penny lying on the street is usually acceptable, whereas taking cash from a wallet lying on the street is not.\n\nThe ETHICS dataset has contextualized scenarios about justice, deontology, virtue ethics, utilitarianism, and commonsense moral intuitions. To do well on the ETHICS dataset, models must know about the morally relevant factors emphasized by each of these ethical systems.\n", "citation": "@article{hendrycksethics2021,\n  title={Aligning {AI} With Shared Human Values},\n  author={Dan Hendrycks\n    and Collin Burns\n    and Steven Basart\n    and Andrew Critch\n    and Jerry Li\n    and Dawn Song\n    and Jacob Steinhardt},\n  journal={arXiv preprint arXiv:2008.02275},\n  year={2021}\n}\n", "homepage": "https://github.com/hendrycks/ethics", "license": "https://github.com/hendrycks/ethics/blob/master/LICENSE", "features": {"more_pleasant": {"dtype": "string", "id": null, "_type": "Value"}, "less_pleasant": {"dtype": "string", "id": null, "_type": "Value"}}, "post_processed": null, "supervised_keys": null, "task_templates": null, "builder_name": "new_dataset", "config_name": "utilitarianism", "version": {"version_str": "1.0.0", "description": null, "major": 1, "minor": 0, "patch": 0}, "splits": {"train": {"name": "train", "num_bytes": 2186834, "num_examples": 13738, "dataset_name": "new_dataset"}, "test": {"name": "test", "num_bytes": 730544, "num_examples": 4808, "dataset_name": "new_dataset"}, "test_hard": {"name": "test_hard", "num_bytes": 668627, "num_examples": 4272, "dataset_name": "new_dataset"}}, "download_checksums": {"https://people.eecs.berkeley.edu/~hendrycks/ethics.tar": {"num_bytes": 35585024, "checksum": "40acbf1ac0da79a2aabef394d58889136b8d38b05be09482006de2453fb06333"}}, "download_size": 35585024, "post_processing_size": null, "dataset_size": 3586005, "size_in_bytes": 39171029}, "virtue": {"description": "The dataset is based in natural language scenarios, which enables us to construct diverse \nsituations involving interpersonal relationships, everyday events, and thousands of objects. \nThis means models must connect diverse facts about the world to their ethical consequences. \nThe ETHICS: Justice dataset contains 27K examples, and has models perform binary classification \nto predict whether each given claim about desert, merit, or entitlement is reasonable or unreasonable.\n", "citation": "@article{hendrycksethics2021,\n  title={Aligning {AI} With Shared Human Values},\n  author={Dan Hendrycks\n    and Collin Burns\n    and Steven Basart\n    and Andrew Critch\n    and Jerry Li\n    and Dawn Song\n    and Jacob Steinhardt},\n  journal={arXiv preprint arXiv:2008.02275},\n  year={2021}\n}\n", "homepage": "https://github.com/hendrycks/ethics", "license": "https://github.com/hendrycks/ethics/blob/master/LICENSE", "features": {"label": {"num_classes": 2, "names": ["0", "1"], "names_file": null, "id": null, "_type": "ClassLabel"}, "scenario": {"dtype": "string", "id": null, "_type": "Value"}}, "post_processed": null, "supervised_keys": null, "task_templates": null, "builder_name": "new_dataset", "config_name": "virtue", "version": {"version_str": "1.0.0", "description": null, "major": 1, "minor": 0, "patch": 0}, "splits": {"train": {"name": "train", "num_bytes": 2718013, "num_examples": 28245, "dataset_name": "new_dataset"}, "test": {"name": "test", "num_bytes": 487158, "num_examples": 4975, "dataset_name": "new_dataset"}, "test_hard": {"name": "test_hard", "num_bytes": 471615, "num_examples": 4780, "dataset_name": "new_dataset"}}, "download_checksums": {"https://people.eecs.berkeley.edu/~hendrycks/ethics.tar": {"num_bytes": 35585024, "checksum": "40acbf1ac0da79a2aabef394d58889136b8d38b05be09482006de2453fb06333"}}, "download_size": 35585024, "post_processing_size": null, "dataset_size": 3676786, "size_in_bytes": 39261810}, "commonsense_morality": {"description": "The ETHICS dataset tests a machine learning system's ability to predict basic human ethical judgements in open-world settings. The dataset is based in natural language scenarios, which enables us to construct diverse situations involving interpersonal relationships, everyday events, and thousands of objects. This means models must connect diverse facts about the world to their ethical consequences. For instance, taking a penny lying on the street is usually acceptable, whereas taking cash from a wallet lying on the street is not.\n\nThe ETHICS dataset has contextualized scenarios about justice, deontology, virtue ethics, utilitarianism, and commonsense moral intuitions. To do well on the ETHICS dataset, models must know about the morally relevant factors emphasized by each of these ethical systems.\n", "citation": "@article{hendrycksethics2021,\n  title={Aligning {AI} With Shared Human Values},\n  author={Dan Hendrycks\n    and Collin Burns\n    and Steven Basart\n    and Andrew Critch\n    and Jerry Li\n    and Dawn Song\n    and Jacob Steinhardt},\n  journal={arXiv preprint arXiv:2008.02275},\n  year={2021}\n}\n", "homepage": "https://github.com/hendrycks/ethics", "license": "https://github.com/hendrycks/ethics/blob/master/LICENSE", "features": {"label": {"num_classes": 2, "names": ["0", "1"], "names_file": null, "id": null, "_type": "ClassLabel"}, "input": {"dtype": "string", "id": null, "_type": "Value"}, "is_short": {"num_classes": 2, "names": ["True", "False"], "names_file": null, "id": null, "_type": "ClassLabel"}, "edited": {"num_classes": 2, "names": ["True", "False"], "names_file": null, "id": null, "_type": "ClassLabel"}}, "post_processed": null, "supervised_keys": null, "task_templates": null, "builder_name": "new_dataset", "config_name": "commonsense_morality", "version": {"version_str": "1.0.0", "description": null, "major": 1, "minor": 0, "patch": 0}, "splits": {"train": {"name": "train", "num_bytes": 14708129, "num_examples": 13910, "dataset_name": "new_dataset"}, "test": {"name": "test", "num_bytes": 3226320, "num_examples": 3885, "dataset_name": "new_dataset"}, "test_hard": {"name": "test_hard", "num_bytes": 3942352, "num_examples": 3964, "dataset_name": "new_dataset"}}, "download_checksums": {"https://people.eecs.berkeley.edu/~hendrycks/ethics.tar": {"num_bytes": 35585024, "checksum": "40acbf1ac0da79a2aabef394d58889136b8d38b05be09482006de2453fb06333"}}, "download_size": 35585024, "post_processing_size": null, "dataset_size": 21876801, "size_in_bytes": 57461825}, "virtue_ethics": {"description": "The ETHICS dataset tests a machine learning system's ability to predict basic human ethical judgements in open-world settings. The dataset is based in natural language scenarios, which enables us to construct diverse situations involving interpersonal relationships, everyday events, and thousands of objects. This means models must connect diverse facts about the world to their ethical consequences. For instance, taking a penny lying on the street is usually acceptable, whereas taking cash from a wallet lying on the street is not.\n\nThe ETHICS dataset has contextualized scenarios about justice, deontology, virtue ethics, utilitarianism, and commonsense moral intuitions. To do well on the ETHICS dataset, models must know about the morally relevant factors emphasized by each of these ethical systems.\n", "citation": "@article{hendrycksethics2021,\n  title={Aligning {AI} With Shared Human Values},\n  author={Dan Hendrycks\n    and Collin Burns\n    and Steven Basart\n    and Andrew Critch\n    and Jerry Li\n    and Dawn Song\n    and Jacob Steinhardt},\n  journal={arXiv preprint arXiv:2008.02275},\n  year={2021}\n}\n", "homepage": "https://github.com/hendrycks/ethics", "license": "https://github.com/hendrycks/ethics/blob/master/LICENSE", "features": {"label": {"num_classes": 2, "names": ["0", "1"], "names_file": null, "id": null, "_type": "ClassLabel"}, "scenario": {"dtype": "string", "id": null, "_type": "Value"}}, "post_processed": null, "supervised_keys": null, "task_templates": null, "builder_name": "new_dataset", "config_name": "virtue_ethics", "version": {"version_str": "1.0.0", "description": null, "major": 1, "minor": 0, "patch": 0}, "splits": {"train": {"name": "train", "num_bytes": 2718013, "num_examples": 28245, "dataset_name": "new_dataset"}, "test": {"name": "test", "num_bytes": 487158, "num_examples": 4975, "dataset_name": "new_dataset"}, "test_hard": {"name": "test_hard", "num_bytes": 471615, "num_examples": 4780, "dataset_name": "new_dataset"}}, "download_checksums": {"https://people.eecs.berkeley.edu/~hendrycks/ethics.tar": {"num_bytes": 35585024, "checksum": "40acbf1ac0da79a2aabef394d58889136b8d38b05be09482006de2453fb06333"}}, "download_size": 35585024, "post_processing_size": null, "dataset_size": 3676786, "size_in_bytes": 39261810}}