{
    "wnli.hi": {
        "description": "    To thoroughly evaluate language models on Indian languages, \n    we need a robust NLU benchmark consisting of a wide variety of tasks and covering all the Indian languages. \n    IndicGLUE is a natural language understanding benchmark that we propose.\n\n\nThe Winograd Schema Challenge (Levesque et al., 2011) is a reading comprehension task\nin which a system must read a sentence with a pronoun and select the referent of that pronoun from\na list of choices. The examples are manually constructed to foil simple statistical methods: Each\none is contingent on contextual information provided by a single word or phrase in the sentence.\nTo convert the problem into sentence pair classification, we construct sentence pairs by replacing\nthe ambiguous pronoun with each possible referent. The task is to predict if the sentence with the\npronoun substituted is entailed by the original sentence. We use a small evaluation set consisting of\nnew examples derived from fiction books that was shared privately by the authors of the original\ncorpus. While the included training set is balanced between two classes, the test set is imbalanced\nbetween them (65% not entailment). Also, due to a data quirk, the development set is adversarial:\nhypotheses are sometimes shared between training and development examples, so if a model memorizes the\ntraining examples, they will predict the wrong label on corresponding development set\nexample. As with QNLI, each example is evaluated separately, so there is not a systematic correspondence\nbetween a model's score on this task and its score on the unconverted original task. We\ncall converted dataset WNLI (Winograd NLI). The dataset is available in 3 languages.\n",
        "citation": "    @inproceedings{kakwani2020indicnlpsuite,\n    title={{IndicNLPSuite: Monolingual Corpora, Evaluation Benchmarks and Pre-trained Multilingual Language Models for Indian Languages}},\n    author={Divyanshu Kakwani and Anoop Kunchukuttan and Satish Golla and Gokul N.C. and Avik Bhattacharyya and Mitesh M. Khapra and Pratyush Kumar},\n    year={2020},\n    booktitle={Findings of EMNLP},\n}\n\n\nREPLACE\n",
        "homepage": "https://indicnlp.ai4bharat.org/indic-glue/#natural-language-inference",
        "license": "",
        "features": {
            "sentence1": {
                "dtype": "string",
                "id": null,
                "_type": "Value"
            },
            "sentence2": {
                "dtype": "string",
                "id": null,
                "_type": "Value"
            },
            "label": {
                "dtype": "int32",
                "id": null,
                "_type": "Value"
            }
        },
        "post_processed": null,
        "supervised_keys": null,
        "builder_name": "indic_glue",
        "config_name": "wnli.hi",
        "version": {
            "version_str": "1.0.0",
            "description": "",
            "major": 1,
            "minor": 0,
            "patch": 0
        },
        "splits": {
            "train": {
                "name": "train",
                "num_bytes": 250802,
                "num_examples": 635,
                "dataset_name": "indic_glue"
            },
            "validation": {
                "name": "validation",
                "num_bytes": 28400,
                "num_examples": 71,
                "dataset_name": "indic_glue"
            }
        },
        "download_checksums": {
            "https://storage.googleapis.com/ai4bharat-public-indic-nlp-corpora/evaluations/wnli-translated.tar.gz": {
                "num_bytes": 591249,
                "checksum": "7babf4a8250bf727e6cd55a4c5e1d4564f01317e91adea45f8eb57b9887b048b"
            }
        },
        "download_size": 591249,
        "post_processing_size": null,
        "dataset_size": 279202,
        "size_in_bytes": 870451
    },
    "wnli.gu": {
        "description": "    To thoroughly evaluate language models on Indian languages, \n    we need a robust NLU benchmark consisting of a wide variety of tasks and covering all the Indian languages. \n    IndicGLUE is a natural language understanding benchmark that we propose.\n\n\nThe Winograd Schema Challenge (Levesque et al., 2011) is a reading comprehension task\nin which a system must read a sentence with a pronoun and select the referent of that pronoun from\na list of choices. The examples are manually constructed to foil simple statistical methods: Each\none is contingent on contextual information provided by a single word or phrase in the sentence.\nTo convert the problem into sentence pair classification, we construct sentence pairs by replacing\nthe ambiguous pronoun with each possible referent. The task is to predict if the sentence with the\npronoun substituted is entailed by the original sentence. We use a small evaluation set consisting of\nnew examples derived from fiction books that was shared privately by the authors of the original\ncorpus. While the included training set is balanced between two classes, the test set is imbalanced\nbetween them (65% not entailment). Also, due to a data quirk, the development set is adversarial:\nhypotheses are sometimes shared between training and development examples, so if a model memorizes the\ntraining examples, they will predict the wrong label on corresponding development set\nexample. As with QNLI, each example is evaluated separately, so there is not a systematic correspondence\nbetween a model's score on this task and its score on the unconverted original task. We\ncall converted dataset WNLI (Winograd NLI). The dataset is available in 3 languages.\n",
        "citation": "    @inproceedings{kakwani2020indicnlpsuite,\n    title={{IndicNLPSuite: Monolingual Corpora, Evaluation Benchmarks and Pre-trained Multilingual Language Models for Indian Languages}},\n    author={Divyanshu Kakwani and Anoop Kunchukuttan and Satish Golla and Gokul N.C. and Avik Bhattacharyya and Mitesh M. Khapra and Pratyush Kumar},\n    year={2020},\n    booktitle={Findings of EMNLP},\n}\n\n\nREPLACE\n",
        "homepage": "https://indicnlp.ai4bharat.org/indic-glue/#natural-language-inference",
        "license": "",
        "features": {
            "sentence1": {
                "dtype": "string",
                "id": null,
                "_type": "Value"
            },
            "sentence2": {
                "dtype": "string",
                "id": null,
                "_type": "Value"
            },
            "label": {
                "dtype": "int32",
                "id": null,
                "_type": "Value"
            }
        },
        "post_processed": null,
        "supervised_keys": null,
        "builder_name": "indic_glue",
        "config_name": "wnli.gu",
        "version": {
            "version_str": "1.0.0",
            "description": "",
            "major": 1,
            "minor": 0,
            "patch": 0
        },
        "splits": {
            "train": {
                "name": "train",
                "num_bytes": 249022,
                "num_examples": 635,
                "dataset_name": "indic_glue"
            },
            "validation": {
                "name": "validation",
                "num_bytes": 27899,
                "num_examples": 71,
                "dataset_name": "indic_glue"
            }
        },
        "download_checksums": {
            "https://storage.googleapis.com/ai4bharat-public-indic-nlp-corpora/evaluations/wnli-translated.tar.gz": {
                "num_bytes": 591249,
                "checksum": "7babf4a8250bf727e6cd55a4c5e1d4564f01317e91adea45f8eb57b9887b048b"
            }
        },
        "download_size": 591249,
        "post_processing_size": null,
        "dataset_size": 276921,
        "size_in_bytes": 868170
    },
    "wnli.mr": {
        "description": "    To thoroughly evaluate language models on Indian languages, \n    we need a robust NLU benchmark consisting of a wide variety of tasks and covering all the Indian languages. \n    IndicGLUE is a natural language understanding benchmark that we propose.\n\n\nThe Winograd Schema Challenge (Levesque et al., 2011) is a reading comprehension task\nin which a system must read a sentence with a pronoun and select the referent of that pronoun from\na list of choices. The examples are manually constructed to foil simple statistical methods: Each\none is contingent on contextual information provided by a single word or phrase in the sentence.\nTo convert the problem into sentence pair classification, we construct sentence pairs by replacing\nthe ambiguous pronoun with each possible referent. The task is to predict if the sentence with the\npronoun substituted is entailed by the original sentence. We use a small evaluation set consisting of\nnew examples derived from fiction books that was shared privately by the authors of the original\ncorpus. While the included training set is balanced between two classes, the test set is imbalanced\nbetween them (65% not entailment). Also, due to a data quirk, the development set is adversarial:\nhypotheses are sometimes shared between training and development examples, so if a model memorizes the\ntraining examples, they will predict the wrong label on corresponding development set\nexample. As with QNLI, each example is evaluated separately, so there is not a systematic correspondence\nbetween a model's score on this task and its score on the unconverted original task. We\ncall converted dataset WNLI (Winograd NLI). The dataset is available in 3 languages.\n",
        "citation": "    @inproceedings{kakwani2020indicnlpsuite,\n    title={{IndicNLPSuite: Monolingual Corpora, Evaluation Benchmarks and Pre-trained Multilingual Language Models for Indian Languages}},\n    author={Divyanshu Kakwani and Anoop Kunchukuttan and Satish Golla and Gokul N.C. and Avik Bhattacharyya and Mitesh M. Khapra and Pratyush Kumar},\n    year={2020},\n    booktitle={Findings of EMNLP},\n}\n\n\nREPLACE\n",
        "homepage": "https://indicnlp.ai4bharat.org/indic-glue/#natural-language-inference",
        "license": "",
        "features": {
            "sentence1": {
                "dtype": "string",
                "id": null,
                "_type": "Value"
            },
            "sentence2": {
                "dtype": "string",
                "id": null,
                "_type": "Value"
            },
            "label": {
                "dtype": "int32",
                "id": null,
                "_type": "Value"
            }
        },
        "post_processed": null,
        "supervised_keys": null,
        "builder_name": "indic_glue",
        "config_name": "wnli.mr",
        "version": {
            "version_str": "1.0.0",
            "description": "",
            "major": 1,
            "minor": 0,
            "patch": 0
        },
        "splits": {
            "train": {
                "name": "train",
                "num_bytes": 254117,
                "num_examples": 635,
                "dataset_name": "indic_glue"
            },
            "validation": {
                "name": "validation",
                "num_bytes": 28942,
                "num_examples": 71,
                "dataset_name": "indic_glue"
            }
        },
        "download_checksums": {
            "https://storage.googleapis.com/ai4bharat-public-indic-nlp-corpora/evaluations/wnli-translated.tar.gz": {
                "num_bytes": 591249,
                "checksum": "7babf4a8250bf727e6cd55a4c5e1d4564f01317e91adea45f8eb57b9887b048b"
            }
        },
        "download_size": 591249,
        "post_processing_size": null,
        "dataset_size": 283059,
        "size_in_bytes": 874308
    },
    "wnli.en": {
        "description": "    To thoroughly evaluate language models on Indian languages, \n    we need a robust NLU benchmark consisting of a wide variety of tasks and covering all the Indian languages. \n    IndicGLUE is a natural language understanding benchmark that we propose.\n\n\nThe Winograd Schema Challenge (Levesque et al., 2011) is a reading comprehension task\nin which a system must read a sentence with a pronoun and select the referent of that pronoun from\na list of choices. The examples are manually constructed to foil simple statistical methods: Each\none is contingent on contextual information provided by a single word or phrase in the sentence.\nTo convert the problem into sentence pair classification, we construct sentence pairs by replacing\nthe ambiguous pronoun with each possible referent. The task is to predict if the sentence with the\npronoun substituted is entailed by the original sentence. We use a small evaluation set consisting of\nnew examples derived from fiction books that was shared privately by the authors of the original\ncorpus. While the included training set is balanced between two classes, the test set is imbalanced\nbetween them (65% not entailment). Also, due to a data quirk, the development set is adversarial:\nhypotheses are sometimes shared between training and development examples, so if a model memorizes the\ntraining examples, they will predict the wrong label on corresponding development set\nexample. As with QNLI, each example is evaluated separately, so there is not a systematic correspondence\nbetween a model's score on this task and its score on the unconverted original task. We\ncall converted dataset WNLI (Winograd NLI). The dataset is available in 3 languages.\n",
        "citation": "    @inproceedings{kakwani2020indicnlpsuite,\n    title={{IndicNLPSuite: Monolingual Corpora, Evaluation Benchmarks and Pre-trained Multilingual Language Models for Indian Languages}},\n    author={Divyanshu Kakwani and Anoop Kunchukuttan and Satish Golla and Gokul N.C. and Avik Bhattacharyya and Mitesh M. Khapra and Pratyush Kumar},\n    year={2020},\n    booktitle={Findings of EMNLP},\n}\n\n\nREPLACE\n",
        "homepage": "https://indicnlp.ai4bharat.org/indic-glue/#natural-language-inference",
        "license": "",
        "features": {
            "sentence1": {
                "dtype": "string",
                "id": null,
                "_type": "Value"
            },
            "sentence2": {
                "dtype": "string",
                "id": null,
                "_type": "Value"
            },
            "label": {
                "dtype": "int32",
                "id": null,
                "_type": "Value"
            }
        },
        "post_processed": null,
        "supervised_keys": null,
        "builder_name": "indic_glue",
        "config_name": "wnli.en",
        "version": {
            "version_str": "1.0.0",
            "description": "",
            "major": 1,
            "minor": 0,
            "patch": 0
        },
        "splits": {
            "train": {
                "name": "train",
                "num_bytes": 102037,
                "num_examples": 635,
                "dataset_name": "indic_glue"
            },
            "validation": {
                "name": "validation",
                "num_bytes": 11602,
                "num_examples": 71,
                "dataset_name": "indic_glue"
            }
        },
        "download_checksums": {
            "https://storage.googleapis.com/ai4bharat-public-indic-nlp-corpora/evaluations/wnli-translated.tar.gz": {
                "num_bytes": 591249,
                "checksum": "7babf4a8250bf727e6cd55a4c5e1d4564f01317e91adea45f8eb57b9887b048b"
            }
        },
        "download_size": 591249,
        "post_processing_size": null,
        "dataset_size": 113639,
        "size_in_bytes": 704888
    },
    "copa.en": {
        "description": "    To thoroughly evaluate language models on Indian languages, \n    we need a robust NLU benchmark consisting of a wide variety of tasks and covering all the Indian languages. \n    IndicGLUE is a natural language understanding benchmark that we propose.\n\n\nThe Choice Of Plausible Alternatives (COPA) evaluation provides researchers with a tool for assessing \nprogress in open-domain commonsense causal reasoning. COPA consists of 1000 questions, split equally \ninto development and test sets of 500 questions each. Each question is composed of a premise and two \nalternatives, where the task is to select the alternative that more plausibly has a causal relation \nwith the premise. The correct alternative is randomized so that the expected performance of randomly \nguessing is 50%. The dataset is available is 3 languages.\n",
        "citation": "    @inproceedings{kakwani2020indicnlpsuite,\n    title={{IndicNLPSuite: Monolingual Corpora, Evaluation Benchmarks and Pre-trained Multilingual Language Models for Indian Languages}},\n    author={Divyanshu Kakwani and Anoop Kunchukuttan and Satish Golla and Gokul N.C. and Avik Bhattacharyya and Mitesh M. Khapra and Pratyush Kumar},\n    year={2020},\n    booktitle={Findings of EMNLP},\n}\n\n\nREPLACE\n",
        "homepage": "https://indicnlp.ai4bharat.org/indic-glue/#natural-language-inference",
        "license": "",
        "features": {
            "premise": {
                "dtype": "string",
                "id": null,
                "_type": "Value"
            },
            "choice1": {
                "dtype": "string",
                "id": null,
                "_type": "Value"
            },
            "choice2": {
                "dtype": "string",
                "id": null,
                "_type": "Value"
            },
            "question": {
                "dtype": "string",
                "id": null,
                "_type": "Value"
            },
            "label": {
                "dtype": "int32",
                "id": null,
                "_type": "Value"
            }
        },
        "post_processed": null,
        "supervised_keys": null,
        "builder_name": "indic_glue",
        "config_name": "copa.en",
        "version": {
            "version_str": "1.0.0",
            "description": "",
            "major": 1,
            "minor": 0,
            "patch": 0
        },
        "splits": {
            "train": {
                "name": "train",
                "num_bytes": 46049,
                "num_examples": 400,
                "dataset_name": "indic_glue"
            },
            "validation": {
                "name": "validation",
                "num_bytes": 11695,
                "num_examples": 100,
                "dataset_name": "indic_glue"
            }
        },
        "download_checksums": {
            "https://storage.googleapis.com/ai4bharat-public-indic-nlp-corpora/evaluations/copa-translated.tar.gz": {
                "num_bytes": 757679,
                "checksum": "5f30e91c4071c7fc0f1cbe85195def7aa42637d90df313dc9b85db7f9676d008"
            }
        },
        "download_size": 757679,
        "post_processing_size": null,
        "dataset_size": 57744,
        "size_in_bytes": 815423
    },
    "copa.hi": {
        "description": "    To thoroughly evaluate language models on Indian languages, \n    we need a robust NLU benchmark consisting of a wide variety of tasks and covering all the Indian languages. \n    IndicGLUE is a natural language understanding benchmark that we propose.\n\n\nThe Choice Of Plausible Alternatives (COPA) evaluation provides researchers with a tool for assessing \nprogress in open-domain commonsense causal reasoning. COPA consists of 1000 questions, split equally \ninto development and test sets of 500 questions each. Each question is composed of a premise and two \nalternatives, where the task is to select the alternative that more plausibly has a causal relation \nwith the premise. The correct alternative is randomized so that the expected performance of randomly \nguessing is 50%. The dataset is available is 3 languages.\n",
        "citation": "    @inproceedings{kakwani2020indicnlpsuite,\n    title={{IndicNLPSuite: Monolingual Corpora, Evaluation Benchmarks and Pre-trained Multilingual Language Models for Indian Languages}},\n    author={Divyanshu Kakwani and Anoop Kunchukuttan and Satish Golla and Gokul N.C. and Avik Bhattacharyya and Mitesh M. Khapra and Pratyush Kumar},\n    year={2020},\n    booktitle={Findings of EMNLP},\n}\n\n\nREPLACE\n",
        "homepage": "https://indicnlp.ai4bharat.org/indic-glue/#natural-language-inference",
        "license": "",
        "features": {
            "premise": {
                "dtype": "string",
                "id": null,
                "_type": "Value"
            },
            "choice1": {
                "dtype": "string",
                "id": null,
                "_type": "Value"
            },
            "choice2": {
                "dtype": "string",
                "id": null,
                "_type": "Value"
            },
            "question": {
                "dtype": "string",
                "id": null,
                "_type": "Value"
            },
            "label": {
                "dtype": "int32",
                "id": null,
                "_type": "Value"
            }
        },
        "post_processed": null,
        "supervised_keys": null,
        "builder_name": "indic_glue",
        "config_name": "copa.hi",
        "version": {
            "version_str": "1.0.0",
            "description": "",
            "major": 1,
            "minor": 0,
            "patch": 0
        },
        "splits": {
            "train": {
                "name": "train",
                "num_bytes": 93392,
                "num_examples": 362,
                "dataset_name": "indic_glue"
            },
            "validation": {
                "name": "validation",
                "num_bytes": 23575,
                "num_examples": 88,
                "dataset_name": "indic_glue"
            }
        },
        "download_checksums": {
            "https://storage.googleapis.com/ai4bharat-public-indic-nlp-corpora/evaluations/copa-translated.tar.gz": {
                "num_bytes": 757679,
                "checksum": "5f30e91c4071c7fc0f1cbe85195def7aa42637d90df313dc9b85db7f9676d008"
            }
        },
        "download_size": 757679,
        "post_processing_size": null,
        "dataset_size": 116967,
        "size_in_bytes": 874646
    },
    "copa.gu": {
        "description": "    To thoroughly evaluate language models on Indian languages, \n    we need a robust NLU benchmark consisting of a wide variety of tasks and covering all the Indian languages. \n    IndicGLUE is a natural language understanding benchmark that we propose.\n\n\nThe Choice Of Plausible Alternatives (COPA) evaluation provides researchers with a tool for assessing \nprogress in open-domain commonsense causal reasoning. COPA consists of 1000 questions, split equally \ninto development and test sets of 500 questions each. Each question is composed of a premise and two \nalternatives, where the task is to select the alternative that more plausibly has a causal relation \nwith the premise. The correct alternative is randomized so that the expected performance of randomly \nguessing is 50%. The dataset is available is 3 languages.\n",
        "citation": "    @inproceedings{kakwani2020indicnlpsuite,\n    title={{IndicNLPSuite: Monolingual Corpora, Evaluation Benchmarks and Pre-trained Multilingual Language Models for Indian Languages}},\n    author={Divyanshu Kakwani and Anoop Kunchukuttan and Satish Golla and Gokul N.C. and Avik Bhattacharyya and Mitesh M. Khapra and Pratyush Kumar},\n    year={2020},\n    booktitle={Findings of EMNLP},\n}\n\n\nREPLACE\n",
        "homepage": "https://indicnlp.ai4bharat.org/indic-glue/#natural-language-inference",
        "license": "",
        "features": {
            "premise": {
                "dtype": "string",
                "id": null,
                "_type": "Value"
            },
            "choice1": {
                "dtype": "string",
                "id": null,
                "_type": "Value"
            },
            "choice2": {
                "dtype": "string",
                "id": null,
                "_type": "Value"
            },
            "question": {
                "dtype": "string",
                "id": null,
                "_type": "Value"
            },
            "label": {
                "dtype": "int32",
                "id": null,
                "_type": "Value"
            }
        },
        "post_processed": null,
        "supervised_keys": null,
        "builder_name": "indic_glue",
        "config_name": "copa.gu",
        "version": {
            "version_str": "1.0.0",
            "description": "",
            "major": 1,
            "minor": 0,
            "patch": 0
        },
        "splits": {
            "train": {
                "name": "train",
                "num_bytes": 92113,
                "num_examples": 362,
                "dataset_name": "indic_glue"
            },
            "validation": {
                "name": "validation",
                "num_bytes": 23466,
                "num_examples": 88,
                "dataset_name": "indic_glue"
            }
        },
        "download_checksums": {
            "https://storage.googleapis.com/ai4bharat-public-indic-nlp-corpora/evaluations/copa-translated.tar.gz": {
                "num_bytes": 757679,
                "checksum": "5f30e91c4071c7fc0f1cbe85195def7aa42637d90df313dc9b85db7f9676d008"
            }
        },
        "download_size": 757679,
        "post_processing_size": null,
        "dataset_size": 115579,
        "size_in_bytes": 873258
    },
    "copa.mr": {
        "description": "    To thoroughly evaluate language models on Indian languages, \n    we need a robust NLU benchmark consisting of a wide variety of tasks and covering all the Indian languages. \n    IndicGLUE is a natural language understanding benchmark that we propose.\n\n\nThe Choice Of Plausible Alternatives (COPA) evaluation provides researchers with a tool for assessing \nprogress in open-domain commonsense causal reasoning. COPA consists of 1000 questions, split equally \ninto development and test sets of 500 questions each. Each question is composed of a premise and two \nalternatives, where the task is to select the alternative that more plausibly has a causal relation \nwith the premise. The correct alternative is randomized so that the expected performance of randomly \nguessing is 50%. The dataset is available is 3 languages.\n",
        "citation": "    @inproceedings{kakwani2020indicnlpsuite,\n    title={{IndicNLPSuite: Monolingual Corpora, Evaluation Benchmarks and Pre-trained Multilingual Language Models for Indian Languages}},\n    author={Divyanshu Kakwani and Anoop Kunchukuttan and Satish Golla and Gokul N.C. and Avik Bhattacharyya and Mitesh M. Khapra and Pratyush Kumar},\n    year={2020},\n    booktitle={Findings of EMNLP},\n}\n\n\nREPLACE\n",
        "homepage": "https://indicnlp.ai4bharat.org/indic-glue/#natural-language-inference",
        "license": "",
        "features": {
            "premise": {
                "dtype": "string",
                "id": null,
                "_type": "Value"
            },
            "choice1": {
                "dtype": "string",
                "id": null,
                "_type": "Value"
            },
            "choice2": {
                "dtype": "string",
                "id": null,
                "_type": "Value"
            },
            "question": {
                "dtype": "string",
                "id": null,
                "_type": "Value"
            },
            "label": {
                "dtype": "int32",
                "id": null,
                "_type": "Value"
            }
        },
        "post_processed": null,
        "supervised_keys": null,
        "builder_name": "indic_glue",
        "config_name": "copa.mr",
        "version": {
            "version_str": "1.0.0",
            "description": "",
            "major": 1,
            "minor": 0,
            "patch": 0
        },
        "splits": {
            "train": {
                "name": "train",
                "num_bytes": 93457,
                "num_examples": 362,
                "dataset_name": "indic_glue"
            },
            "validation": {
                "name": "validation",
                "num_bytes": 23890,
                "num_examples": 88,
                "dataset_name": "indic_glue"
            }
        },
        "download_checksums": {
            "https://storage.googleapis.com/ai4bharat-public-indic-nlp-corpora/evaluations/copa-translated.tar.gz": {
                "num_bytes": 757679,
                "checksum": "5f30e91c4071c7fc0f1cbe85195def7aa42637d90df313dc9b85db7f9676d008"
            }
        },
        "download_size": 757679,
        "post_processing_size": null,
        "dataset_size": 117347,
        "size_in_bytes": 875026
    },
    "sna.bn": {
        "description": "    To thoroughly evaluate language models on Indian languages, \n    we need a robust NLU benchmark consisting of a wide variety of tasks and covering all the Indian languages. \n    IndicGLUE is a natural language understanding benchmark that we propose.\n\n\nThis dataset is a collection of Bengali News articles. The dataset is used for classifying articles into\n5 different classes namely international, state, kolkata, entertainment and sports.\n",
        "citation": "    @inproceedings{kakwani2020indicnlpsuite,\n    title={{IndicNLPSuite: Monolingual Corpora, Evaluation Benchmarks and Pre-trained Multilingual Language Models for Indian Languages}},\n    author={Divyanshu Kakwani and Anoop Kunchukuttan and Satish Golla and Gokul N.C. and Avik Bhattacharyya and Mitesh M. Khapra and Pratyush Kumar},\n    year={2020},\n    booktitle={Findings of EMNLP},\n}\n\n\nREPLACE\n",
        "homepage": "https://indicnlp.ai4bharat.org/indic-glue/#news-category-classification",
        "license": "",
        "features": {
            "text": {
                "dtype": "string",
                "id": null,
                "_type": "Value"
            },
            "label": {
                "dtype": "string",
                "id": null,
                "_type": "Value"
            }
        },
        "post_processed": null,
        "supervised_keys": null,
        "builder_name": "indic_glue",
        "config_name": "sna.bn",
        "version": {
            "version_str": "1.0.0",
            "description": "",
            "major": 1,
            "minor": 0,
            "patch": 0
        },
        "splits": {
            "train": {
                "name": "train",
                "num_bytes": 46109842,
                "num_examples": 11284,
                "dataset_name": "indic_glue"
            },
            "validation": {
                "name": "validation",
                "num_bytes": 5653325,
                "num_examples": 1411,
                "dataset_name": "indic_glue"
            },
            "test": {
                "name": "test",
                "num_bytes": 5804821,
                "num_examples": 1411,
                "dataset_name": "indic_glue"
            }
        },
        "download_checksums": {
            "https://storage.googleapis.com/ai4bharat-public-indic-nlp-corpora/evaluations/soham-articles.tar.gz": {
                "num_bytes": 11803096,
                "checksum": "3ef5e7a1917a53791ba0edfbc35151569525bd5c50d9be2561f48fa953caf64d"
            }
        },
        "download_size": 11803096,
        "post_processing_size": null,
        "dataset_size": 57567988,
        "size_in_bytes": 69371084
    },
    "csqa.as": {
        "description": "    To thoroughly evaluate language models on Indian languages, \n    we need a robust NLU benchmark consisting of a wide variety of tasks and covering all the Indian languages. \n    IndicGLUE is a natural language understanding benchmark that we propose.\n\n\nREPLACE\n",
        "citation": "    @inproceedings{kakwani2020indicnlpsuite,\n    title={{IndicNLPSuite: Monolingual Corpora, Evaluation Benchmarks and Pre-trained Multilingual Language Models for Indian Languages}},\n    author={Divyanshu Kakwani and Anoop Kunchukuttan and Satish Golla and Gokul N.C. and Avik Bhattacharyya and Mitesh M. Khapra and Pratyush Kumar},\n    year={2020},\n    booktitle={Findings of EMNLP},\n}\n\n\nREPLACE\n",
        "homepage": "https://indicnlp.ai4bharat.org/indic-glue/#cloze-style-question-answering",
        "license": "",
        "features": {
            "question": {
                "dtype": "string",
                "id": null,
                "_type": "Value"
            },
            "answer": {
                "dtype": "string",
                "id": null,
                "_type": "Value"
            },
            "category": {
                "dtype": "string",
                "id": null,
                "_type": "Value"
            },
            "title": {
                "dtype": "string",
                "id": null,
                "_type": "Value"
            },
            "options": {
                "feature": {
                    "dtype": "string",
                    "id": null,
                    "_type": "Value"
                },
                "length": -1,
                "id": null,
                "_type": "Sequence"
            },
            "out_of_context_options": {
                "feature": {
                    "dtype": "string",
                    "id": null,
                    "_type": "Value"
                },
                "length": -1,
                "id": null,
                "_type": "Sequence"
            }
        },
        "post_processed": null,
        "supervised_keys": null,
        "builder_name": "indic_glue",
        "config_name": "csqa.as",
        "version": {
            "version_str": "1.0.0",
            "description": "",
            "major": 1,
            "minor": 0,
            "patch": 0
        },
        "splits": {
            "test": {
                "name": "test",
                "num_bytes": 3800555,
                "num_examples": 2942,
                "dataset_name": "indic_glue"
            }
        },
        "download_checksums": {
            "https://storage.googleapis.com/ai4bharat-public-indic-nlp-corpora/evaluations/wiki-cloze.tar.gz": {
                "num_bytes": 65099316,
                "checksum": "9028f77adce320ed4878e22dc88175aa9ee9304188bbd30cbdd274750f4871ef"
            }
        },
        "download_size": 65099316,
        "post_processing_size": null,
        "dataset_size": 3800555,
        "size_in_bytes": 68899871
    },
    "csqa.bn": {
        "description": "    To thoroughly evaluate language models on Indian languages, \n    we need a robust NLU benchmark consisting of a wide variety of tasks and covering all the Indian languages. \n    IndicGLUE is a natural language understanding benchmark that we propose.\n\n\nREPLACE\n",
        "citation": "    @inproceedings{kakwani2020indicnlpsuite,\n    title={{IndicNLPSuite: Monolingual Corpora, Evaluation Benchmarks and Pre-trained Multilingual Language Models for Indian Languages}},\n    author={Divyanshu Kakwani and Anoop Kunchukuttan and Satish Golla and Gokul N.C. and Avik Bhattacharyya and Mitesh M. Khapra and Pratyush Kumar},\n    year={2020},\n    booktitle={Findings of EMNLP},\n}\n\n\nREPLACE\n",
        "homepage": "https://indicnlp.ai4bharat.org/indic-glue/#cloze-style-question-answering",
        "license": "",
        "features": {
            "question": {
                "dtype": "string",
                "id": null,
                "_type": "Value"
            },
            "answer": {
                "dtype": "string",
                "id": null,
                "_type": "Value"
            },
            "category": {
                "dtype": "string",
                "id": null,
                "_type": "Value"
            },
            "title": {
                "dtype": "string",
                "id": null,
                "_type": "Value"
            },
            "options": {
                "feature": {
                    "dtype": "string",
                    "id": null,
                    "_type": "Value"
                },
                "length": -1,
                "id": null,
                "_type": "Sequence"
            },
            "out_of_context_options": {
                "feature": {
                    "dtype": "string",
                    "id": null,
                    "_type": "Value"
                },
                "length": -1,
                "id": null,
                "_type": "Sequence"
            }
        },
        "post_processed": null,
        "supervised_keys": null,
        "builder_name": "indic_glue",
        "config_name": "csqa.bn",
        "version": {
            "version_str": "1.0.0",
            "description": "",
            "major": 1,
            "minor": 0,
            "patch": 0
        },
        "splits": {
            "test": {
                "name": "test",
                "num_bytes": 54671146,
                "num_examples": 38845,
                "dataset_name": "indic_glue"
            }
        },
        "download_checksums": {
            "https://storage.googleapis.com/ai4bharat-public-indic-nlp-corpora/evaluations/wiki-cloze.tar.gz": {
                "num_bytes": 65099316,
                "checksum": "9028f77adce320ed4878e22dc88175aa9ee9304188bbd30cbdd274750f4871ef"
            }
        },
        "download_size": 65099316,
        "post_processing_size": null,
        "dataset_size": 54671146,
        "size_in_bytes": 119770462
    },
    "csqa.gu": {
        "description": "    To thoroughly evaluate language models on Indian languages, \n    we need a robust NLU benchmark consisting of a wide variety of tasks and covering all the Indian languages. \n    IndicGLUE is a natural language understanding benchmark that we propose.\n\n\nREPLACE\n",
        "citation": "    @inproceedings{kakwani2020indicnlpsuite,\n    title={{IndicNLPSuite: Monolingual Corpora, Evaluation Benchmarks and Pre-trained Multilingual Language Models for Indian Languages}},\n    author={Divyanshu Kakwani and Anoop Kunchukuttan and Satish Golla and Gokul N.C. and Avik Bhattacharyya and Mitesh M. Khapra and Pratyush Kumar},\n    year={2020},\n    booktitle={Findings of EMNLP},\n}\n\n\nREPLACE\n",
        "homepage": "https://indicnlp.ai4bharat.org/indic-glue/#cloze-style-question-answering",
        "license": "",
        "features": {
            "question": {
                "dtype": "string",
                "id": null,
                "_type": "Value"
            },
            "answer": {
                "dtype": "string",
                "id": null,
                "_type": "Value"
            },
            "category": {
                "dtype": "string",
                "id": null,
                "_type": "Value"
            },
            "title": {
                "dtype": "string",
                "id": null,
                "_type": "Value"
            },
            "options": {
                "feature": {
                    "dtype": "string",
                    "id": null,
                    "_type": "Value"
                },
                "length": -1,
                "id": null,
                "_type": "Sequence"
            },
            "out_of_context_options": {
                "feature": {
                    "dtype": "string",
                    "id": null,
                    "_type": "Value"
                },
                "length": -1,
                "id": null,
                "_type": "Sequence"
            }
        },
        "post_processed": null,
        "supervised_keys": null,
        "builder_name": "indic_glue",
        "config_name": "csqa.gu",
        "version": {
            "version_str": "1.0.0",
            "description": "",
            "major": 1,
            "minor": 0,
            "patch": 0
        },
        "splits": {
            "test": {
                "name": "test",
                "num_bytes": 29131703,
                "num_examples": 22861,
                "dataset_name": "indic_glue"
            }
        },
        "download_checksums": {
            "https://storage.googleapis.com/ai4bharat-public-indic-nlp-corpora/evaluations/wiki-cloze.tar.gz": {
                "num_bytes": 65099316,
                "checksum": "9028f77adce320ed4878e22dc88175aa9ee9304188bbd30cbdd274750f4871ef"
            }
        },
        "download_size": 65099316,
        "post_processing_size": null,
        "dataset_size": 29131703,
        "size_in_bytes": 94231019
    },
    "csqa.hi": {
        "description": "    To thoroughly evaluate language models on Indian languages, \n    we need a robust NLU benchmark consisting of a wide variety of tasks and covering all the Indian languages. \n    IndicGLUE is a natural language understanding benchmark that we propose.\n\n\nREPLACE\n",
        "citation": "    @inproceedings{kakwani2020indicnlpsuite,\n    title={{IndicNLPSuite: Monolingual Corpora, Evaluation Benchmarks and Pre-trained Multilingual Language Models for Indian Languages}},\n    author={Divyanshu Kakwani and Anoop Kunchukuttan and Satish Golla and Gokul N.C. and Avik Bhattacharyya and Mitesh M. Khapra and Pratyush Kumar},\n    year={2020},\n    booktitle={Findings of EMNLP},\n}\n\n\nREPLACE\n",
        "homepage": "https://indicnlp.ai4bharat.org/indic-glue/#cloze-style-question-answering",
        "license": "",
        "features": {
            "question": {
                "dtype": "string",
                "id": null,
                "_type": "Value"
            },
            "answer": {
                "dtype": "string",
                "id": null,
                "_type": "Value"
            },
            "category": {
                "dtype": "string",
                "id": null,
                "_type": "Value"
            },
            "title": {
                "dtype": "string",
                "id": null,
                "_type": "Value"
            },
            "options": {
                "feature": {
                    "dtype": "string",
                    "id": null,
                    "_type": "Value"
                },
                "length": -1,
                "id": null,
                "_type": "Sequence"
            },
            "out_of_context_options": {
                "feature": {
                    "dtype": "string",
                    "id": null,
                    "_type": "Value"
                },
                "length": -1,
                "id": null,
                "_type": "Sequence"
            }
        },
        "post_processed": null,
        "supervised_keys": null,
        "builder_name": "indic_glue",
        "config_name": "csqa.hi",
        "version": {
            "version_str": "1.0.0",
            "description": "",
            "major": 1,
            "minor": 0,
            "patch": 0
        },
        "splits": {
            "test": {
                "name": "test",
                "num_bytes": 40409475,
                "num_examples": 35140,
                "dataset_name": "indic_glue"
            }
        },
        "download_checksums": {
            "https://storage.googleapis.com/ai4bharat-public-indic-nlp-corpora/evaluations/wiki-cloze.tar.gz": {
                "num_bytes": 65099316,
                "checksum": "9028f77adce320ed4878e22dc88175aa9ee9304188bbd30cbdd274750f4871ef"
            }
        },
        "download_size": 65099316,
        "post_processing_size": null,
        "dataset_size": 40409475,
        "size_in_bytes": 105508791
    },
    "csqa.kn": {
        "description": "    To thoroughly evaluate language models on Indian languages, \n    we need a robust NLU benchmark consisting of a wide variety of tasks and covering all the Indian languages. \n    IndicGLUE is a natural language understanding benchmark that we propose.\n\n\nREPLACE\n",
        "citation": "    @inproceedings{kakwani2020indicnlpsuite,\n    title={{IndicNLPSuite: Monolingual Corpora, Evaluation Benchmarks and Pre-trained Multilingual Language Models for Indian Languages}},\n    author={Divyanshu Kakwani and Anoop Kunchukuttan and Satish Golla and Gokul N.C. and Avik Bhattacharyya and Mitesh M. Khapra and Pratyush Kumar},\n    year={2020},\n    booktitle={Findings of EMNLP},\n}\n\n\nREPLACE\n",
        "homepage": "https://indicnlp.ai4bharat.org/indic-glue/#cloze-style-question-answering",
        "license": "",
        "features": {
            "question": {
                "dtype": "string",
                "id": null,
                "_type": "Value"
            },
            "answer": {
                "dtype": "string",
                "id": null,
                "_type": "Value"
            },
            "category": {
                "dtype": "string",
                "id": null,
                "_type": "Value"
            },
            "title": {
                "dtype": "string",
                "id": null,
                "_type": "Value"
            },
            "options": {
                "feature": {
                    "dtype": "string",
                    "id": null,
                    "_type": "Value"
                },
                "length": -1,
                "id": null,
                "_type": "Sequence"
            },
            "out_of_context_options": {
                "feature": {
                    "dtype": "string",
                    "id": null,
                    "_type": "Value"
                },
                "length": -1,
                "id": null,
                "_type": "Sequence"
            }
        },
        "post_processed": null,
        "supervised_keys": null,
        "builder_name": "indic_glue",
        "config_name": "csqa.kn",
        "version": {
            "version_str": "1.0.0",
            "description": "",
            "major": 1,
            "minor": 0,
            "patch": 0
        },
        "splits": {
            "test": {
                "name": "test",
                "num_bytes": 21199880,
                "num_examples": 13666,
                "dataset_name": "indic_glue"
            }
        },
        "download_checksums": {
            "https://storage.googleapis.com/ai4bharat-public-indic-nlp-corpora/evaluations/wiki-cloze.tar.gz": {
                "num_bytes": 65099316,
                "checksum": "9028f77adce320ed4878e22dc88175aa9ee9304188bbd30cbdd274750f4871ef"
            }
        },
        "download_size": 65099316,
        "post_processing_size": null,
        "dataset_size": 21199880,
        "size_in_bytes": 86299196
    },
    "csqa.ml": {
        "description": "    To thoroughly evaluate language models on Indian languages, \n    we need a robust NLU benchmark consisting of a wide variety of tasks and covering all the Indian languages. \n    IndicGLUE is a natural language understanding benchmark that we propose.\n\n\nREPLACE\n",
        "citation": "    @inproceedings{kakwani2020indicnlpsuite,\n    title={{IndicNLPSuite: Monolingual Corpora, Evaluation Benchmarks and Pre-trained Multilingual Language Models for Indian Languages}},\n    author={Divyanshu Kakwani and Anoop Kunchukuttan and Satish Golla and Gokul N.C. and Avik Bhattacharyya and Mitesh M. Khapra and Pratyush Kumar},\n    year={2020},\n    booktitle={Findings of EMNLP},\n}\n\n\nREPLACE\n",
        "homepage": "https://indicnlp.ai4bharat.org/indic-glue/#cloze-style-question-answering",
        "license": "",
        "features": {
            "question": {
                "dtype": "string",
                "id": null,
                "_type": "Value"
            },
            "answer": {
                "dtype": "string",
                "id": null,
                "_type": "Value"
            },
            "category": {
                "dtype": "string",
                "id": null,
                "_type": "Value"
            },
            "title": {
                "dtype": "string",
                "id": null,
                "_type": "Value"
            },
            "options": {
                "feature": {
                    "dtype": "string",
                    "id": null,
                    "_type": "Value"
                },
                "length": -1,
                "id": null,
                "_type": "Sequence"
            },
            "out_of_context_options": {
                "feature": {
                    "dtype": "string",
                    "id": null,
                    "_type": "Value"
                },
                "length": -1,
                "id": null,
                "_type": "Sequence"
            }
        },
        "post_processed": null,
        "supervised_keys": null,
        "builder_name": "indic_glue",
        "config_name": "csqa.ml",
        "version": {
            "version_str": "1.0.0",
            "description": "",
            "major": 1,
            "minor": 0,
            "patch": 0
        },
        "splits": {
            "test": {
                "name": "test",
                "num_bytes": 47220932,
                "num_examples": 26537,
                "dataset_name": "indic_glue"
            }
        },
        "download_checksums": {
            "https://storage.googleapis.com/ai4bharat-public-indic-nlp-corpora/evaluations/wiki-cloze.tar.gz": {
                "num_bytes": 65099316,
                "checksum": "9028f77adce320ed4878e22dc88175aa9ee9304188bbd30cbdd274750f4871ef"
            }
        },
        "download_size": 65099316,
        "post_processing_size": null,
        "dataset_size": 47220932,
        "size_in_bytes": 112320248
    },
    "csqa.mr": {
        "description": "    To thoroughly evaluate language models on Indian languages, \n    we need a robust NLU benchmark consisting of a wide variety of tasks and covering all the Indian languages. \n    IndicGLUE is a natural language understanding benchmark that we propose.\n\n\nREPLACE\n",
        "citation": "    @inproceedings{kakwani2020indicnlpsuite,\n    title={{IndicNLPSuite: Monolingual Corpora, Evaluation Benchmarks and Pre-trained Multilingual Language Models for Indian Languages}},\n    author={Divyanshu Kakwani and Anoop Kunchukuttan and Satish Golla and Gokul N.C. and Avik Bhattacharyya and Mitesh M. Khapra and Pratyush Kumar},\n    year={2020},\n    booktitle={Findings of EMNLP},\n}\n\n\nREPLACE\n",
        "homepage": "https://indicnlp.ai4bharat.org/indic-glue/#cloze-style-question-answering",
        "license": "",
        "features": {
            "question": {
                "dtype": "string",
                "id": null,
                "_type": "Value"
            },
            "answer": {
                "dtype": "string",
                "id": null,
                "_type": "Value"
            },
            "category": {
                "dtype": "string",
                "id": null,
                "_type": "Value"
            },
            "title": {
                "dtype": "string",
                "id": null,
                "_type": "Value"
            },
            "options": {
                "feature": {
                    "dtype": "string",
                    "id": null,
                    "_type": "Value"
                },
                "length": -1,
                "id": null,
                "_type": "Sequence"
            },
            "out_of_context_options": {
                "feature": {
                    "dtype": "string",
                    "id": null,
                    "_type": "Value"
                },
                "length": -1,
                "id": null,
                "_type": "Sequence"
            }
        },
        "post_processed": null,
        "supervised_keys": null,
        "builder_name": "indic_glue",
        "config_name": "csqa.mr",
        "version": {
            "version_str": "1.0.0",
            "description": "",
            "major": 1,
            "minor": 0,
            "patch": 0
        },
        "splits": {
            "test": {
                "name": "test",
                "num_bytes": 13667238,
                "num_examples": 11370,
                "dataset_name": "indic_glue"
            }
        },
        "download_checksums": {
            "https://storage.googleapis.com/ai4bharat-public-indic-nlp-corpora/evaluations/wiki-cloze.tar.gz": {
                "num_bytes": 65099316,
                "checksum": "9028f77adce320ed4878e22dc88175aa9ee9304188bbd30cbdd274750f4871ef"
            }
        },
        "download_size": 65099316,
        "post_processing_size": null,
        "dataset_size": 13667238,
        "size_in_bytes": 78766554
    },
    "csqa.or": {
        "description": "    To thoroughly evaluate language models on Indian languages, \n    we need a robust NLU benchmark consisting of a wide variety of tasks and covering all the Indian languages. \n    IndicGLUE is a natural language understanding benchmark that we propose.\n\n\nREPLACE\n",
        "citation": "    @inproceedings{kakwani2020indicnlpsuite,\n    title={{IndicNLPSuite: Monolingual Corpora, Evaluation Benchmarks and Pre-trained Multilingual Language Models for Indian Languages}},\n    author={Divyanshu Kakwani and Anoop Kunchukuttan and Satish Golla and Gokul N.C. and Avik Bhattacharyya and Mitesh M. Khapra and Pratyush Kumar},\n    year={2020},\n    booktitle={Findings of EMNLP},\n}\n\n\nREPLACE\n",
        "homepage": "https://indicnlp.ai4bharat.org/indic-glue/#cloze-style-question-answering",
        "license": "",
        "features": {
            "question": {
                "dtype": "string",
                "id": null,
                "_type": "Value"
            },
            "answer": {
                "dtype": "string",
                "id": null,
                "_type": "Value"
            },
            "category": {
                "dtype": "string",
                "id": null,
                "_type": "Value"
            },
            "title": {
                "dtype": "string",
                "id": null,
                "_type": "Value"
            },
            "options": {
                "feature": {
                    "dtype": "string",
                    "id": null,
                    "_type": "Value"
                },
                "length": -1,
                "id": null,
                "_type": "Sequence"
            },
            "out_of_context_options": {
                "feature": {
                    "dtype": "string",
                    "id": null,
                    "_type": "Value"
                },
                "length": -1,
                "id": null,
                "_type": "Sequence"
            }
        },
        "post_processed": null,
        "supervised_keys": null,
        "builder_name": "indic_glue",
        "config_name": "csqa.or",
        "version": {
            "version_str": "1.0.0",
            "description": "",
            "major": 1,
            "minor": 0,
            "patch": 0
        },
        "splits": {
            "test": {
                "name": "test",
                "num_bytes": 2562397,
                "num_examples": 1975,
                "dataset_name": "indic_glue"
            }
        },
        "download_checksums": {
            "https://storage.googleapis.com/ai4bharat-public-indic-nlp-corpora/evaluations/wiki-cloze.tar.gz": {
                "num_bytes": 65099316,
                "checksum": "9028f77adce320ed4878e22dc88175aa9ee9304188bbd30cbdd274750f4871ef"
            }
        },
        "download_size": 65099316,
        "post_processing_size": null,
        "dataset_size": 2562397,
        "size_in_bytes": 67661713
    },
    "csqa.pa": {
        "description": "    To thoroughly evaluate language models on Indian languages, \n    we need a robust NLU benchmark consisting of a wide variety of tasks and covering all the Indian languages. \n    IndicGLUE is a natural language understanding benchmark that we propose.\n\n\nREPLACE\n",
        "citation": "    @inproceedings{kakwani2020indicnlpsuite,\n    title={{IndicNLPSuite: Monolingual Corpora, Evaluation Benchmarks and Pre-trained Multilingual Language Models for Indian Languages}},\n    author={Divyanshu Kakwani and Anoop Kunchukuttan and Satish Golla and Gokul N.C. and Avik Bhattacharyya and Mitesh M. Khapra and Pratyush Kumar},\n    year={2020},\n    booktitle={Findings of EMNLP},\n}\n\n\nREPLACE\n",
        "homepage": "https://indicnlp.ai4bharat.org/indic-glue/#cloze-style-question-answering",
        "license": "",
        "features": {
            "question": {
                "dtype": "string",
                "id": null,
                "_type": "Value"
            },
            "answer": {
                "dtype": "string",
                "id": null,
                "_type": "Value"
            },
            "category": {
                "dtype": "string",
                "id": null,
                "_type": "Value"
            },
            "title": {
                "dtype": "string",
                "id": null,
                "_type": "Value"
            },
            "options": {
                "feature": {
                    "dtype": "string",
                    "id": null,
                    "_type": "Value"
                },
                "length": -1,
                "id": null,
                "_type": "Sequence"
            },
            "out_of_context_options": {
                "feature": {
                    "dtype": "string",
                    "id": null,
                    "_type": "Value"
                },
                "length": -1,
                "id": null,
                "_type": "Sequence"
            }
        },
        "post_processed": null,
        "supervised_keys": null,
        "builder_name": "indic_glue",
        "config_name": "csqa.pa",
        "version": {
            "version_str": "1.0.0",
            "description": "",
            "major": 1,
            "minor": 0,
            "patch": 0
        },
        "splits": {
            "test": {
                "name": "test",
                "num_bytes": 5806129,
                "num_examples": 5667,
                "dataset_name": "indic_glue"
            }
        },
        "download_checksums": {
            "https://storage.googleapis.com/ai4bharat-public-indic-nlp-corpora/evaluations/wiki-cloze.tar.gz": {
                "num_bytes": 65099316,
                "checksum": "9028f77adce320ed4878e22dc88175aa9ee9304188bbd30cbdd274750f4871ef"
            }
        },
        "download_size": 65099316,
        "post_processing_size": null,
        "dataset_size": 5806129,
        "size_in_bytes": 70905445
    },
    "csqa.ta": {
        "description": "    To thoroughly evaluate language models on Indian languages, \n    we need a robust NLU benchmark consisting of a wide variety of tasks and covering all the Indian languages. \n    IndicGLUE is a natural language understanding benchmark that we propose.\n\n\nREPLACE\n",
        "citation": "    @inproceedings{kakwani2020indicnlpsuite,\n    title={{IndicNLPSuite: Monolingual Corpora, Evaluation Benchmarks and Pre-trained Multilingual Language Models for Indian Languages}},\n    author={Divyanshu Kakwani and Anoop Kunchukuttan and Satish Golla and Gokul N.C. and Avik Bhattacharyya and Mitesh M. Khapra and Pratyush Kumar},\n    year={2020},\n    booktitle={Findings of EMNLP},\n}\n\n\nREPLACE\n",
        "homepage": "https://indicnlp.ai4bharat.org/indic-glue/#cloze-style-question-answering",
        "license": "",
        "features": {
            "question": {
                "dtype": "string",
                "id": null,
                "_type": "Value"
            },
            "answer": {
                "dtype": "string",
                "id": null,
                "_type": "Value"
            },
            "category": {
                "dtype": "string",
                "id": null,
                "_type": "Value"
            },
            "title": {
                "dtype": "string",
                "id": null,
                "_type": "Value"
            },
            "options": {
                "feature": {
                    "dtype": "string",
                    "id": null,
                    "_type": "Value"
                },
                "length": -1,
                "id": null,
                "_type": "Sequence"
            },
            "out_of_context_options": {
                "feature": {
                    "dtype": "string",
                    "id": null,
                    "_type": "Value"
                },
                "length": -1,
                "id": null,
                "_type": "Sequence"
            }
        },
        "post_processed": null,
        "supervised_keys": null,
        "builder_name": "indic_glue",
        "config_name": "csqa.ta",
        "version": {
            "version_str": "1.0.0",
            "description": "",
            "major": 1,
            "minor": 0,
            "patch": 0
        },
        "splits": {
            "test": {
                "name": "test",
                "num_bytes": 61868609,
                "num_examples": 38590,
                "dataset_name": "indic_glue"
            }
        },
        "download_checksums": {
            "https://storage.googleapis.com/ai4bharat-public-indic-nlp-corpora/evaluations/wiki-cloze.tar.gz": {
                "num_bytes": 65099316,
                "checksum": "9028f77adce320ed4878e22dc88175aa9ee9304188bbd30cbdd274750f4871ef"
            }
        },
        "download_size": 65099316,
        "post_processing_size": null,
        "dataset_size": 61868609,
        "size_in_bytes": 126967925
    },
    "csqa.te": {
        "description": "    To thoroughly evaluate language models on Indian languages, \n    we need a robust NLU benchmark consisting of a wide variety of tasks and covering all the Indian languages. \n    IndicGLUE is a natural language understanding benchmark that we propose.\n\n\nREPLACE\n",
        "citation": "    @inproceedings{kakwani2020indicnlpsuite,\n    title={{IndicNLPSuite: Monolingual Corpora, Evaluation Benchmarks and Pre-trained Multilingual Language Models for Indian Languages}},\n    author={Divyanshu Kakwani and Anoop Kunchukuttan and Satish Golla and Gokul N.C. and Avik Bhattacharyya and Mitesh M. Khapra and Pratyush Kumar},\n    year={2020},\n    booktitle={Findings of EMNLP},\n}\n\n\nREPLACE\n",
        "homepage": "https://indicnlp.ai4bharat.org/indic-glue/#cloze-style-question-answering",
        "license": "",
        "features": {
            "question": {
                "dtype": "string",
                "id": null,
                "_type": "Value"
            },
            "answer": {
                "dtype": "string",
                "id": null,
                "_type": "Value"
            },
            "category": {
                "dtype": "string",
                "id": null,
                "_type": "Value"
            },
            "title": {
                "dtype": "string",
                "id": null,
                "_type": "Value"
            },
            "options": {
                "feature": {
                    "dtype": "string",
                    "id": null,
                    "_type": "Value"
                },
                "length": -1,
                "id": null,
                "_type": "Sequence"
            },
            "out_of_context_options": {
                "feature": {
                    "dtype": "string",
                    "id": null,
                    "_type": "Value"
                },
                "length": -1,
                "id": null,
                "_type": "Sequence"
            }
        },
        "post_processed": null,
        "supervised_keys": null,
        "builder_name": "indic_glue",
        "config_name": "csqa.te",
        "version": {
            "version_str": "1.0.0",
            "description": "",
            "major": 1,
            "minor": 0,
            "patch": 0
        },
        "splits": {
            "test": {
                "name": "test",
                "num_bytes": 58785157,
                "num_examples": 41338,
                "dataset_name": "indic_glue"
            }
        },
        "download_checksums": {
            "https://storage.googleapis.com/ai4bharat-public-indic-nlp-corpora/evaluations/wiki-cloze.tar.gz": {
                "num_bytes": 65099316,
                "checksum": "9028f77adce320ed4878e22dc88175aa9ee9304188bbd30cbdd274750f4871ef"
            }
        },
        "download_size": 65099316,
        "post_processing_size": null,
        "dataset_size": 58785157,
        "size_in_bytes": 123884473
    }
}