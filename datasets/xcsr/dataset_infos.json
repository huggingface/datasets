{"X-CSQA-en": {"description": "To evaluate multi-lingual language models (ML-LMs) for commonsense reasoning in a cross-lingual zero-shot transfer setting (X-CSR), i.e., training in English and test in other languages, we create two benchmark datasets, namely X-CSQA and X-CODAH. Specifically, we automatically translate the original CSQA and CODAH datasets, which only have English versions, to 15 other languages, forming development and test sets for studying X-CSR. As our goal is to evaluate different ML-LMs in a unified evaluation protocol for X-CSR, we argue that such translated examples, although might contain noise, can serve as a starting benchmark for us to obtain meaningful analysis, before more human-translated datasets will be available in the future.\n", "citation": "# X-CSR\n@inproceedings{lin-etal-2021-common,\n    title = \"Common Sense Beyond {E}nglish: Evaluating and Improving Multilingual Language Models for Commonsense Reasoning\",\n    author = \"Lin, Bill Yuchen  and\n      Lee, Seyeon  and\n      Qiao, Xiaoyang  and\n      Ren, Xiang\",\n    booktitle = \"Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)\",\n    month = aug,\n    year = \"2021\",\n    address = \"Online\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2021.acl-long.102\",\n    doi = \"10.18653/v1/2021.acl-long.102\",\n    pages = \"1274--1287\",\n}\n\n# CSQA\n@inproceedings{Talmor2019commonsenseqaaq,\n    address = {Minneapolis, Minnesota},\n    author = {Talmor, Alon  and Herzig, Jonathan  and Lourie, Nicholas and Berant, Jonathan},\n    booktitle = {Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},\n    doi = {10.18653/v1/N19-1421},\n    pages = {4149--4158},\n    publisher = {Association for Computational Linguistics},\n    title = {CommonsenseQA: A Question Answering Challenge Targeting Commonsense Knowledge},\n    url = {https://www.aclweb.org/anthology/N19-1421},\n    year = {2019}\n}\n\n# CODAH\n@inproceedings{Chen2019CODAHAA,\n    address = {Minneapolis, USA},\n    author = {Chen, Michael  and D{'}Arcy, Mike  and Liu, Alisa  and Fernandez, Jared  and Downey, Doug},\n    booktitle = {Proceedings of the 3rd Workshop on Evaluating Vector Space Representations for {NLP}},\n    doi = {10.18653/v1/W19-2008},\n    pages = {63--69},\n    publisher = {Association for Computational Linguistics},\n    title = {CODAH: An Adversarially-Authored Question Answering Dataset for Common Sense},\n    url = {https://www.aclweb.org/anthology/W19-2008},\n    year = {2019}\n}\n", "homepage": "https://inklab.usc.edu//XCSR/", "license": "", "features": {"id": {"dtype": "string", "id": null, "_type": "Value"}, "lang": {"dtype": "string", "id": null, "_type": "Value"}, "question": {"stem": {"dtype": "string", "id": null, "_type": "Value"}, "choices": {"feature": {"label": {"dtype": "string", "id": null, "_type": "Value"}, "text": {"dtype": "string", "id": null, "_type": "Value"}}, "length": -1, "id": null, "_type": "Sequence"}}, "answerKey": {"dtype": "string", "id": null, "_type": "Value"}}, "post_processed": null, "supervised_keys": null, "task_templates": null, "builder_name": "xcsr", "config_name": "X-CSQA-en", "version": {"version_str": "1.1.0", "description": "", "major": 1, "minor": 1, "patch": 0}, "splits": {"test": {"name": "test", "num_bytes": 215919, "num_examples": 1074, "dataset_name": "xcsr"}, "validation": {"name": "validation", "num_bytes": 205361, "num_examples": 1000, "dataset_name": "xcsr"}}, "download_checksums": {"https://inklab.usc.edu/XCSR/xcsr_datasets.zip": {"num_bytes": 7519903, "checksum": "c45b29ece740643252d5402e76be1e33f96f9d6910053f79e80d39887f10c85e"}}, "download_size": 7519903, "post_processing_size": null, "dataset_size": 421280, "size_in_bytes": 7941183}, "X-CSQA-zh": {"description": "To evaluate multi-lingual language models (ML-LMs) for commonsense reasoning in a cross-lingual zero-shot transfer setting (X-CSR), i.e., training in English and test in other languages, we create two benchmark datasets, namely X-CSQA and X-CODAH. Specifically, we automatically translate the original CSQA and CODAH datasets, which only have English versions, to 15 other languages, forming development and test sets for studying X-CSR. As our goal is to evaluate different ML-LMs in a unified evaluation protocol for X-CSR, we argue that such translated examples, although might contain noise, can serve as a starting benchmark for us to obtain meaningful analysis, before more human-translated datasets will be available in the future.\n", "citation": "# X-CSR\n@inproceedings{lin-etal-2021-common,\n    title = \"Common Sense Beyond {E}nglish: Evaluating and Improving Multilingual Language Models for Commonsense Reasoning\",\n    author = \"Lin, Bill Yuchen  and\n      Lee, Seyeon  and\n      Qiao, Xiaoyang  and\n      Ren, Xiang\",\n    booktitle = \"Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)\",\n    month = aug,\n    year = \"2021\",\n    address = \"Online\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2021.acl-long.102\",\n    doi = \"10.18653/v1/2021.acl-long.102\",\n    pages = \"1274--1287\",\n}\n\n# CSQA\n@inproceedings{Talmor2019commonsenseqaaq,\n    address = {Minneapolis, Minnesota},\n    author = {Talmor, Alon  and Herzig, Jonathan  and Lourie, Nicholas and Berant, Jonathan},\n    booktitle = {Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},\n    doi = {10.18653/v1/N19-1421},\n    pages = {4149--4158},\n    publisher = {Association for Computational Linguistics},\n    title = {CommonsenseQA: A Question Answering Challenge Targeting Commonsense Knowledge},\n    url = {https://www.aclweb.org/anthology/N19-1421},\n    year = {2019}\n}\n\n# CODAH\n@inproceedings{Chen2019CODAHAA,\n    address = {Minneapolis, USA},\n    author = {Chen, Michael  and D{'}Arcy, Mike  and Liu, Alisa  and Fernandez, Jared  and Downey, Doug},\n    booktitle = {Proceedings of the 3rd Workshop on Evaluating Vector Space Representations for {NLP}},\n    doi = {10.18653/v1/W19-2008},\n    pages = {63--69},\n    publisher = {Association for Computational Linguistics},\n    title = {CODAH: An Adversarially-Authored Question Answering Dataset for Common Sense},\n    url = {https://www.aclweb.org/anthology/W19-2008},\n    year = {2019}\n}\n", "homepage": "https://inklab.usc.edu//XCSR/", "license": "", "features": {"id": {"dtype": "string", "id": null, "_type": "Value"}, "lang": {"dtype": "string", "id": null, "_type": "Value"}, "question": {"stem": {"dtype": "string", "id": null, "_type": "Value"}, "choices": {"feature": {"label": {"dtype": "string", "id": null, "_type": "Value"}, "text": {"dtype": "string", "id": null, "_type": "Value"}}, "length": -1, "id": null, "_type": "Sequence"}}, "answerKey": {"dtype": "string", "id": null, "_type": "Value"}}, "post_processed": null, "supervised_keys": null, "task_templates": null, "builder_name": "xcsr", "config_name": "X-CSQA-zh", "version": {"version_str": "1.1.0", "description": "", "major": 1, "minor": 1, "patch": 0}, "splits": {"test": {"name": "test", "num_bytes": 197746, "num_examples": 1074, "dataset_name": "xcsr"}, "validation": {"name": "validation", "num_bytes": 188555, "num_examples": 1000, "dataset_name": "xcsr"}}, "download_checksums": {"https://inklab.usc.edu/XCSR/xcsr_datasets.zip": {"num_bytes": 7519903, "checksum": "c45b29ece740643252d5402e76be1e33f96f9d6910053f79e80d39887f10c85e"}}, "download_size": 7519903, "post_processing_size": null, "dataset_size": 386301, "size_in_bytes": 7906204}, "X-CSQA-de": {"description": "To evaluate multi-lingual language models (ML-LMs) for commonsense reasoning in a cross-lingual zero-shot transfer setting (X-CSR), i.e., training in English and test in other languages, we create two benchmark datasets, namely X-CSQA and X-CODAH. Specifically, we automatically translate the original CSQA and CODAH datasets, which only have English versions, to 15 other languages, forming development and test sets for studying X-CSR. As our goal is to evaluate different ML-LMs in a unified evaluation protocol for X-CSR, we argue that such translated examples, although might contain noise, can serve as a starting benchmark for us to obtain meaningful analysis, before more human-translated datasets will be available in the future.\n", "citation": "# X-CSR\n@inproceedings{lin-etal-2021-common,\n    title = \"Common Sense Beyond {E}nglish: Evaluating and Improving Multilingual Language Models for Commonsense Reasoning\",\n    author = \"Lin, Bill Yuchen  and\n      Lee, Seyeon  and\n      Qiao, Xiaoyang  and\n      Ren, Xiang\",\n    booktitle = \"Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)\",\n    month = aug,\n    year = \"2021\",\n    address = \"Online\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2021.acl-long.102\",\n    doi = \"10.18653/v1/2021.acl-long.102\",\n    pages = \"1274--1287\",\n}\n\n# CSQA\n@inproceedings{Talmor2019commonsenseqaaq,\n    address = {Minneapolis, Minnesota},\n    author = {Talmor, Alon  and Herzig, Jonathan  and Lourie, Nicholas and Berant, Jonathan},\n    booktitle = {Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},\n    doi = {10.18653/v1/N19-1421},\n    pages = {4149--4158},\n    publisher = {Association for Computational Linguistics},\n    title = {CommonsenseQA: A Question Answering Challenge Targeting Commonsense Knowledge},\n    url = {https://www.aclweb.org/anthology/N19-1421},\n    year = {2019}\n}\n\n# CODAH\n@inproceedings{Chen2019CODAHAA,\n    address = {Minneapolis, USA},\n    author = {Chen, Michael  and D{'}Arcy, Mike  and Liu, Alisa  and Fernandez, Jared  and Downey, Doug},\n    booktitle = {Proceedings of the 3rd Workshop on Evaluating Vector Space Representations for {NLP}},\n    doi = {10.18653/v1/W19-2008},\n    pages = {63--69},\n    publisher = {Association for Computational Linguistics},\n    title = {CODAH: An Adversarially-Authored Question Answering Dataset for Common Sense},\n    url = {https://www.aclweb.org/anthology/W19-2008},\n    year = {2019}\n}\n", "homepage": "https://inklab.usc.edu//XCSR/", "license": "", "features": {"id": {"dtype": "string", "id": null, "_type": "Value"}, "lang": {"dtype": "string", "id": null, "_type": "Value"}, "question": {"stem": {"dtype": "string", "id": null, "_type": "Value"}, "choices": {"feature": {"label": {"dtype": "string", "id": null, "_type": "Value"}, "text": {"dtype": "string", "id": null, "_type": "Value"}}, "length": -1, "id": null, "_type": "Sequence"}}, "answerKey": {"dtype": "string", "id": null, "_type": "Value"}}, "post_processed": null, "supervised_keys": null, "task_templates": null, "builder_name": "xcsr", "config_name": "X-CSQA-de", "version": {"version_str": "1.1.0", "description": "", "major": 1, "minor": 1, "patch": 0}, "splits": {"test": {"name": "test", "num_bytes": 234472, "num_examples": 1074, "dataset_name": "xcsr"}, "validation": {"name": "validation", "num_bytes": 223122, "num_examples": 1000, "dataset_name": "xcsr"}}, "download_checksums": {"https://inklab.usc.edu/XCSR/xcsr_datasets.zip": {"num_bytes": 7519903, "checksum": "c45b29ece740643252d5402e76be1e33f96f9d6910053f79e80d39887f10c85e"}}, "download_size": 7519903, "post_processing_size": null, "dataset_size": 457594, "size_in_bytes": 7977497}, "X-CSQA-es": {"description": "To evaluate multi-lingual language models (ML-LMs) for commonsense reasoning in a cross-lingual zero-shot transfer setting (X-CSR), i.e., training in English and test in other languages, we create two benchmark datasets, namely X-CSQA and X-CODAH. Specifically, we automatically translate the original CSQA and CODAH datasets, which only have English versions, to 15 other languages, forming development and test sets for studying X-CSR. As our goal is to evaluate different ML-LMs in a unified evaluation protocol for X-CSR, we argue that such translated examples, although might contain noise, can serve as a starting benchmark for us to obtain meaningful analysis, before more human-translated datasets will be available in the future.\n", "citation": "# X-CSR\n@inproceedings{lin-etal-2021-common,\n    title = \"Common Sense Beyond {E}nglish: Evaluating and Improving Multilingual Language Models for Commonsense Reasoning\",\n    author = \"Lin, Bill Yuchen  and\n      Lee, Seyeon  and\n      Qiao, Xiaoyang  and\n      Ren, Xiang\",\n    booktitle = \"Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)\",\n    month = aug,\n    year = \"2021\",\n    address = \"Online\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2021.acl-long.102\",\n    doi = \"10.18653/v1/2021.acl-long.102\",\n    pages = \"1274--1287\",\n}\n\n# CSQA\n@inproceedings{Talmor2019commonsenseqaaq,\n    address = {Minneapolis, Minnesota},\n    author = {Talmor, Alon  and Herzig, Jonathan  and Lourie, Nicholas and Berant, Jonathan},\n    booktitle = {Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},\n    doi = {10.18653/v1/N19-1421},\n    pages = {4149--4158},\n    publisher = {Association for Computational Linguistics},\n    title = {CommonsenseQA: A Question Answering Challenge Targeting Commonsense Knowledge},\n    url = {https://www.aclweb.org/anthology/N19-1421},\n    year = {2019}\n}\n\n# CODAH\n@inproceedings{Chen2019CODAHAA,\n    address = {Minneapolis, USA},\n    author = {Chen, Michael  and D{'}Arcy, Mike  and Liu, Alisa  and Fernandez, Jared  and Downey, Doug},\n    booktitle = {Proceedings of the 3rd Workshop on Evaluating Vector Space Representations for {NLP}},\n    doi = {10.18653/v1/W19-2008},\n    pages = {63--69},\n    publisher = {Association for Computational Linguistics},\n    title = {CODAH: An Adversarially-Authored Question Answering Dataset for Common Sense},\n    url = {https://www.aclweb.org/anthology/W19-2008},\n    year = {2019}\n}\n", "homepage": "https://inklab.usc.edu//XCSR/", "license": "", "features": {"id": {"dtype": "string", "id": null, "_type": "Value"}, "lang": {"dtype": "string", "id": null, "_type": "Value"}, "question": {"stem": {"dtype": "string", "id": null, "_type": "Value"}, "choices": {"feature": {"label": {"dtype": "string", "id": null, "_type": "Value"}, "text": {"dtype": "string", "id": null, "_type": "Value"}}, "length": -1, "id": null, "_type": "Sequence"}}, "answerKey": {"dtype": "string", "id": null, "_type": "Value"}}, "post_processed": null, "supervised_keys": null, "task_templates": null, "builder_name": "xcsr", "config_name": "X-CSQA-es", "version": {"version_str": "1.1.0", "description": "", "major": 1, "minor": 1, "patch": 0}, "splits": {"test": {"name": "test", "num_bytes": 237119, "num_examples": 1074, "dataset_name": "xcsr"}, "validation": {"name": "validation", "num_bytes": 224779, "num_examples": 1000, "dataset_name": "xcsr"}}, "download_checksums": {"https://inklab.usc.edu/XCSR/xcsr_datasets.zip": {"num_bytes": 7519903, "checksum": "c45b29ece740643252d5402e76be1e33f96f9d6910053f79e80d39887f10c85e"}}, "download_size": 7519903, "post_processing_size": null, "dataset_size": 461898, "size_in_bytes": 7981801}, "X-CSQA-fr": {"description": "To evaluate multi-lingual language models (ML-LMs) for commonsense reasoning in a cross-lingual zero-shot transfer setting (X-CSR), i.e., training in English and test in other languages, we create two benchmark datasets, namely X-CSQA and X-CODAH. Specifically, we automatically translate the original CSQA and CODAH datasets, which only have English versions, to 15 other languages, forming development and test sets for studying X-CSR. As our goal is to evaluate different ML-LMs in a unified evaluation protocol for X-CSR, we argue that such translated examples, although might contain noise, can serve as a starting benchmark for us to obtain meaningful analysis, before more human-translated datasets will be available in the future.\n", "citation": "# X-CSR\n@inproceedings{lin-etal-2021-common,\n    title = \"Common Sense Beyond {E}nglish: Evaluating and Improving Multilingual Language Models for Commonsense Reasoning\",\n    author = \"Lin, Bill Yuchen  and\n      Lee, Seyeon  and\n      Qiao, Xiaoyang  and\n      Ren, Xiang\",\n    booktitle = \"Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)\",\n    month = aug,\n    year = \"2021\",\n    address = \"Online\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2021.acl-long.102\",\n    doi = \"10.18653/v1/2021.acl-long.102\",\n    pages = \"1274--1287\",\n}\n\n# CSQA\n@inproceedings{Talmor2019commonsenseqaaq,\n    address = {Minneapolis, Minnesota},\n    author = {Talmor, Alon  and Herzig, Jonathan  and Lourie, Nicholas and Berant, Jonathan},\n    booktitle = {Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},\n    doi = {10.18653/v1/N19-1421},\n    pages = {4149--4158},\n    publisher = {Association for Computational Linguistics},\n    title = {CommonsenseQA: A Question Answering Challenge Targeting Commonsense Knowledge},\n    url = {https://www.aclweb.org/anthology/N19-1421},\n    year = {2019}\n}\n\n# CODAH\n@inproceedings{Chen2019CODAHAA,\n    address = {Minneapolis, USA},\n    author = {Chen, Michael  and D{'}Arcy, Mike  and Liu, Alisa  and Fernandez, Jared  and Downey, Doug},\n    booktitle = {Proceedings of the 3rd Workshop on Evaluating Vector Space Representations for {NLP}},\n    doi = {10.18653/v1/W19-2008},\n    pages = {63--69},\n    publisher = {Association for Computational Linguistics},\n    title = {CODAH: An Adversarially-Authored Question Answering Dataset for Common Sense},\n    url = {https://www.aclweb.org/anthology/W19-2008},\n    year = {2019}\n}\n", "homepage": "https://inklab.usc.edu//XCSR/", "license": "", "features": {"id": {"dtype": "string", "id": null, "_type": "Value"}, "lang": {"dtype": "string", "id": null, "_type": "Value"}, "question": {"stem": {"dtype": "string", "id": null, "_type": "Value"}, "choices": {"feature": {"label": {"dtype": "string", "id": null, "_type": "Value"}, "text": {"dtype": "string", "id": null, "_type": "Value"}}, "length": -1, "id": null, "_type": "Sequence"}}, "answerKey": {"dtype": "string", "id": null, "_type": "Value"}}, "post_processed": null, "supervised_keys": null, "task_templates": null, "builder_name": "xcsr", "config_name": "X-CSQA-fr", "version": {"version_str": "1.1.0", "description": "", "major": 1, "minor": 1, "patch": 0}, "splits": {"test": {"name": "test", "num_bytes": 244254, "num_examples": 1074, "dataset_name": "xcsr"}, "validation": {"name": "validation", "num_bytes": 231678, "num_examples": 1000, "dataset_name": "xcsr"}}, "download_checksums": {"https://inklab.usc.edu/XCSR/xcsr_datasets.zip": {"num_bytes": 7519903, "checksum": "c45b29ece740643252d5402e76be1e33f96f9d6910053f79e80d39887f10c85e"}}, "download_size": 7519903, "post_processing_size": null, "dataset_size": 475932, "size_in_bytes": 7995835}, "X-CSQA-it": {"description": "To evaluate multi-lingual language models (ML-LMs) for commonsense reasoning in a cross-lingual zero-shot transfer setting (X-CSR), i.e., training in English and test in other languages, we create two benchmark datasets, namely X-CSQA and X-CODAH. Specifically, we automatically translate the original CSQA and CODAH datasets, which only have English versions, to 15 other languages, forming development and test sets for studying X-CSR. As our goal is to evaluate different ML-LMs in a unified evaluation protocol for X-CSR, we argue that such translated examples, although might contain noise, can serve as a starting benchmark for us to obtain meaningful analysis, before more human-translated datasets will be available in the future.\n", "citation": "# X-CSR\n@inproceedings{lin-etal-2021-common,\n    title = \"Common Sense Beyond {E}nglish: Evaluating and Improving Multilingual Language Models for Commonsense Reasoning\",\n    author = \"Lin, Bill Yuchen  and\n      Lee, Seyeon  and\n      Qiao, Xiaoyang  and\n      Ren, Xiang\",\n    booktitle = \"Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)\",\n    month = aug,\n    year = \"2021\",\n    address = \"Online\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2021.acl-long.102\",\n    doi = \"10.18653/v1/2021.acl-long.102\",\n    pages = \"1274--1287\",\n}\n\n# CSQA\n@inproceedings{Talmor2019commonsenseqaaq,\n    address = {Minneapolis, Minnesota},\n    author = {Talmor, Alon  and Herzig, Jonathan  and Lourie, Nicholas and Berant, Jonathan},\n    booktitle = {Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},\n    doi = {10.18653/v1/N19-1421},\n    pages = {4149--4158},\n    publisher = {Association for Computational Linguistics},\n    title = {CommonsenseQA: A Question Answering Challenge Targeting Commonsense Knowledge},\n    url = {https://www.aclweb.org/anthology/N19-1421},\n    year = {2019}\n}\n\n# CODAH\n@inproceedings{Chen2019CODAHAA,\n    address = {Minneapolis, USA},\n    author = {Chen, Michael  and D{'}Arcy, Mike  and Liu, Alisa  and Fernandez, Jared  and Downey, Doug},\n    booktitle = {Proceedings of the 3rd Workshop on Evaluating Vector Space Representations for {NLP}},\n    doi = {10.18653/v1/W19-2008},\n    pages = {63--69},\n    publisher = {Association for Computational Linguistics},\n    title = {CODAH: An Adversarially-Authored Question Answering Dataset for Common Sense},\n    url = {https://www.aclweb.org/anthology/W19-2008},\n    year = {2019}\n}\n", "homepage": "https://inklab.usc.edu//XCSR/", "license": "", "features": {"id": {"dtype": "string", "id": null, "_type": "Value"}, "lang": {"dtype": "string", "id": null, "_type": "Value"}, "question": {"stem": {"dtype": "string", "id": null, "_type": "Value"}, "choices": {"feature": {"label": {"dtype": "string", "id": null, "_type": "Value"}, "text": {"dtype": "string", "id": null, "_type": "Value"}}, "length": -1, "id": null, "_type": "Sequence"}}, "answerKey": {"dtype": "string", "id": null, "_type": "Value"}}, "post_processed": null, "supervised_keys": null, "task_templates": null, "builder_name": "xcsr", "config_name": "X-CSQA-it", "version": {"version_str": "1.1.0", "description": "", "major": 1, "minor": 1, "patch": 0}, "splits": {"test": {"name": "test", "num_bytes": 232906, "num_examples": 1074, "dataset_name": "xcsr"}, "validation": {"name": "validation", "num_bytes": 221184, "num_examples": 1000, "dataset_name": "xcsr"}}, "download_checksums": {"https://inklab.usc.edu/XCSR/xcsr_datasets.zip": {"num_bytes": 7519903, "checksum": "c45b29ece740643252d5402e76be1e33f96f9d6910053f79e80d39887f10c85e"}}, "download_size": 7519903, "post_processing_size": null, "dataset_size": 454090, "size_in_bytes": 7973993}, "X-CSQA-jap": {"description": "To evaluate multi-lingual language models (ML-LMs) for commonsense reasoning in a cross-lingual zero-shot transfer setting (X-CSR), i.e., training in English and test in other languages, we create two benchmark datasets, namely X-CSQA and X-CODAH. Specifically, we automatically translate the original CSQA and CODAH datasets, which only have English versions, to 15 other languages, forming development and test sets for studying X-CSR. As our goal is to evaluate different ML-LMs in a unified evaluation protocol for X-CSR, we argue that such translated examples, although might contain noise, can serve as a starting benchmark for us to obtain meaningful analysis, before more human-translated datasets will be available in the future.\n", "citation": "# X-CSR\n@inproceedings{lin-etal-2021-common,\n    title = \"Common Sense Beyond {E}nglish: Evaluating and Improving Multilingual Language Models for Commonsense Reasoning\",\n    author = \"Lin, Bill Yuchen  and\n      Lee, Seyeon  and\n      Qiao, Xiaoyang  and\n      Ren, Xiang\",\n    booktitle = \"Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)\",\n    month = aug,\n    year = \"2021\",\n    address = \"Online\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2021.acl-long.102\",\n    doi = \"10.18653/v1/2021.acl-long.102\",\n    pages = \"1274--1287\",\n}\n\n# CSQA\n@inproceedings{Talmor2019commonsenseqaaq,\n    address = {Minneapolis, Minnesota},\n    author = {Talmor, Alon  and Herzig, Jonathan  and Lourie, Nicholas and Berant, Jonathan},\n    booktitle = {Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},\n    doi = {10.18653/v1/N19-1421},\n    pages = {4149--4158},\n    publisher = {Association for Computational Linguistics},\n    title = {CommonsenseQA: A Question Answering Challenge Targeting Commonsense Knowledge},\n    url = {https://www.aclweb.org/anthology/N19-1421},\n    year = {2019}\n}\n\n# CODAH\n@inproceedings{Chen2019CODAHAA,\n    address = {Minneapolis, USA},\n    author = {Chen, Michael  and D{'}Arcy, Mike  and Liu, Alisa  and Fernandez, Jared  and Downey, Doug},\n    booktitle = {Proceedings of the 3rd Workshop on Evaluating Vector Space Representations for {NLP}},\n    doi = {10.18653/v1/W19-2008},\n    pages = {63--69},\n    publisher = {Association for Computational Linguistics},\n    title = {CODAH: An Adversarially-Authored Question Answering Dataset for Common Sense},\n    url = {https://www.aclweb.org/anthology/W19-2008},\n    year = {2019}\n}\n", "homepage": "https://inklab.usc.edu//XCSR/", "license": "", "features": {"id": {"dtype": "string", "id": null, "_type": "Value"}, "lang": {"dtype": "string", "id": null, "_type": "Value"}, "question": {"stem": {"dtype": "string", "id": null, "_type": "Value"}, "choices": {"feature": {"label": {"dtype": "string", "id": null, "_type": "Value"}, "text": {"dtype": "string", "id": null, "_type": "Value"}}, "length": -1, "id": null, "_type": "Sequence"}}, "answerKey": {"dtype": "string", "id": null, "_type": "Value"}}, "post_processed": null, "supervised_keys": null, "task_templates": null, "builder_name": "xcsr", "config_name": "X-CSQA-jap", "version": {"version_str": "1.1.0", "description": "", "major": 1, "minor": 1, "patch": 0}, "splits": {"test": {"name": "test", "num_bytes": 251148, "num_examples": 1074, "dataset_name": "xcsr"}, "validation": {"name": "validation", "num_bytes": 240686, "num_examples": 1000, "dataset_name": "xcsr"}}, "download_checksums": {"https://inklab.usc.edu/XCSR/xcsr_datasets.zip": {"num_bytes": 7519903, "checksum": "c45b29ece740643252d5402e76be1e33f96f9d6910053f79e80d39887f10c85e"}}, "download_size": 7519903, "post_processing_size": null, "dataset_size": 491834, "size_in_bytes": 8011737}, "X-CSQA-nl": {"description": "To evaluate multi-lingual language models (ML-LMs) for commonsense reasoning in a cross-lingual zero-shot transfer setting (X-CSR), i.e., training in English and test in other languages, we create two benchmark datasets, namely X-CSQA and X-CODAH. Specifically, we automatically translate the original CSQA and CODAH datasets, which only have English versions, to 15 other languages, forming development and test sets for studying X-CSR. As our goal is to evaluate different ML-LMs in a unified evaluation protocol for X-CSR, we argue that such translated examples, although might contain noise, can serve as a starting benchmark for us to obtain meaningful analysis, before more human-translated datasets will be available in the future.\n", "citation": "# X-CSR\n@inproceedings{lin-etal-2021-common,\n    title = \"Common Sense Beyond {E}nglish: Evaluating and Improving Multilingual Language Models for Commonsense Reasoning\",\n    author = \"Lin, Bill Yuchen  and\n      Lee, Seyeon  and\n      Qiao, Xiaoyang  and\n      Ren, Xiang\",\n    booktitle = \"Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)\",\n    month = aug,\n    year = \"2021\",\n    address = \"Online\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2021.acl-long.102\",\n    doi = \"10.18653/v1/2021.acl-long.102\",\n    pages = \"1274--1287\",\n}\n\n# CSQA\n@inproceedings{Talmor2019commonsenseqaaq,\n    address = {Minneapolis, Minnesota},\n    author = {Talmor, Alon  and Herzig, Jonathan  and Lourie, Nicholas and Berant, Jonathan},\n    booktitle = {Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},\n    doi = {10.18653/v1/N19-1421},\n    pages = {4149--4158},\n    publisher = {Association for Computational Linguistics},\n    title = {CommonsenseQA: A Question Answering Challenge Targeting Commonsense Knowledge},\n    url = {https://www.aclweb.org/anthology/N19-1421},\n    year = {2019}\n}\n\n# CODAH\n@inproceedings{Chen2019CODAHAA,\n    address = {Minneapolis, USA},\n    author = {Chen, Michael  and D{'}Arcy, Mike  and Liu, Alisa  and Fernandez, Jared  and Downey, Doug},\n    booktitle = {Proceedings of the 3rd Workshop on Evaluating Vector Space Representations for {NLP}},\n    doi = {10.18653/v1/W19-2008},\n    pages = {63--69},\n    publisher = {Association for Computational Linguistics},\n    title = {CODAH: An Adversarially-Authored Question Answering Dataset for Common Sense},\n    url = {https://www.aclweb.org/anthology/W19-2008},\n    year = {2019}\n}\n", "homepage": "https://inklab.usc.edu//XCSR/", "license": "", "features": {"id": {"dtype": "string", "id": null, "_type": "Value"}, "lang": {"dtype": "string", "id": null, "_type": "Value"}, "question": {"stem": {"dtype": "string", "id": null, "_type": "Value"}, "choices": {"feature": {"label": {"dtype": "string", "id": null, "_type": "Value"}, "text": {"dtype": "string", "id": null, "_type": "Value"}}, "length": -1, "id": null, "_type": "Sequence"}}, "answerKey": {"dtype": "string", "id": null, "_type": "Value"}}, "post_processed": null, "supervised_keys": null, "task_templates": null, "builder_name": "xcsr", "config_name": "X-CSQA-nl", "version": {"version_str": "1.1.0", "description": "", "major": 1, "minor": 1, "patch": 0}, "splits": {"test": {"name": "test", "num_bytes": 227251, "num_examples": 1074, "dataset_name": "xcsr"}, "validation": {"name": "validation", "num_bytes": 216476, "num_examples": 1000, "dataset_name": "xcsr"}}, "download_checksums": {"https://inklab.usc.edu/XCSR/xcsr_datasets.zip": {"num_bytes": 7519903, "checksum": "c45b29ece740643252d5402e76be1e33f96f9d6910053f79e80d39887f10c85e"}}, "download_size": 7519903, "post_processing_size": null, "dataset_size": 443727, "size_in_bytes": 7963630}, "X-CSQA-pl": {"description": "To evaluate multi-lingual language models (ML-LMs) for commonsense reasoning in a cross-lingual zero-shot transfer setting (X-CSR), i.e., training in English and test in other languages, we create two benchmark datasets, namely X-CSQA and X-CODAH. Specifically, we automatically translate the original CSQA and CODAH datasets, which only have English versions, to 15 other languages, forming development and test sets for studying X-CSR. As our goal is to evaluate different ML-LMs in a unified evaluation protocol for X-CSR, we argue that such translated examples, although might contain noise, can serve as a starting benchmark for us to obtain meaningful analysis, before more human-translated datasets will be available in the future.\n", "citation": "# X-CSR\n@inproceedings{lin-etal-2021-common,\n    title = \"Common Sense Beyond {E}nglish: Evaluating and Improving Multilingual Language Models for Commonsense Reasoning\",\n    author = \"Lin, Bill Yuchen  and\n      Lee, Seyeon  and\n      Qiao, Xiaoyang  and\n      Ren, Xiang\",\n    booktitle = \"Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)\",\n    month = aug,\n    year = \"2021\",\n    address = \"Online\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2021.acl-long.102\",\n    doi = \"10.18653/v1/2021.acl-long.102\",\n    pages = \"1274--1287\",\n}\n\n# CSQA\n@inproceedings{Talmor2019commonsenseqaaq,\n    address = {Minneapolis, Minnesota},\n    author = {Talmor, Alon  and Herzig, Jonathan  and Lourie, Nicholas and Berant, Jonathan},\n    booktitle = {Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},\n    doi = {10.18653/v1/N19-1421},\n    pages = {4149--4158},\n    publisher = {Association for Computational Linguistics},\n    title = {CommonsenseQA: A Question Answering Challenge Targeting Commonsense Knowledge},\n    url = {https://www.aclweb.org/anthology/N19-1421},\n    year = {2019}\n}\n\n# CODAH\n@inproceedings{Chen2019CODAHAA,\n    address = {Minneapolis, USA},\n    author = {Chen, Michael  and D{'}Arcy, Mike  and Liu, Alisa  and Fernandez, Jared  and Downey, Doug},\n    booktitle = {Proceedings of the 3rd Workshop on Evaluating Vector Space Representations for {NLP}},\n    doi = {10.18653/v1/W19-2008},\n    pages = {63--69},\n    publisher = {Association for Computational Linguistics},\n    title = {CODAH: An Adversarially-Authored Question Answering Dataset for Common Sense},\n    url = {https://www.aclweb.org/anthology/W19-2008},\n    year = {2019}\n}\n", "homepage": "https://inklab.usc.edu//XCSR/", "license": "", "features": {"id": {"dtype": "string", "id": null, "_type": "Value"}, "lang": {"dtype": "string", "id": null, "_type": "Value"}, "question": {"stem": {"dtype": "string", "id": null, "_type": "Value"}, "choices": {"feature": {"label": {"dtype": "string", "id": null, "_type": "Value"}, "text": {"dtype": "string", "id": null, "_type": "Value"}}, "length": -1, "id": null, "_type": "Sequence"}}, "answerKey": {"dtype": "string", "id": null, "_type": "Value"}}, "post_processed": null, "supervised_keys": null, "task_templates": null, "builder_name": "xcsr", "config_name": "X-CSQA-pl", "version": {"version_str": "1.1.0", "description": "", "major": 1, "minor": 1, "patch": 0}, "splits": {"test": {"name": "test", "num_bytes": 231781, "num_examples": 1074, "dataset_name": "xcsr"}, "validation": {"name": "validation", "num_bytes": 220096, "num_examples": 1000, "dataset_name": "xcsr"}}, "download_checksums": {"https://inklab.usc.edu/XCSR/xcsr_datasets.zip": {"num_bytes": 7519903, "checksum": "c45b29ece740643252d5402e76be1e33f96f9d6910053f79e80d39887f10c85e"}}, "download_size": 7519903, "post_processing_size": null, "dataset_size": 451877, "size_in_bytes": 7971780}, "X-CSQA-pt": {"description": "To evaluate multi-lingual language models (ML-LMs) for commonsense reasoning in a cross-lingual zero-shot transfer setting (X-CSR), i.e., training in English and test in other languages, we create two benchmark datasets, namely X-CSQA and X-CODAH. Specifically, we automatically translate the original CSQA and CODAH datasets, which only have English versions, to 15 other languages, forming development and test sets for studying X-CSR. As our goal is to evaluate different ML-LMs in a unified evaluation protocol for X-CSR, we argue that such translated examples, although might contain noise, can serve as a starting benchmark for us to obtain meaningful analysis, before more human-translated datasets will be available in the future.\n", "citation": "# X-CSR\n@inproceedings{lin-etal-2021-common,\n    title = \"Common Sense Beyond {E}nglish: Evaluating and Improving Multilingual Language Models for Commonsense Reasoning\",\n    author = \"Lin, Bill Yuchen  and\n      Lee, Seyeon  and\n      Qiao, Xiaoyang  and\n      Ren, Xiang\",\n    booktitle = \"Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)\",\n    month = aug,\n    year = \"2021\",\n    address = \"Online\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2021.acl-long.102\",\n    doi = \"10.18653/v1/2021.acl-long.102\",\n    pages = \"1274--1287\",\n}\n\n# CSQA\n@inproceedings{Talmor2019commonsenseqaaq,\n    address = {Minneapolis, Minnesota},\n    author = {Talmor, Alon  and Herzig, Jonathan  and Lourie, Nicholas and Berant, Jonathan},\n    booktitle = {Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},\n    doi = {10.18653/v1/N19-1421},\n    pages = {4149--4158},\n    publisher = {Association for Computational Linguistics},\n    title = {CommonsenseQA: A Question Answering Challenge Targeting Commonsense Knowledge},\n    url = {https://www.aclweb.org/anthology/N19-1421},\n    year = {2019}\n}\n\n# CODAH\n@inproceedings{Chen2019CODAHAA,\n    address = {Minneapolis, USA},\n    author = {Chen, Michael  and D{'}Arcy, Mike  and Liu, Alisa  and Fernandez, Jared  and Downey, Doug},\n    booktitle = {Proceedings of the 3rd Workshop on Evaluating Vector Space Representations for {NLP}},\n    doi = {10.18653/v1/W19-2008},\n    pages = {63--69},\n    publisher = {Association for Computational Linguistics},\n    title = {CODAH: An Adversarially-Authored Question Answering Dataset for Common Sense},\n    url = {https://www.aclweb.org/anthology/W19-2008},\n    year = {2019}\n}\n", "homepage": "https://inklab.usc.edu//XCSR/", "license": "", "features": {"id": {"dtype": "string", "id": null, "_type": "Value"}, "lang": {"dtype": "string", "id": null, "_type": "Value"}, "question": {"stem": {"dtype": "string", "id": null, "_type": "Value"}, "choices": {"feature": {"label": {"dtype": "string", "id": null, "_type": "Value"}, "text": {"dtype": "string", "id": null, "_type": "Value"}}, "length": -1, "id": null, "_type": "Sequence"}}, "answerKey": {"dtype": "string", "id": null, "_type": "Value"}}, "post_processed": null, "supervised_keys": null, "task_templates": null, "builder_name": "xcsr", "config_name": "X-CSQA-pt", "version": {"version_str": "1.1.0", "description": "", "major": 1, "minor": 1, "patch": 0}, "splits": {"test": {"name": "test", "num_bytes": 235771, "num_examples": 1074, "dataset_name": "xcsr"}, "validation": {"name": "validation", "num_bytes": 223067, "num_examples": 1000, "dataset_name": "xcsr"}}, "download_checksums": {"https://inklab.usc.edu/XCSR/xcsr_datasets.zip": {"num_bytes": 7519903, "checksum": "c45b29ece740643252d5402e76be1e33f96f9d6910053f79e80d39887f10c85e"}}, "download_size": 7519903, "post_processing_size": null, "dataset_size": 458838, "size_in_bytes": 7978741}, "X-CSQA-ru": {"description": "To evaluate multi-lingual language models (ML-LMs) for commonsense reasoning in a cross-lingual zero-shot transfer setting (X-CSR), i.e., training in English and test in other languages, we create two benchmark datasets, namely X-CSQA and X-CODAH. Specifically, we automatically translate the original CSQA and CODAH datasets, which only have English versions, to 15 other languages, forming development and test sets for studying X-CSR. As our goal is to evaluate different ML-LMs in a unified evaluation protocol for X-CSR, we argue that such translated examples, although might contain noise, can serve as a starting benchmark for us to obtain meaningful analysis, before more human-translated datasets will be available in the future.\n", "citation": "# X-CSR\n@inproceedings{lin-etal-2021-common,\n    title = \"Common Sense Beyond {E}nglish: Evaluating and Improving Multilingual Language Models for Commonsense Reasoning\",\n    author = \"Lin, Bill Yuchen  and\n      Lee, Seyeon  and\n      Qiao, Xiaoyang  and\n      Ren, Xiang\",\n    booktitle = \"Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)\",\n    month = aug,\n    year = \"2021\",\n    address = \"Online\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2021.acl-long.102\",\n    doi = \"10.18653/v1/2021.acl-long.102\",\n    pages = \"1274--1287\",\n}\n\n# CSQA\n@inproceedings{Talmor2019commonsenseqaaq,\n    address = {Minneapolis, Minnesota},\n    author = {Talmor, Alon  and Herzig, Jonathan  and Lourie, Nicholas and Berant, Jonathan},\n    booktitle = {Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},\n    doi = {10.18653/v1/N19-1421},\n    pages = {4149--4158},\n    publisher = {Association for Computational Linguistics},\n    title = {CommonsenseQA: A Question Answering Challenge Targeting Commonsense Knowledge},\n    url = {https://www.aclweb.org/anthology/N19-1421},\n    year = {2019}\n}\n\n# CODAH\n@inproceedings{Chen2019CODAHAA,\n    address = {Minneapolis, USA},\n    author = {Chen, Michael  and D{'}Arcy, Mike  and Liu, Alisa  and Fernandez, Jared  and Downey, Doug},\n    booktitle = {Proceedings of the 3rd Workshop on Evaluating Vector Space Representations for {NLP}},\n    doi = {10.18653/v1/W19-2008},\n    pages = {63--69},\n    publisher = {Association for Computational Linguistics},\n    title = {CODAH: An Adversarially-Authored Question Answering Dataset for Common Sense},\n    url = {https://www.aclweb.org/anthology/W19-2008},\n    year = {2019}\n}\n", "homepage": "https://inklab.usc.edu//XCSR/", "license": "", "features": {"id": {"dtype": "string", "id": null, "_type": "Value"}, "lang": {"dtype": "string", "id": null, "_type": "Value"}, "question": {"stem": {"dtype": "string", "id": null, "_type": "Value"}, "choices": {"feature": {"label": {"dtype": "string", "id": null, "_type": "Value"}, "text": {"dtype": "string", "id": null, "_type": "Value"}}, "length": -1, "id": null, "_type": "Sequence"}}, "answerKey": {"dtype": "string", "id": null, "_type": "Value"}}, "post_processed": null, "supervised_keys": null, "task_templates": null, "builder_name": "xcsr", "config_name": "X-CSQA-ru", "version": {"version_str": "1.1.0", "description": "", "major": 1, "minor": 1, "patch": 0}, "splits": {"test": {"name": "test", "num_bytes": 342051, "num_examples": 1074, "dataset_name": "xcsr"}, "validation": {"name": "validation", "num_bytes": 324006, "num_examples": 1000, "dataset_name": "xcsr"}}, "download_checksums": {"https://inklab.usc.edu/XCSR/xcsr_datasets.zip": {"num_bytes": 7519903, "checksum": "c45b29ece740643252d5402e76be1e33f96f9d6910053f79e80d39887f10c85e"}}, "download_size": 7519903, "post_processing_size": null, "dataset_size": 666057, "size_in_bytes": 8185960}, "X-CSQA-ar": {"description": "To evaluate multi-lingual language models (ML-LMs) for commonsense reasoning in a cross-lingual zero-shot transfer setting (X-CSR), i.e., training in English and test in other languages, we create two benchmark datasets, namely X-CSQA and X-CODAH. Specifically, we automatically translate the original CSQA and CODAH datasets, which only have English versions, to 15 other languages, forming development and test sets for studying X-CSR. As our goal is to evaluate different ML-LMs in a unified evaluation protocol for X-CSR, we argue that such translated examples, although might contain noise, can serve as a starting benchmark for us to obtain meaningful analysis, before more human-translated datasets will be available in the future.\n", "citation": "# X-CSR\n@inproceedings{lin-etal-2021-common,\n    title = \"Common Sense Beyond {E}nglish: Evaluating and Improving Multilingual Language Models for Commonsense Reasoning\",\n    author = \"Lin, Bill Yuchen  and\n      Lee, Seyeon  and\n      Qiao, Xiaoyang  and\n      Ren, Xiang\",\n    booktitle = \"Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)\",\n    month = aug,\n    year = \"2021\",\n    address = \"Online\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2021.acl-long.102\",\n    doi = \"10.18653/v1/2021.acl-long.102\",\n    pages = \"1274--1287\",\n}\n\n# CSQA\n@inproceedings{Talmor2019commonsenseqaaq,\n    address = {Minneapolis, Minnesota},\n    author = {Talmor, Alon  and Herzig, Jonathan  and Lourie, Nicholas and Berant, Jonathan},\n    booktitle = {Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},\n    doi = {10.18653/v1/N19-1421},\n    pages = {4149--4158},\n    publisher = {Association for Computational Linguistics},\n    title = {CommonsenseQA: A Question Answering Challenge Targeting Commonsense Knowledge},\n    url = {https://www.aclweb.org/anthology/N19-1421},\n    year = {2019}\n}\n\n# CODAH\n@inproceedings{Chen2019CODAHAA,\n    address = {Minneapolis, USA},\n    author = {Chen, Michael  and D{'}Arcy, Mike  and Liu, Alisa  and Fernandez, Jared  and Downey, Doug},\n    booktitle = {Proceedings of the 3rd Workshop on Evaluating Vector Space Representations for {NLP}},\n    doi = {10.18653/v1/W19-2008},\n    pages = {63--69},\n    publisher = {Association for Computational Linguistics},\n    title = {CODAH: An Adversarially-Authored Question Answering Dataset for Common Sense},\n    url = {https://www.aclweb.org/anthology/W19-2008},\n    year = {2019}\n}\n", "homepage": "https://inklab.usc.edu//XCSR/", "license": "", "features": {"id": {"dtype": "string", "id": null, "_type": "Value"}, "lang": {"dtype": "string", "id": null, "_type": "Value"}, "question": {"stem": {"dtype": "string", "id": null, "_type": "Value"}, "choices": {"feature": {"label": {"dtype": "string", "id": null, "_type": "Value"}, "text": {"dtype": "string", "id": null, "_type": "Value"}}, "length": -1, "id": null, "_type": "Sequence"}}, "answerKey": {"dtype": "string", "id": null, "_type": "Value"}}, "post_processed": null, "supervised_keys": null, "task_templates": null, "builder_name": "xcsr", "config_name": "X-CSQA-ar", "version": {"version_str": "1.1.0", "description": "", "major": 1, "minor": 1, "patch": 0}, "splits": {"test": {"name": "test", "num_bytes": 288947, "num_examples": 1074, "dataset_name": "xcsr"}, "validation": {"name": "validation", "num_bytes": 273862, "num_examples": 1000, "dataset_name": "xcsr"}}, "download_checksums": {"https://inklab.usc.edu/XCSR/xcsr_datasets.zip": {"num_bytes": 7519903, "checksum": "c45b29ece740643252d5402e76be1e33f96f9d6910053f79e80d39887f10c85e"}}, "download_size": 7519903, "post_processing_size": null, "dataset_size": 562809, "size_in_bytes": 8082712}, "X-CSQA-vi": {"description": "To evaluate multi-lingual language models (ML-LMs) for commonsense reasoning in a cross-lingual zero-shot transfer setting (X-CSR), i.e., training in English and test in other languages, we create two benchmark datasets, namely X-CSQA and X-CODAH. Specifically, we automatically translate the original CSQA and CODAH datasets, which only have English versions, to 15 other languages, forming development and test sets for studying X-CSR. As our goal is to evaluate different ML-LMs in a unified evaluation protocol for X-CSR, we argue that such translated examples, although might contain noise, can serve as a starting benchmark for us to obtain meaningful analysis, before more human-translated datasets will be available in the future.\n", "citation": "# X-CSR\n@inproceedings{lin-etal-2021-common,\n    title = \"Common Sense Beyond {E}nglish: Evaluating and Improving Multilingual Language Models for Commonsense Reasoning\",\n    author = \"Lin, Bill Yuchen  and\n      Lee, Seyeon  and\n      Qiao, Xiaoyang  and\n      Ren, Xiang\",\n    booktitle = \"Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)\",\n    month = aug,\n    year = \"2021\",\n    address = \"Online\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2021.acl-long.102\",\n    doi = \"10.18653/v1/2021.acl-long.102\",\n    pages = \"1274--1287\",\n}\n\n# CSQA\n@inproceedings{Talmor2019commonsenseqaaq,\n    address = {Minneapolis, Minnesota},\n    author = {Talmor, Alon  and Herzig, Jonathan  and Lourie, Nicholas and Berant, Jonathan},\n    booktitle = {Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},\n    doi = {10.18653/v1/N19-1421},\n    pages = {4149--4158},\n    publisher = {Association for Computational Linguistics},\n    title = {CommonsenseQA: A Question Answering Challenge Targeting Commonsense Knowledge},\n    url = {https://www.aclweb.org/anthology/N19-1421},\n    year = {2019}\n}\n\n# CODAH\n@inproceedings{Chen2019CODAHAA,\n    address = {Minneapolis, USA},\n    author = {Chen, Michael  and D{'}Arcy, Mike  and Liu, Alisa  and Fernandez, Jared  and Downey, Doug},\n    booktitle = {Proceedings of the 3rd Workshop on Evaluating Vector Space Representations for {NLP}},\n    doi = {10.18653/v1/W19-2008},\n    pages = {63--69},\n    publisher = {Association for Computational Linguistics},\n    title = {CODAH: An Adversarially-Authored Question Answering Dataset for Common Sense},\n    url = {https://www.aclweb.org/anthology/W19-2008},\n    year = {2019}\n}\n", "homepage": "https://inklab.usc.edu//XCSR/", "license": "", "features": {"id": {"dtype": "string", "id": null, "_type": "Value"}, "lang": {"dtype": "string", "id": null, "_type": "Value"}, "question": {"stem": {"dtype": "string", "id": null, "_type": "Value"}, "choices": {"feature": {"label": {"dtype": "string", "id": null, "_type": "Value"}, "text": {"dtype": "string", "id": null, "_type": "Value"}}, "length": -1, "id": null, "_type": "Sequence"}}, "answerKey": {"dtype": "string", "id": null, "_type": "Value"}}, "post_processed": null, "supervised_keys": null, "task_templates": null, "builder_name": "xcsr", "config_name": "X-CSQA-vi", "version": {"version_str": "1.1.0", "description": "", "major": 1, "minor": 1, "patch": 0}, "splits": {"test": {"name": "test", "num_bytes": 265512, "num_examples": 1074, "dataset_name": "xcsr"}, "validation": {"name": "validation", "num_bytes": 253784, "num_examples": 1000, "dataset_name": "xcsr"}}, "download_checksums": {"https://inklab.usc.edu/XCSR/xcsr_datasets.zip": {"num_bytes": 7519903, "checksum": "c45b29ece740643252d5402e76be1e33f96f9d6910053f79e80d39887f10c85e"}}, "download_size": 7519903, "post_processing_size": null, "dataset_size": 519296, "size_in_bytes": 8039199}, "X-CSQA-hi": {"description": "To evaluate multi-lingual language models (ML-LMs) for commonsense reasoning in a cross-lingual zero-shot transfer setting (X-CSR), i.e., training in English and test in other languages, we create two benchmark datasets, namely X-CSQA and X-CODAH. Specifically, we automatically translate the original CSQA and CODAH datasets, which only have English versions, to 15 other languages, forming development and test sets for studying X-CSR. As our goal is to evaluate different ML-LMs in a unified evaluation protocol for X-CSR, we argue that such translated examples, although might contain noise, can serve as a starting benchmark for us to obtain meaningful analysis, before more human-translated datasets will be available in the future.\n", "citation": "# X-CSR\n@inproceedings{lin-etal-2021-common,\n    title = \"Common Sense Beyond {E}nglish: Evaluating and Improving Multilingual Language Models for Commonsense Reasoning\",\n    author = \"Lin, Bill Yuchen  and\n      Lee, Seyeon  and\n      Qiao, Xiaoyang  and\n      Ren, Xiang\",\n    booktitle = \"Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)\",\n    month = aug,\n    year = \"2021\",\n    address = \"Online\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2021.acl-long.102\",\n    doi = \"10.18653/v1/2021.acl-long.102\",\n    pages = \"1274--1287\",\n}\n\n# CSQA\n@inproceedings{Talmor2019commonsenseqaaq,\n    address = {Minneapolis, Minnesota},\n    author = {Talmor, Alon  and Herzig, Jonathan  and Lourie, Nicholas and Berant, Jonathan},\n    booktitle = {Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},\n    doi = {10.18653/v1/N19-1421},\n    pages = {4149--4158},\n    publisher = {Association for Computational Linguistics},\n    title = {CommonsenseQA: A Question Answering Challenge Targeting Commonsense Knowledge},\n    url = {https://www.aclweb.org/anthology/N19-1421},\n    year = {2019}\n}\n\n# CODAH\n@inproceedings{Chen2019CODAHAA,\n    address = {Minneapolis, USA},\n    author = {Chen, Michael  and D{'}Arcy, Mike  and Liu, Alisa  and Fernandez, Jared  and Downey, Doug},\n    booktitle = {Proceedings of the 3rd Workshop on Evaluating Vector Space Representations for {NLP}},\n    doi = {10.18653/v1/W19-2008},\n    pages = {63--69},\n    publisher = {Association for Computational Linguistics},\n    title = {CODAH: An Adversarially-Authored Question Answering Dataset for Common Sense},\n    url = {https://www.aclweb.org/anthology/W19-2008},\n    year = {2019}\n}\n", "homepage": "https://inklab.usc.edu//XCSR/", "license": "", "features": {"id": {"dtype": "string", "id": null, "_type": "Value"}, "lang": {"dtype": "string", "id": null, "_type": "Value"}, "question": {"stem": {"dtype": "string", "id": null, "_type": "Value"}, "choices": {"feature": {"label": {"dtype": "string", "id": null, "_type": "Value"}, "text": {"dtype": "string", "id": null, "_type": "Value"}}, "length": -1, "id": null, "_type": "Sequence"}}, "answerKey": {"dtype": "string", "id": null, "_type": "Value"}}, "post_processed": null, "supervised_keys": null, "task_templates": null, "builder_name": "xcsr", "config_name": "X-CSQA-hi", "version": {"version_str": "1.1.0", "description": "", "major": 1, "minor": 1, "patch": 0}, "splits": {"test": {"name": "test", "num_bytes": 415313, "num_examples": 1074, "dataset_name": "xcsr"}, "validation": {"name": "validation", "num_bytes": 396600, "num_examples": 1000, "dataset_name": "xcsr"}}, "download_checksums": {"https://inklab.usc.edu/XCSR/xcsr_datasets.zip": {"num_bytes": 7519903, "checksum": "c45b29ece740643252d5402e76be1e33f96f9d6910053f79e80d39887f10c85e"}}, "download_size": 7519903, "post_processing_size": null, "dataset_size": 811913, "size_in_bytes": 8331816}, "X-CSQA-sw": {"description": "To evaluate multi-lingual language models (ML-LMs) for commonsense reasoning in a cross-lingual zero-shot transfer setting (X-CSR), i.e., training in English and test in other languages, we create two benchmark datasets, namely X-CSQA and X-CODAH. Specifically, we automatically translate the original CSQA and CODAH datasets, which only have English versions, to 15 other languages, forming development and test sets for studying X-CSR. As our goal is to evaluate different ML-LMs in a unified evaluation protocol for X-CSR, we argue that such translated examples, although might contain noise, can serve as a starting benchmark for us to obtain meaningful analysis, before more human-translated datasets will be available in the future.\n", "citation": "# X-CSR\n@inproceedings{lin-etal-2021-common,\n    title = \"Common Sense Beyond {E}nglish: Evaluating and Improving Multilingual Language Models for Commonsense Reasoning\",\n    author = \"Lin, Bill Yuchen  and\n      Lee, Seyeon  and\n      Qiao, Xiaoyang  and\n      Ren, Xiang\",\n    booktitle = \"Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)\",\n    month = aug,\n    year = \"2021\",\n    address = \"Online\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2021.acl-long.102\",\n    doi = \"10.18653/v1/2021.acl-long.102\",\n    pages = \"1274--1287\",\n}\n\n# CSQA\n@inproceedings{Talmor2019commonsenseqaaq,\n    address = {Minneapolis, Minnesota},\n    author = {Talmor, Alon  and Herzig, Jonathan  and Lourie, Nicholas and Berant, Jonathan},\n    booktitle = {Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},\n    doi = {10.18653/v1/N19-1421},\n    pages = {4149--4158},\n    publisher = {Association for Computational Linguistics},\n    title = {CommonsenseQA: A Question Answering Challenge Targeting Commonsense Knowledge},\n    url = {https://www.aclweb.org/anthology/N19-1421},\n    year = {2019}\n}\n\n# CODAH\n@inproceedings{Chen2019CODAHAA,\n    address = {Minneapolis, USA},\n    author = {Chen, Michael  and D{'}Arcy, Mike  and Liu, Alisa  and Fernandez, Jared  and Downey, Doug},\n    booktitle = {Proceedings of the 3rd Workshop on Evaluating Vector Space Representations for {NLP}},\n    doi = {10.18653/v1/W19-2008},\n    pages = {63--69},\n    publisher = {Association for Computational Linguistics},\n    title = {CODAH: An Adversarially-Authored Question Answering Dataset for Common Sense},\n    url = {https://www.aclweb.org/anthology/W19-2008},\n    year = {2019}\n}\n", "homepage": "https://inklab.usc.edu//XCSR/", "license": "", "features": {"id": {"dtype": "string", "id": null, "_type": "Value"}, "lang": {"dtype": "string", "id": null, "_type": "Value"}, "question": {"stem": {"dtype": "string", "id": null, "_type": "Value"}, "choices": {"feature": {"label": {"dtype": "string", "id": null, "_type": "Value"}, "text": {"dtype": "string", "id": null, "_type": "Value"}}, "length": -1, "id": null, "_type": "Sequence"}}, "answerKey": {"dtype": "string", "id": null, "_type": "Value"}}, "post_processed": null, "supervised_keys": null, "task_templates": null, "builder_name": "xcsr", "config_name": "X-CSQA-sw", "version": {"version_str": "1.1.0", "description": "", "major": 1, "minor": 1, "patch": 0}, "splits": {"test": {"name": "test", "num_bytes": 222517, "num_examples": 1074, "dataset_name": "xcsr"}, "validation": {"name": "validation", "num_bytes": 211708, "num_examples": 1000, "dataset_name": "xcsr"}}, "download_checksums": {"https://inklab.usc.edu/XCSR/xcsr_datasets.zip": {"num_bytes": 7519903, "checksum": "c45b29ece740643252d5402e76be1e33f96f9d6910053f79e80d39887f10c85e"}}, "download_size": 7519903, "post_processing_size": null, "dataset_size": 434225, "size_in_bytes": 7954128}, "X-CSQA-ur": {"description": "To evaluate multi-lingual language models (ML-LMs) for commonsense reasoning in a cross-lingual zero-shot transfer setting (X-CSR), i.e., training in English and test in other languages, we create two benchmark datasets, namely X-CSQA and X-CODAH. Specifically, we automatically translate the original CSQA and CODAH datasets, which only have English versions, to 15 other languages, forming development and test sets for studying X-CSR. As our goal is to evaluate different ML-LMs in a unified evaluation protocol for X-CSR, we argue that such translated examples, although might contain noise, can serve as a starting benchmark for us to obtain meaningful analysis, before more human-translated datasets will be available in the future.\n", "citation": "# X-CSR\n@inproceedings{lin-etal-2021-common,\n    title = \"Common Sense Beyond {E}nglish: Evaluating and Improving Multilingual Language Models for Commonsense Reasoning\",\n    author = \"Lin, Bill Yuchen  and\n      Lee, Seyeon  and\n      Qiao, Xiaoyang  and\n      Ren, Xiang\",\n    booktitle = \"Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)\",\n    month = aug,\n    year = \"2021\",\n    address = \"Online\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2021.acl-long.102\",\n    doi = \"10.18653/v1/2021.acl-long.102\",\n    pages = \"1274--1287\",\n}\n\n# CSQA\n@inproceedings{Talmor2019commonsenseqaaq,\n    address = {Minneapolis, Minnesota},\n    author = {Talmor, Alon  and Herzig, Jonathan  and Lourie, Nicholas and Berant, Jonathan},\n    booktitle = {Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},\n    doi = {10.18653/v1/N19-1421},\n    pages = {4149--4158},\n    publisher = {Association for Computational Linguistics},\n    title = {CommonsenseQA: A Question Answering Challenge Targeting Commonsense Knowledge},\n    url = {https://www.aclweb.org/anthology/N19-1421},\n    year = {2019}\n}\n\n# CODAH\n@inproceedings{Chen2019CODAHAA,\n    address = {Minneapolis, USA},\n    author = {Chen, Michael  and D{'}Arcy, Mike  and Liu, Alisa  and Fernandez, Jared  and Downey, Doug},\n    booktitle = {Proceedings of the 3rd Workshop on Evaluating Vector Space Representations for {NLP}},\n    doi = {10.18653/v1/W19-2008},\n    pages = {63--69},\n    publisher = {Association for Computational Linguistics},\n    title = {CODAH: An Adversarially-Authored Question Answering Dataset for Common Sense},\n    url = {https://www.aclweb.org/anthology/W19-2008},\n    year = {2019}\n}\n", "homepage": "https://inklab.usc.edu//XCSR/", "license": "", "features": {"id": {"dtype": "string", "id": null, "_type": "Value"}, "lang": {"dtype": "string", "id": null, "_type": "Value"}, "question": {"stem": {"dtype": "string", "id": null, "_type": "Value"}, "choices": {"feature": {"label": {"dtype": "string", "id": null, "_type": "Value"}, "text": {"dtype": "string", "id": null, "_type": "Value"}}, "length": -1, "id": null, "_type": "Sequence"}}, "answerKey": {"dtype": "string", "id": null, "_type": "Value"}}, "post_processed": null, "supervised_keys": null, "task_templates": null, "builder_name": "xcsr", "config_name": "X-CSQA-ur", "version": {"version_str": "1.1.0", "description": "", "major": 1, "minor": 1, "patch": 0}, "splits": {"test": {"name": "test", "num_bytes": 306431, "num_examples": 1074, "dataset_name": "xcsr"}, "validation": {"name": "validation", "num_bytes": 292283, "num_examples": 1000, "dataset_name": "xcsr"}}, "download_checksums": {"https://inklab.usc.edu/XCSR/xcsr_datasets.zip": {"num_bytes": 7519903, "checksum": "c45b29ece740643252d5402e76be1e33f96f9d6910053f79e80d39887f10c85e"}}, "download_size": 7519903, "post_processing_size": null, "dataset_size": 598714, "size_in_bytes": 8118617}, "X-CODAH-en": {"description": "To evaluate multi-lingual language models (ML-LMs) for commonsense reasoning in a cross-lingual zero-shot transfer setting (X-CSR), i.e., training in English and test in other languages, we create two benchmark datasets, namely X-CSQA and X-CODAH. Specifically, we automatically translate the original CSQA and CODAH datasets, which only have English versions, to 15 other languages, forming development and test sets for studying X-CSR. As our goal is to evaluate different ML-LMs in a unified evaluation protocol for X-CSR, we argue that such translated examples, although might contain noise, can serve as a starting benchmark for us to obtain meaningful analysis, before more human-translated datasets will be available in the future.\n", "citation": "# X-CSR\n@inproceedings{lin-etal-2021-common,\n    title = \"Common Sense Beyond {E}nglish: Evaluating and Improving Multilingual Language Models for Commonsense Reasoning\",\n    author = \"Lin, Bill Yuchen  and\n      Lee, Seyeon  and\n      Qiao, Xiaoyang  and\n      Ren, Xiang\",\n    booktitle = \"Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)\",\n    month = aug,\n    year = \"2021\",\n    address = \"Online\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2021.acl-long.102\",\n    doi = \"10.18653/v1/2021.acl-long.102\",\n    pages = \"1274--1287\",\n}\n\n# CSQA\n@inproceedings{Talmor2019commonsenseqaaq,\n    address = {Minneapolis, Minnesota},\n    author = {Talmor, Alon  and Herzig, Jonathan  and Lourie, Nicholas and Berant, Jonathan},\n    booktitle = {Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},\n    doi = {10.18653/v1/N19-1421},\n    pages = {4149--4158},\n    publisher = {Association for Computational Linguistics},\n    title = {CommonsenseQA: A Question Answering Challenge Targeting Commonsense Knowledge},\n    url = {https://www.aclweb.org/anthology/N19-1421},\n    year = {2019}\n}\n\n# CODAH\n@inproceedings{Chen2019CODAHAA,\n    address = {Minneapolis, USA},\n    author = {Chen, Michael  and D{'}Arcy, Mike  and Liu, Alisa  and Fernandez, Jared  and Downey, Doug},\n    booktitle = {Proceedings of the 3rd Workshop on Evaluating Vector Space Representations for {NLP}},\n    doi = {10.18653/v1/W19-2008},\n    pages = {63--69},\n    publisher = {Association for Computational Linguistics},\n    title = {CODAH: An Adversarially-Authored Question Answering Dataset for Common Sense},\n    url = {https://www.aclweb.org/anthology/W19-2008},\n    year = {2019}\n}\n", "homepage": "https://inklab.usc.edu//XCSR/", "license": "", "features": {"id": {"dtype": "string", "id": null, "_type": "Value"}, "lang": {"dtype": "string", "id": null, "_type": "Value"}, "question_tag": {"dtype": "string", "id": null, "_type": "Value"}, "question": {"stem": {"dtype": "string", "id": null, "_type": "Value"}, "choices": {"feature": {"label": {"dtype": "string", "id": null, "_type": "Value"}, "text": {"dtype": "string", "id": null, "_type": "Value"}}, "length": -1, "id": null, "_type": "Sequence"}}, "answerKey": {"dtype": "string", "id": null, "_type": "Value"}}, "post_processed": null, "supervised_keys": null, "task_templates": null, "builder_name": "xcsr", "config_name": "X-CODAH-en", "version": {"version_str": "1.1.0", "description": "", "major": 1, "minor": 1, "patch": 0}, "splits": {"test": {"name": "test", "num_bytes": 417286, "num_examples": 1000, "dataset_name": "xcsr"}, "validation": {"name": "validation", "num_bytes": 121923, "num_examples": 300, "dataset_name": "xcsr"}}, "download_checksums": {"https://inklab.usc.edu/XCSR/xcsr_datasets.zip": {"num_bytes": 7519903, "checksum": "c45b29ece740643252d5402e76be1e33f96f9d6910053f79e80d39887f10c85e"}}, "download_size": 7519903, "post_processing_size": null, "dataset_size": 539209, "size_in_bytes": 8059112}, "X-CODAH-zh": {"description": "To evaluate multi-lingual language models (ML-LMs) for commonsense reasoning in a cross-lingual zero-shot transfer setting (X-CSR), i.e., training in English and test in other languages, we create two benchmark datasets, namely X-CSQA and X-CODAH. Specifically, we automatically translate the original CSQA and CODAH datasets, which only have English versions, to 15 other languages, forming development and test sets for studying X-CSR. As our goal is to evaluate different ML-LMs in a unified evaluation protocol for X-CSR, we argue that such translated examples, although might contain noise, can serve as a starting benchmark for us to obtain meaningful analysis, before more human-translated datasets will be available in the future.\n", "citation": "# X-CSR\n@inproceedings{lin-etal-2021-common,\n    title = \"Common Sense Beyond {E}nglish: Evaluating and Improving Multilingual Language Models for Commonsense Reasoning\",\n    author = \"Lin, Bill Yuchen  and\n      Lee, Seyeon  and\n      Qiao, Xiaoyang  and\n      Ren, Xiang\",\n    booktitle = \"Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)\",\n    month = aug,\n    year = \"2021\",\n    address = \"Online\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2021.acl-long.102\",\n    doi = \"10.18653/v1/2021.acl-long.102\",\n    pages = \"1274--1287\",\n}\n\n# CSQA\n@inproceedings{Talmor2019commonsenseqaaq,\n    address = {Minneapolis, Minnesota},\n    author = {Talmor, Alon  and Herzig, Jonathan  and Lourie, Nicholas and Berant, Jonathan},\n    booktitle = {Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},\n    doi = {10.18653/v1/N19-1421},\n    pages = {4149--4158},\n    publisher = {Association for Computational Linguistics},\n    title = {CommonsenseQA: A Question Answering Challenge Targeting Commonsense Knowledge},\n    url = {https://www.aclweb.org/anthology/N19-1421},\n    year = {2019}\n}\n\n# CODAH\n@inproceedings{Chen2019CODAHAA,\n    address = {Minneapolis, USA},\n    author = {Chen, Michael  and D{'}Arcy, Mike  and Liu, Alisa  and Fernandez, Jared  and Downey, Doug},\n    booktitle = {Proceedings of the 3rd Workshop on Evaluating Vector Space Representations for {NLP}},\n    doi = {10.18653/v1/W19-2008},\n    pages = {63--69},\n    publisher = {Association for Computational Linguistics},\n    title = {CODAH: An Adversarially-Authored Question Answering Dataset for Common Sense},\n    url = {https://www.aclweb.org/anthology/W19-2008},\n    year = {2019}\n}\n", "homepage": "https://inklab.usc.edu//XCSR/", "license": "", "features": {"id": {"dtype": "string", "id": null, "_type": "Value"}, "lang": {"dtype": "string", "id": null, "_type": "Value"}, "question_tag": {"dtype": "string", "id": null, "_type": "Value"}, "question": {"stem": {"dtype": "string", "id": null, "_type": "Value"}, "choices": {"feature": {"label": {"dtype": "string", "id": null, "_type": "Value"}, "text": {"dtype": "string", "id": null, "_type": "Value"}}, "length": -1, "id": null, "_type": "Sequence"}}, "answerKey": {"dtype": "string", "id": null, "_type": "Value"}}, "post_processed": null, "supervised_keys": null, "task_templates": null, "builder_name": "xcsr", "config_name": "X-CODAH-zh", "version": {"version_str": "1.1.0", "description": "", "major": 1, "minor": 1, "patch": 0}, "splits": {"test": {"name": "test", "num_bytes": 394946, "num_examples": 1000, "dataset_name": "xcsr"}, "validation": {"name": "validation", "num_bytes": 115137, "num_examples": 300, "dataset_name": "xcsr"}}, "download_checksums": {"https://inklab.usc.edu/XCSR/xcsr_datasets.zip": {"num_bytes": 7519903, "checksum": "c45b29ece740643252d5402e76be1e33f96f9d6910053f79e80d39887f10c85e"}}, "download_size": 7519903, "post_processing_size": null, "dataset_size": 510083, "size_in_bytes": 8029986}, "X-CODAH-de": {"description": "To evaluate multi-lingual language models (ML-LMs) for commonsense reasoning in a cross-lingual zero-shot transfer setting (X-CSR), i.e., training in English and test in other languages, we create two benchmark datasets, namely X-CSQA and X-CODAH. Specifically, we automatically translate the original CSQA and CODAH datasets, which only have English versions, to 15 other languages, forming development and test sets for studying X-CSR. As our goal is to evaluate different ML-LMs in a unified evaluation protocol for X-CSR, we argue that such translated examples, although might contain noise, can serve as a starting benchmark for us to obtain meaningful analysis, before more human-translated datasets will be available in the future.\n", "citation": "# X-CSR\n@inproceedings{lin-etal-2021-common,\n    title = \"Common Sense Beyond {E}nglish: Evaluating and Improving Multilingual Language Models for Commonsense Reasoning\",\n    author = \"Lin, Bill Yuchen  and\n      Lee, Seyeon  and\n      Qiao, Xiaoyang  and\n      Ren, Xiang\",\n    booktitle = \"Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)\",\n    month = aug,\n    year = \"2021\",\n    address = \"Online\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2021.acl-long.102\",\n    doi = \"10.18653/v1/2021.acl-long.102\",\n    pages = \"1274--1287\",\n}\n\n# CSQA\n@inproceedings{Talmor2019commonsenseqaaq,\n    address = {Minneapolis, Minnesota},\n    author = {Talmor, Alon  and Herzig, Jonathan  and Lourie, Nicholas and Berant, Jonathan},\n    booktitle = {Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},\n    doi = {10.18653/v1/N19-1421},\n    pages = {4149--4158},\n    publisher = {Association for Computational Linguistics},\n    title = {CommonsenseQA: A Question Answering Challenge Targeting Commonsense Knowledge},\n    url = {https://www.aclweb.org/anthology/N19-1421},\n    year = {2019}\n}\n\n# CODAH\n@inproceedings{Chen2019CODAHAA,\n    address = {Minneapolis, USA},\n    author = {Chen, Michael  and D{'}Arcy, Mike  and Liu, Alisa  and Fernandez, Jared  and Downey, Doug},\n    booktitle = {Proceedings of the 3rd Workshop on Evaluating Vector Space Representations for {NLP}},\n    doi = {10.18653/v1/W19-2008},\n    pages = {63--69},\n    publisher = {Association for Computational Linguistics},\n    title = {CODAH: An Adversarially-Authored Question Answering Dataset for Common Sense},\n    url = {https://www.aclweb.org/anthology/W19-2008},\n    year = {2019}\n}\n", "homepage": "https://inklab.usc.edu//XCSR/", "license": "", "features": {"id": {"dtype": "string", "id": null, "_type": "Value"}, "lang": {"dtype": "string", "id": null, "_type": "Value"}, "question_tag": {"dtype": "string", "id": null, "_type": "Value"}, "question": {"stem": {"dtype": "string", "id": null, "_type": "Value"}, "choices": {"feature": {"label": {"dtype": "string", "id": null, "_type": "Value"}, "text": {"dtype": "string", "id": null, "_type": "Value"}}, "length": -1, "id": null, "_type": "Sequence"}}, "answerKey": {"dtype": "string", "id": null, "_type": "Value"}}, "post_processed": null, "supervised_keys": null, "task_templates": null, "builder_name": "xcsr", "config_name": "X-CODAH-de", "version": {"version_str": "1.1.0", "description": "", "major": 1, "minor": 1, "patch": 0}, "splits": {"test": {"name": "test", "num_bytes": 476373, "num_examples": 1000, "dataset_name": "xcsr"}, "validation": {"name": "validation", "num_bytes": 138876, "num_examples": 300, "dataset_name": "xcsr"}}, "download_checksums": {"https://inklab.usc.edu/XCSR/xcsr_datasets.zip": {"num_bytes": 7519903, "checksum": "c45b29ece740643252d5402e76be1e33f96f9d6910053f79e80d39887f10c85e"}}, "download_size": 7519903, "post_processing_size": null, "dataset_size": 615249, "size_in_bytes": 8135152}, "X-CODAH-es": {"description": "To evaluate multi-lingual language models (ML-LMs) for commonsense reasoning in a cross-lingual zero-shot transfer setting (X-CSR), i.e., training in English and test in other languages, we create two benchmark datasets, namely X-CSQA and X-CODAH. Specifically, we automatically translate the original CSQA and CODAH datasets, which only have English versions, to 15 other languages, forming development and test sets for studying X-CSR. As our goal is to evaluate different ML-LMs in a unified evaluation protocol for X-CSR, we argue that such translated examples, although might contain noise, can serve as a starting benchmark for us to obtain meaningful analysis, before more human-translated datasets will be available in the future.\n", "citation": "# X-CSR\n@inproceedings{lin-etal-2021-common,\n    title = \"Common Sense Beyond {E}nglish: Evaluating and Improving Multilingual Language Models for Commonsense Reasoning\",\n    author = \"Lin, Bill Yuchen  and\n      Lee, Seyeon  and\n      Qiao, Xiaoyang  and\n      Ren, Xiang\",\n    booktitle = \"Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)\",\n    month = aug,\n    year = \"2021\",\n    address = \"Online\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2021.acl-long.102\",\n    doi = \"10.18653/v1/2021.acl-long.102\",\n    pages = \"1274--1287\",\n}\n\n# CSQA\n@inproceedings{Talmor2019commonsenseqaaq,\n    address = {Minneapolis, Minnesota},\n    author = {Talmor, Alon  and Herzig, Jonathan  and Lourie, Nicholas and Berant, Jonathan},\n    booktitle = {Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},\n    doi = {10.18653/v1/N19-1421},\n    pages = {4149--4158},\n    publisher = {Association for Computational Linguistics},\n    title = {CommonsenseQA: A Question Answering Challenge Targeting Commonsense Knowledge},\n    url = {https://www.aclweb.org/anthology/N19-1421},\n    year = {2019}\n}\n\n# CODAH\n@inproceedings{Chen2019CODAHAA,\n    address = {Minneapolis, USA},\n    author = {Chen, Michael  and D{'}Arcy, Mike  and Liu, Alisa  and Fernandez, Jared  and Downey, Doug},\n    booktitle = {Proceedings of the 3rd Workshop on Evaluating Vector Space Representations for {NLP}},\n    doi = {10.18653/v1/W19-2008},\n    pages = {63--69},\n    publisher = {Association for Computational Linguistics},\n    title = {CODAH: An Adversarially-Authored Question Answering Dataset for Common Sense},\n    url = {https://www.aclweb.org/anthology/W19-2008},\n    year = {2019}\n}\n", "homepage": "https://inklab.usc.edu//XCSR/", "license": "", "features": {"id": {"dtype": "string", "id": null, "_type": "Value"}, "lang": {"dtype": "string", "id": null, "_type": "Value"}, "question_tag": {"dtype": "string", "id": null, "_type": "Value"}, "question": {"stem": {"dtype": "string", "id": null, "_type": "Value"}, "choices": {"feature": {"label": {"dtype": "string", "id": null, "_type": "Value"}, "text": {"dtype": "string", "id": null, "_type": "Value"}}, "length": -1, "id": null, "_type": "Sequence"}}, "answerKey": {"dtype": "string", "id": null, "_type": "Value"}}, "post_processed": null, "supervised_keys": null, "task_templates": null, "builder_name": "xcsr", "config_name": "X-CODAH-es", "version": {"version_str": "1.1.0", "description": "", "major": 1, "minor": 1, "patch": 0}, "splits": {"test": {"name": "test", "num_bytes": 451240, "num_examples": 1000, "dataset_name": "xcsr"}, "validation": {"name": "validation", "num_bytes": 130790, "num_examples": 300, "dataset_name": "xcsr"}}, "download_checksums": {"https://inklab.usc.edu/XCSR/xcsr_datasets.zip": {"num_bytes": 7519903, "checksum": "c45b29ece740643252d5402e76be1e33f96f9d6910053f79e80d39887f10c85e"}}, "download_size": 7519903, "post_processing_size": null, "dataset_size": 582030, "size_in_bytes": 8101933}, "X-CODAH-fr": {"description": "To evaluate multi-lingual language models (ML-LMs) for commonsense reasoning in a cross-lingual zero-shot transfer setting (X-CSR), i.e., training in English and test in other languages, we create two benchmark datasets, namely X-CSQA and X-CODAH. Specifically, we automatically translate the original CSQA and CODAH datasets, which only have English versions, to 15 other languages, forming development and test sets for studying X-CSR. As our goal is to evaluate different ML-LMs in a unified evaluation protocol for X-CSR, we argue that such translated examples, although might contain noise, can serve as a starting benchmark for us to obtain meaningful analysis, before more human-translated datasets will be available in the future.\n", "citation": "# X-CSR\n@inproceedings{lin-etal-2021-common,\n    title = \"Common Sense Beyond {E}nglish: Evaluating and Improving Multilingual Language Models for Commonsense Reasoning\",\n    author = \"Lin, Bill Yuchen  and\n      Lee, Seyeon  and\n      Qiao, Xiaoyang  and\n      Ren, Xiang\",\n    booktitle = \"Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)\",\n    month = aug,\n    year = \"2021\",\n    address = \"Online\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2021.acl-long.102\",\n    doi = \"10.18653/v1/2021.acl-long.102\",\n    pages = \"1274--1287\",\n}\n\n# CSQA\n@inproceedings{Talmor2019commonsenseqaaq,\n    address = {Minneapolis, Minnesota},\n    author = {Talmor, Alon  and Herzig, Jonathan  and Lourie, Nicholas and Berant, Jonathan},\n    booktitle = {Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},\n    doi = {10.18653/v1/N19-1421},\n    pages = {4149--4158},\n    publisher = {Association for Computational Linguistics},\n    title = {CommonsenseQA: A Question Answering Challenge Targeting Commonsense Knowledge},\n    url = {https://www.aclweb.org/anthology/N19-1421},\n    year = {2019}\n}\n\n# CODAH\n@inproceedings{Chen2019CODAHAA,\n    address = {Minneapolis, USA},\n    author = {Chen, Michael  and D{'}Arcy, Mike  and Liu, Alisa  and Fernandez, Jared  and Downey, Doug},\n    booktitle = {Proceedings of the 3rd Workshop on Evaluating Vector Space Representations for {NLP}},\n    doi = {10.18653/v1/W19-2008},\n    pages = {63--69},\n    publisher = {Association for Computational Linguistics},\n    title = {CODAH: An Adversarially-Authored Question Answering Dataset for Common Sense},\n    url = {https://www.aclweb.org/anthology/W19-2008},\n    year = {2019}\n}\n", "homepage": "https://inklab.usc.edu//XCSR/", "license": "", "features": {"id": {"dtype": "string", "id": null, "_type": "Value"}, "lang": {"dtype": "string", "id": null, "_type": "Value"}, "question_tag": {"dtype": "string", "id": null, "_type": "Value"}, "question": {"stem": {"dtype": "string", "id": null, "_type": "Value"}, "choices": {"feature": {"label": {"dtype": "string", "id": null, "_type": "Value"}, "text": {"dtype": "string", "id": null, "_type": "Value"}}, "length": -1, "id": null, "_type": "Sequence"}}, "answerKey": {"dtype": "string", "id": null, "_type": "Value"}}, "post_processed": null, "supervised_keys": null, "task_templates": null, "builder_name": "xcsr", "config_name": "X-CODAH-fr", "version": {"version_str": "1.1.0", "description": "", "major": 1, "minor": 1, "patch": 0}, "splits": {"test": {"name": "test", "num_bytes": 477811, "num_examples": 1000, "dataset_name": "xcsr"}, "validation": {"name": "validation", "num_bytes": 138001, "num_examples": 300, "dataset_name": "xcsr"}}, "download_checksums": {"https://inklab.usc.edu/XCSR/xcsr_datasets.zip": {"num_bytes": 7519903, "checksum": "c45b29ece740643252d5402e76be1e33f96f9d6910053f79e80d39887f10c85e"}}, "download_size": 7519903, "post_processing_size": null, "dataset_size": 615812, "size_in_bytes": 8135715}, "X-CODAH-it": {"description": "To evaluate multi-lingual language models (ML-LMs) for commonsense reasoning in a cross-lingual zero-shot transfer setting (X-CSR), i.e., training in English and test in other languages, we create two benchmark datasets, namely X-CSQA and X-CODAH. Specifically, we automatically translate the original CSQA and CODAH datasets, which only have English versions, to 15 other languages, forming development and test sets for studying X-CSR. As our goal is to evaluate different ML-LMs in a unified evaluation protocol for X-CSR, we argue that such translated examples, although might contain noise, can serve as a starting benchmark for us to obtain meaningful analysis, before more human-translated datasets will be available in the future.\n", "citation": "# X-CSR\n@inproceedings{lin-etal-2021-common,\n    title = \"Common Sense Beyond {E}nglish: Evaluating and Improving Multilingual Language Models for Commonsense Reasoning\",\n    author = \"Lin, Bill Yuchen  and\n      Lee, Seyeon  and\n      Qiao, Xiaoyang  and\n      Ren, Xiang\",\n    booktitle = \"Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)\",\n    month = aug,\n    year = \"2021\",\n    address = \"Online\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2021.acl-long.102\",\n    doi = \"10.18653/v1/2021.acl-long.102\",\n    pages = \"1274--1287\",\n}\n\n# CSQA\n@inproceedings{Talmor2019commonsenseqaaq,\n    address = {Minneapolis, Minnesota},\n    author = {Talmor, Alon  and Herzig, Jonathan  and Lourie, Nicholas and Berant, Jonathan},\n    booktitle = {Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},\n    doi = {10.18653/v1/N19-1421},\n    pages = {4149--4158},\n    publisher = {Association for Computational Linguistics},\n    title = {CommonsenseQA: A Question Answering Challenge Targeting Commonsense Knowledge},\n    url = {https://www.aclweb.org/anthology/N19-1421},\n    year = {2019}\n}\n\n# CODAH\n@inproceedings{Chen2019CODAHAA,\n    address = {Minneapolis, USA},\n    author = {Chen, Michael  and D{'}Arcy, Mike  and Liu, Alisa  and Fernandez, Jared  and Downey, Doug},\n    booktitle = {Proceedings of the 3rd Workshop on Evaluating Vector Space Representations for {NLP}},\n    doi = {10.18653/v1/W19-2008},\n    pages = {63--69},\n    publisher = {Association for Computational Linguistics},\n    title = {CODAH: An Adversarially-Authored Question Answering Dataset for Common Sense},\n    url = {https://www.aclweb.org/anthology/W19-2008},\n    year = {2019}\n}\n", "homepage": "https://inklab.usc.edu//XCSR/", "license": "", "features": {"id": {"dtype": "string", "id": null, "_type": "Value"}, "lang": {"dtype": "string", "id": null, "_type": "Value"}, "question_tag": {"dtype": "string", "id": null, "_type": "Value"}, "question": {"stem": {"dtype": "string", "id": null, "_type": "Value"}, "choices": {"feature": {"label": {"dtype": "string", "id": null, "_type": "Value"}, "text": {"dtype": "string", "id": null, "_type": "Value"}}, "length": -1, "id": null, "_type": "Sequence"}}, "answerKey": {"dtype": "string", "id": null, "_type": "Value"}}, "post_processed": null, "supervised_keys": null, "task_templates": null, "builder_name": "xcsr", "config_name": "X-CODAH-it", "version": {"version_str": "1.1.0", "description": "", "major": 1, "minor": 1, "patch": 0}, "splits": {"test": {"name": "test", "num_bytes": 457341, "num_examples": 1000, "dataset_name": "xcsr"}, "validation": {"name": "validation", "num_bytes": 133616, "num_examples": 300, "dataset_name": "xcsr"}}, "download_checksums": {"https://inklab.usc.edu/XCSR/xcsr_datasets.zip": {"num_bytes": 7519903, "checksum": "c45b29ece740643252d5402e76be1e33f96f9d6910053f79e80d39887f10c85e"}}, "download_size": 7519903, "post_processing_size": null, "dataset_size": 590957, "size_in_bytes": 8110860}, "X-CODAH-jap": {"description": "To evaluate multi-lingual language models (ML-LMs) for commonsense reasoning in a cross-lingual zero-shot transfer setting (X-CSR), i.e., training in English and test in other languages, we create two benchmark datasets, namely X-CSQA and X-CODAH. Specifically, we automatically translate the original CSQA and CODAH datasets, which only have English versions, to 15 other languages, forming development and test sets for studying X-CSR. As our goal is to evaluate different ML-LMs in a unified evaluation protocol for X-CSR, we argue that such translated examples, although might contain noise, can serve as a starting benchmark for us to obtain meaningful analysis, before more human-translated datasets will be available in the future.\n", "citation": "# X-CSR\n@inproceedings{lin-etal-2021-common,\n    title = \"Common Sense Beyond {E}nglish: Evaluating and Improving Multilingual Language Models for Commonsense Reasoning\",\n    author = \"Lin, Bill Yuchen  and\n      Lee, Seyeon  and\n      Qiao, Xiaoyang  and\n      Ren, Xiang\",\n    booktitle = \"Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)\",\n    month = aug,\n    year = \"2021\",\n    address = \"Online\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2021.acl-long.102\",\n    doi = \"10.18653/v1/2021.acl-long.102\",\n    pages = \"1274--1287\",\n}\n\n# CSQA\n@inproceedings{Talmor2019commonsenseqaaq,\n    address = {Minneapolis, Minnesota},\n    author = {Talmor, Alon  and Herzig, Jonathan  and Lourie, Nicholas and Berant, Jonathan},\n    booktitle = {Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},\n    doi = {10.18653/v1/N19-1421},\n    pages = {4149--4158},\n    publisher = {Association for Computational Linguistics},\n    title = {CommonsenseQA: A Question Answering Challenge Targeting Commonsense Knowledge},\n    url = {https://www.aclweb.org/anthology/N19-1421},\n    year = {2019}\n}\n\n# CODAH\n@inproceedings{Chen2019CODAHAA,\n    address = {Minneapolis, USA},\n    author = {Chen, Michael  and D{'}Arcy, Mike  and Liu, Alisa  and Fernandez, Jared  and Downey, Doug},\n    booktitle = {Proceedings of the 3rd Workshop on Evaluating Vector Space Representations for {NLP}},\n    doi = {10.18653/v1/W19-2008},\n    pages = {63--69},\n    publisher = {Association for Computational Linguistics},\n    title = {CODAH: An Adversarially-Authored Question Answering Dataset for Common Sense},\n    url = {https://www.aclweb.org/anthology/W19-2008},\n    year = {2019}\n}\n", "homepage": "https://inklab.usc.edu//XCSR/", "license": "", "features": {"id": {"dtype": "string", "id": null, "_type": "Value"}, "lang": {"dtype": "string", "id": null, "_type": "Value"}, "question_tag": {"dtype": "string", "id": null, "_type": "Value"}, "question": {"stem": {"dtype": "string", "id": null, "_type": "Value"}, "choices": {"feature": {"label": {"dtype": "string", "id": null, "_type": "Value"}, "text": {"dtype": "string", "id": null, "_type": "Value"}}, "length": -1, "id": null, "_type": "Sequence"}}, "answerKey": {"dtype": "string", "id": null, "_type": "Value"}}, "post_processed": null, "supervised_keys": null, "task_templates": null, "builder_name": "xcsr", "config_name": "X-CODAH-jap", "version": {"version_str": "1.1.0", "description": "", "major": 1, "minor": 1, "patch": 0}, "splits": {"test": {"name": "test", "num_bytes": 538701, "num_examples": 1000, "dataset_name": "xcsr"}, "validation": {"name": "validation", "num_bytes": 157504, "num_examples": 300, "dataset_name": "xcsr"}}, "download_checksums": {"https://inklab.usc.edu/XCSR/xcsr_datasets.zip": {"num_bytes": 7519903, "checksum": "c45b29ece740643252d5402e76be1e33f96f9d6910053f79e80d39887f10c85e"}}, "download_size": 7519903, "post_processing_size": null, "dataset_size": 696205, "size_in_bytes": 8216108}, "X-CODAH-nl": {"description": "To evaluate multi-lingual language models (ML-LMs) for commonsense reasoning in a cross-lingual zero-shot transfer setting (X-CSR), i.e., training in English and test in other languages, we create two benchmark datasets, namely X-CSQA and X-CODAH. Specifically, we automatically translate the original CSQA and CODAH datasets, which only have English versions, to 15 other languages, forming development and test sets for studying X-CSR. As our goal is to evaluate different ML-LMs in a unified evaluation protocol for X-CSR, we argue that such translated examples, although might contain noise, can serve as a starting benchmark for us to obtain meaningful analysis, before more human-translated datasets will be available in the future.\n", "citation": "# X-CSR\n@inproceedings{lin-etal-2021-common,\n    title = \"Common Sense Beyond {E}nglish: Evaluating and Improving Multilingual Language Models for Commonsense Reasoning\",\n    author = \"Lin, Bill Yuchen  and\n      Lee, Seyeon  and\n      Qiao, Xiaoyang  and\n      Ren, Xiang\",\n    booktitle = \"Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)\",\n    month = aug,\n    year = \"2021\",\n    address = \"Online\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2021.acl-long.102\",\n    doi = \"10.18653/v1/2021.acl-long.102\",\n    pages = \"1274--1287\",\n}\n\n# CSQA\n@inproceedings{Talmor2019commonsenseqaaq,\n    address = {Minneapolis, Minnesota},\n    author = {Talmor, Alon  and Herzig, Jonathan  and Lourie, Nicholas and Berant, Jonathan},\n    booktitle = {Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},\n    doi = {10.18653/v1/N19-1421},\n    pages = {4149--4158},\n    publisher = {Association for Computational Linguistics},\n    title = {CommonsenseQA: A Question Answering Challenge Targeting Commonsense Knowledge},\n    url = {https://www.aclweb.org/anthology/N19-1421},\n    year = {2019}\n}\n\n# CODAH\n@inproceedings{Chen2019CODAHAA,\n    address = {Minneapolis, USA},\n    author = {Chen, Michael  and D{'}Arcy, Mike  and Liu, Alisa  and Fernandez, Jared  and Downey, Doug},\n    booktitle = {Proceedings of the 3rd Workshop on Evaluating Vector Space Representations for {NLP}},\n    doi = {10.18653/v1/W19-2008},\n    pages = {63--69},\n    publisher = {Association for Computational Linguistics},\n    title = {CODAH: An Adversarially-Authored Question Answering Dataset for Common Sense},\n    url = {https://www.aclweb.org/anthology/W19-2008},\n    year = {2019}\n}\n", "homepage": "https://inklab.usc.edu//XCSR/", "license": "", "features": {"id": {"dtype": "string", "id": null, "_type": "Value"}, "lang": {"dtype": "string", "id": null, "_type": "Value"}, "question_tag": {"dtype": "string", "id": null, "_type": "Value"}, "question": {"stem": {"dtype": "string", "id": null, "_type": "Value"}, "choices": {"feature": {"label": {"dtype": "string", "id": null, "_type": "Value"}, "text": {"dtype": "string", "id": null, "_type": "Value"}}, "length": -1, "id": null, "_type": "Sequence"}}, "answerKey": {"dtype": "string", "id": null, "_type": "Value"}}, "post_processed": null, "supervised_keys": null, "task_templates": null, "builder_name": "xcsr", "config_name": "X-CODAH-nl", "version": {"version_str": "1.1.0", "description": "", "major": 1, "minor": 1, "patch": 0}, "splits": {"test": {"name": "test", "num_bytes": 449014, "num_examples": 1000, "dataset_name": "xcsr"}, "validation": {"name": "validation", "num_bytes": 130130, "num_examples": 300, "dataset_name": "xcsr"}}, "download_checksums": {"https://inklab.usc.edu/XCSR/xcsr_datasets.zip": {"num_bytes": 7519903, "checksum": "c45b29ece740643252d5402e76be1e33f96f9d6910053f79e80d39887f10c85e"}}, "download_size": 7519903, "post_processing_size": null, "dataset_size": 579144, "size_in_bytes": 8099047}, "X-CODAH-pl": {"description": "To evaluate multi-lingual language models (ML-LMs) for commonsense reasoning in a cross-lingual zero-shot transfer setting (X-CSR), i.e., training in English and test in other languages, we create two benchmark datasets, namely X-CSQA and X-CODAH. Specifically, we automatically translate the original CSQA and CODAH datasets, which only have English versions, to 15 other languages, forming development and test sets for studying X-CSR. As our goal is to evaluate different ML-LMs in a unified evaluation protocol for X-CSR, we argue that such translated examples, although might contain noise, can serve as a starting benchmark for us to obtain meaningful analysis, before more human-translated datasets will be available in the future.\n", "citation": "# X-CSR\n@inproceedings{lin-etal-2021-common,\n    title = \"Common Sense Beyond {E}nglish: Evaluating and Improving Multilingual Language Models for Commonsense Reasoning\",\n    author = \"Lin, Bill Yuchen  and\n      Lee, Seyeon  and\n      Qiao, Xiaoyang  and\n      Ren, Xiang\",\n    booktitle = \"Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)\",\n    month = aug,\n    year = \"2021\",\n    address = \"Online\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2021.acl-long.102\",\n    doi = \"10.18653/v1/2021.acl-long.102\",\n    pages = \"1274--1287\",\n}\n\n# CSQA\n@inproceedings{Talmor2019commonsenseqaaq,\n    address = {Minneapolis, Minnesota},\n    author = {Talmor, Alon  and Herzig, Jonathan  and Lourie, Nicholas and Berant, Jonathan},\n    booktitle = {Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},\n    doi = {10.18653/v1/N19-1421},\n    pages = {4149--4158},\n    publisher = {Association for Computational Linguistics},\n    title = {CommonsenseQA: A Question Answering Challenge Targeting Commonsense Knowledge},\n    url = {https://www.aclweb.org/anthology/N19-1421},\n    year = {2019}\n}\n\n# CODAH\n@inproceedings{Chen2019CODAHAA,\n    address = {Minneapolis, USA},\n    author = {Chen, Michael  and D{'}Arcy, Mike  and Liu, Alisa  and Fernandez, Jared  and Downey, Doug},\n    booktitle = {Proceedings of the 3rd Workshop on Evaluating Vector Space Representations for {NLP}},\n    doi = {10.18653/v1/W19-2008},\n    pages = {63--69},\n    publisher = {Association for Computational Linguistics},\n    title = {CODAH: An Adversarially-Authored Question Answering Dataset for Common Sense},\n    url = {https://www.aclweb.org/anthology/W19-2008},\n    year = {2019}\n}\n", "homepage": "https://inklab.usc.edu//XCSR/", "license": "", "features": {"id": {"dtype": "string", "id": null, "_type": "Value"}, "lang": {"dtype": "string", "id": null, "_type": "Value"}, "question_tag": {"dtype": "string", "id": null, "_type": "Value"}, "question": {"stem": {"dtype": "string", "id": null, "_type": "Value"}, "choices": {"feature": {"label": {"dtype": "string", "id": null, "_type": "Value"}, "text": {"dtype": "string", "id": null, "_type": "Value"}}, "length": -1, "id": null, "_type": "Sequence"}}, "answerKey": {"dtype": "string", "id": null, "_type": "Value"}}, "post_processed": null, "supervised_keys": null, "task_templates": null, "builder_name": "xcsr", "config_name": "X-CODAH-pl", "version": {"version_str": "1.1.0", "description": "", "major": 1, "minor": 1, "patch": 0}, "splits": {"test": {"name": "test", "num_bytes": 438824, "num_examples": 1000, "dataset_name": "xcsr"}, "validation": {"name": "validation", "num_bytes": 127862, "num_examples": 300, "dataset_name": "xcsr"}}, "download_checksums": {"https://inklab.usc.edu/XCSR/xcsr_datasets.zip": {"num_bytes": 7519903, "checksum": "c45b29ece740643252d5402e76be1e33f96f9d6910053f79e80d39887f10c85e"}}, "download_size": 7519903, "post_processing_size": null, "dataset_size": 566686, "size_in_bytes": 8086589}, "X-CODAH-pt": {"description": "To evaluate multi-lingual language models (ML-LMs) for commonsense reasoning in a cross-lingual zero-shot transfer setting (X-CSR), i.e., training in English and test in other languages, we create two benchmark datasets, namely X-CSQA and X-CODAH. Specifically, we automatically translate the original CSQA and CODAH datasets, which only have English versions, to 15 other languages, forming development and test sets for studying X-CSR. As our goal is to evaluate different ML-LMs in a unified evaluation protocol for X-CSR, we argue that such translated examples, although might contain noise, can serve as a starting benchmark for us to obtain meaningful analysis, before more human-translated datasets will be available in the future.\n", "citation": "# X-CSR\n@inproceedings{lin-etal-2021-common,\n    title = \"Common Sense Beyond {E}nglish: Evaluating and Improving Multilingual Language Models for Commonsense Reasoning\",\n    author = \"Lin, Bill Yuchen  and\n      Lee, Seyeon  and\n      Qiao, Xiaoyang  and\n      Ren, Xiang\",\n    booktitle = \"Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)\",\n    month = aug,\n    year = \"2021\",\n    address = \"Online\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2021.acl-long.102\",\n    doi = \"10.18653/v1/2021.acl-long.102\",\n    pages = \"1274--1287\",\n}\n\n# CSQA\n@inproceedings{Talmor2019commonsenseqaaq,\n    address = {Minneapolis, Minnesota},\n    author = {Talmor, Alon  and Herzig, Jonathan  and Lourie, Nicholas and Berant, Jonathan},\n    booktitle = {Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},\n    doi = {10.18653/v1/N19-1421},\n    pages = {4149--4158},\n    publisher = {Association for Computational Linguistics},\n    title = {CommonsenseQA: A Question Answering Challenge Targeting Commonsense Knowledge},\n    url = {https://www.aclweb.org/anthology/N19-1421},\n    year = {2019}\n}\n\n# CODAH\n@inproceedings{Chen2019CODAHAA,\n    address = {Minneapolis, USA},\n    author = {Chen, Michael  and D{'}Arcy, Mike  and Liu, Alisa  and Fernandez, Jared  and Downey, Doug},\n    booktitle = {Proceedings of the 3rd Workshop on Evaluating Vector Space Representations for {NLP}},\n    doi = {10.18653/v1/W19-2008},\n    pages = {63--69},\n    publisher = {Association for Computational Linguistics},\n    title = {CODAH: An Adversarially-Authored Question Answering Dataset for Common Sense},\n    url = {https://www.aclweb.org/anthology/W19-2008},\n    year = {2019}\n}\n", "homepage": "https://inklab.usc.edu//XCSR/", "license": "", "features": {"id": {"dtype": "string", "id": null, "_type": "Value"}, "lang": {"dtype": "string", "id": null, "_type": "Value"}, "question_tag": {"dtype": "string", "id": null, "_type": "Value"}, "question": {"stem": {"dtype": "string", "id": null, "_type": "Value"}, "choices": {"feature": {"label": {"dtype": "string", "id": null, "_type": "Value"}, "text": {"dtype": "string", "id": null, "_type": "Value"}}, "length": -1, "id": null, "_type": "Sequence"}}, "answerKey": {"dtype": "string", "id": null, "_type": "Value"}}, "post_processed": null, "supervised_keys": null, "task_templates": null, "builder_name": "xcsr", "config_name": "X-CODAH-pt", "version": {"version_str": "1.1.0", "description": "", "major": 1, "minor": 1, "patch": 0}, "splits": {"test": {"name": "test", "num_bytes": 455869, "num_examples": 1000, "dataset_name": "xcsr"}, "validation": {"name": "validation", "num_bytes": 132045, "num_examples": 300, "dataset_name": "xcsr"}}, "download_checksums": {"https://inklab.usc.edu/XCSR/xcsr_datasets.zip": {"num_bytes": 7519903, "checksum": "c45b29ece740643252d5402e76be1e33f96f9d6910053f79e80d39887f10c85e"}}, "download_size": 7519903, "post_processing_size": null, "dataset_size": 587914, "size_in_bytes": 8107817}, "X-CODAH-ru": {"description": "To evaluate multi-lingual language models (ML-LMs) for commonsense reasoning in a cross-lingual zero-shot transfer setting (X-CSR), i.e., training in English and test in other languages, we create two benchmark datasets, namely X-CSQA and X-CODAH. Specifically, we automatically translate the original CSQA and CODAH datasets, which only have English versions, to 15 other languages, forming development and test sets for studying X-CSR. As our goal is to evaluate different ML-LMs in a unified evaluation protocol for X-CSR, we argue that such translated examples, although might contain noise, can serve as a starting benchmark for us to obtain meaningful analysis, before more human-translated datasets will be available in the future.\n", "citation": "# X-CSR\n@inproceedings{lin-etal-2021-common,\n    title = \"Common Sense Beyond {E}nglish: Evaluating and Improving Multilingual Language Models for Commonsense Reasoning\",\n    author = \"Lin, Bill Yuchen  and\n      Lee, Seyeon  and\n      Qiao, Xiaoyang  and\n      Ren, Xiang\",\n    booktitle = \"Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)\",\n    month = aug,\n    year = \"2021\",\n    address = \"Online\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2021.acl-long.102\",\n    doi = \"10.18653/v1/2021.acl-long.102\",\n    pages = \"1274--1287\",\n}\n\n# CSQA\n@inproceedings{Talmor2019commonsenseqaaq,\n    address = {Minneapolis, Minnesota},\n    author = {Talmor, Alon  and Herzig, Jonathan  and Lourie, Nicholas and Berant, Jonathan},\n    booktitle = {Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},\n    doi = {10.18653/v1/N19-1421},\n    pages = {4149--4158},\n    publisher = {Association for Computational Linguistics},\n    title = {CommonsenseQA: A Question Answering Challenge Targeting Commonsense Knowledge},\n    url = {https://www.aclweb.org/anthology/N19-1421},\n    year = {2019}\n}\n\n# CODAH\n@inproceedings{Chen2019CODAHAA,\n    address = {Minneapolis, USA},\n    author = {Chen, Michael  and D{'}Arcy, Mike  and Liu, Alisa  and Fernandez, Jared  and Downey, Doug},\n    booktitle = {Proceedings of the 3rd Workshop on Evaluating Vector Space Representations for {NLP}},\n    doi = {10.18653/v1/W19-2008},\n    pages = {63--69},\n    publisher = {Association for Computational Linguistics},\n    title = {CODAH: An Adversarially-Authored Question Answering Dataset for Common Sense},\n    url = {https://www.aclweb.org/anthology/W19-2008},\n    year = {2019}\n}\n", "homepage": "https://inklab.usc.edu//XCSR/", "license": "", "features": {"id": {"dtype": "string", "id": null, "_type": "Value"}, "lang": {"dtype": "string", "id": null, "_type": "Value"}, "question_tag": {"dtype": "string", "id": null, "_type": "Value"}, "question": {"stem": {"dtype": "string", "id": null, "_type": "Value"}, "choices": {"feature": {"label": {"dtype": "string", "id": null, "_type": "Value"}, "text": {"dtype": "string", "id": null, "_type": "Value"}}, "length": -1, "id": null, "_type": "Sequence"}}, "answerKey": {"dtype": "string", "id": null, "_type": "Value"}}, "post_processed": null, "supervised_keys": null, "task_templates": null, "builder_name": "xcsr", "config_name": "X-CODAH-ru", "version": {"version_str": "1.1.0", "description": "", "major": 1, "minor": 1, "patch": 0}, "splits": {"test": {"name": "test", "num_bytes": 674853, "num_examples": 1000, "dataset_name": "xcsr"}, "validation": {"name": "validation", "num_bytes": 193825, "num_examples": 300, "dataset_name": "xcsr"}}, "download_checksums": {"https://inklab.usc.edu/XCSR/xcsr_datasets.zip": {"num_bytes": 7519903, "checksum": "c45b29ece740643252d5402e76be1e33f96f9d6910053f79e80d39887f10c85e"}}, "download_size": 7519903, "post_processing_size": null, "dataset_size": 868678, "size_in_bytes": 8388581}, "X-CODAH-ar": {"description": "To evaluate multi-lingual language models (ML-LMs) for commonsense reasoning in a cross-lingual zero-shot transfer setting (X-CSR), i.e., training in English and test in other languages, we create two benchmark datasets, namely X-CSQA and X-CODAH. Specifically, we automatically translate the original CSQA and CODAH datasets, which only have English versions, to 15 other languages, forming development and test sets for studying X-CSR. As our goal is to evaluate different ML-LMs in a unified evaluation protocol for X-CSR, we argue that such translated examples, although might contain noise, can serve as a starting benchmark for us to obtain meaningful analysis, before more human-translated datasets will be available in the future.\n", "citation": "# X-CSR\n@inproceedings{lin-etal-2021-common,\n    title = \"Common Sense Beyond {E}nglish: Evaluating and Improving Multilingual Language Models for Commonsense Reasoning\",\n    author = \"Lin, Bill Yuchen  and\n      Lee, Seyeon  and\n      Qiao, Xiaoyang  and\n      Ren, Xiang\",\n    booktitle = \"Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)\",\n    month = aug,\n    year = \"2021\",\n    address = \"Online\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2021.acl-long.102\",\n    doi = \"10.18653/v1/2021.acl-long.102\",\n    pages = \"1274--1287\",\n}\n\n# CSQA\n@inproceedings{Talmor2019commonsenseqaaq,\n    address = {Minneapolis, Minnesota},\n    author = {Talmor, Alon  and Herzig, Jonathan  and Lourie, Nicholas and Berant, Jonathan},\n    booktitle = {Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},\n    doi = {10.18653/v1/N19-1421},\n    pages = {4149--4158},\n    publisher = {Association for Computational Linguistics},\n    title = {CommonsenseQA: A Question Answering Challenge Targeting Commonsense Knowledge},\n    url = {https://www.aclweb.org/anthology/N19-1421},\n    year = {2019}\n}\n\n# CODAH\n@inproceedings{Chen2019CODAHAA,\n    address = {Minneapolis, USA},\n    author = {Chen, Michael  and D{'}Arcy, Mike  and Liu, Alisa  and Fernandez, Jared  and Downey, Doug},\n    booktitle = {Proceedings of the 3rd Workshop on Evaluating Vector Space Representations for {NLP}},\n    doi = {10.18653/v1/W19-2008},\n    pages = {63--69},\n    publisher = {Association for Computational Linguistics},\n    title = {CODAH: An Adversarially-Authored Question Answering Dataset for Common Sense},\n    url = {https://www.aclweb.org/anthology/W19-2008},\n    year = {2019}\n}\n", "homepage": "https://inklab.usc.edu//XCSR/", "license": "", "features": {"id": {"dtype": "string", "id": null, "_type": "Value"}, "lang": {"dtype": "string", "id": null, "_type": "Value"}, "question_tag": {"dtype": "string", "id": null, "_type": "Value"}, "question": {"stem": {"dtype": "string", "id": null, "_type": "Value"}, "choices": {"feature": {"label": {"dtype": "string", "id": null, "_type": "Value"}, "text": {"dtype": "string", "id": null, "_type": "Value"}}, "length": -1, "id": null, "_type": "Sequence"}}, "answerKey": {"dtype": "string", "id": null, "_type": "Value"}}, "post_processed": null, "supervised_keys": null, "task_templates": null, "builder_name": "xcsr", "config_name": "X-CODAH-ar", "version": {"version_str": "1.1.0", "description": "", "major": 1, "minor": 1, "patch": 0}, "splits": {"test": {"name": "test", "num_bytes": 568312, "num_examples": 1000, "dataset_name": "xcsr"}, "validation": {"name": "validation", "num_bytes": 165134, "num_examples": 300, "dataset_name": "xcsr"}}, "download_checksums": {"https://inklab.usc.edu/XCSR/xcsr_datasets.zip": {"num_bytes": 7519903, "checksum": "c45b29ece740643252d5402e76be1e33f96f9d6910053f79e80d39887f10c85e"}}, "download_size": 7519903, "post_processing_size": null, "dataset_size": 733446, "size_in_bytes": 8253349}, "X-CODAH-vi": {"description": "To evaluate multi-lingual language models (ML-LMs) for commonsense reasoning in a cross-lingual zero-shot transfer setting (X-CSR), i.e., training in English and test in other languages, we create two benchmark datasets, namely X-CSQA and X-CODAH. Specifically, we automatically translate the original CSQA and CODAH datasets, which only have English versions, to 15 other languages, forming development and test sets for studying X-CSR. As our goal is to evaluate different ML-LMs in a unified evaluation protocol for X-CSR, we argue that such translated examples, although might contain noise, can serve as a starting benchmark for us to obtain meaningful analysis, before more human-translated datasets will be available in the future.\n", "citation": "# X-CSR\n@inproceedings{lin-etal-2021-common,\n    title = \"Common Sense Beyond {E}nglish: Evaluating and Improving Multilingual Language Models for Commonsense Reasoning\",\n    author = \"Lin, Bill Yuchen  and\n      Lee, Seyeon  and\n      Qiao, Xiaoyang  and\n      Ren, Xiang\",\n    booktitle = \"Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)\",\n    month = aug,\n    year = \"2021\",\n    address = \"Online\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2021.acl-long.102\",\n    doi = \"10.18653/v1/2021.acl-long.102\",\n    pages = \"1274--1287\",\n}\n\n# CSQA\n@inproceedings{Talmor2019commonsenseqaaq,\n    address = {Minneapolis, Minnesota},\n    author = {Talmor, Alon  and Herzig, Jonathan  and Lourie, Nicholas and Berant, Jonathan},\n    booktitle = {Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},\n    doi = {10.18653/v1/N19-1421},\n    pages = {4149--4158},\n    publisher = {Association for Computational Linguistics},\n    title = {CommonsenseQA: A Question Answering Challenge Targeting Commonsense Knowledge},\n    url = {https://www.aclweb.org/anthology/N19-1421},\n    year = {2019}\n}\n\n# CODAH\n@inproceedings{Chen2019CODAHAA,\n    address = {Minneapolis, USA},\n    author = {Chen, Michael  and D{'}Arcy, Mike  and Liu, Alisa  and Fernandez, Jared  and Downey, Doug},\n    booktitle = {Proceedings of the 3rd Workshop on Evaluating Vector Space Representations for {NLP}},\n    doi = {10.18653/v1/W19-2008},\n    pages = {63--69},\n    publisher = {Association for Computational Linguistics},\n    title = {CODAH: An Adversarially-Authored Question Answering Dataset for Common Sense},\n    url = {https://www.aclweb.org/anthology/W19-2008},\n    year = {2019}\n}\n", "homepage": "https://inklab.usc.edu//XCSR/", "license": "", "features": {"id": {"dtype": "string", "id": null, "_type": "Value"}, "lang": {"dtype": "string", "id": null, "_type": "Value"}, "question_tag": {"dtype": "string", "id": null, "_type": "Value"}, "question": {"stem": {"dtype": "string", "id": null, "_type": "Value"}, "choices": {"feature": {"label": {"dtype": "string", "id": null, "_type": "Value"}, "text": {"dtype": "string", "id": null, "_type": "Value"}}, "length": -1, "id": null, "_type": "Sequence"}}, "answerKey": {"dtype": "string", "id": null, "_type": "Value"}}, "post_processed": null, "supervised_keys": null, "task_templates": null, "builder_name": "xcsr", "config_name": "X-CODAH-vi", "version": {"version_str": "1.1.0", "description": "", "major": 1, "minor": 1, "patch": 0}, "splits": {"test": {"name": "test", "num_bytes": 543375, "num_examples": 1000, "dataset_name": "xcsr"}, "validation": {"name": "validation", "num_bytes": 157000, "num_examples": 300, "dataset_name": "xcsr"}}, "download_checksums": {"https://inklab.usc.edu/XCSR/xcsr_datasets.zip": {"num_bytes": 7519903, "checksum": "c45b29ece740643252d5402e76be1e33f96f9d6910053f79e80d39887f10c85e"}}, "download_size": 7519903, "post_processing_size": null, "dataset_size": 700375, "size_in_bytes": 8220278}, "X-CODAH-hi": {"description": "To evaluate multi-lingual language models (ML-LMs) for commonsense reasoning in a cross-lingual zero-shot transfer setting (X-CSR), i.e., training in English and test in other languages, we create two benchmark datasets, namely X-CSQA and X-CODAH. Specifically, we automatically translate the original CSQA and CODAH datasets, which only have English versions, to 15 other languages, forming development and test sets for studying X-CSR. As our goal is to evaluate different ML-LMs in a unified evaluation protocol for X-CSR, we argue that such translated examples, although might contain noise, can serve as a starting benchmark for us to obtain meaningful analysis, before more human-translated datasets will be available in the future.\n", "citation": "# X-CSR\n@inproceedings{lin-etal-2021-common,\n    title = \"Common Sense Beyond {E}nglish: Evaluating and Improving Multilingual Language Models for Commonsense Reasoning\",\n    author = \"Lin, Bill Yuchen  and\n      Lee, Seyeon  and\n      Qiao, Xiaoyang  and\n      Ren, Xiang\",\n    booktitle = \"Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)\",\n    month = aug,\n    year = \"2021\",\n    address = \"Online\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2021.acl-long.102\",\n    doi = \"10.18653/v1/2021.acl-long.102\",\n    pages = \"1274--1287\",\n}\n\n# CSQA\n@inproceedings{Talmor2019commonsenseqaaq,\n    address = {Minneapolis, Minnesota},\n    author = {Talmor, Alon  and Herzig, Jonathan  and Lourie, Nicholas and Berant, Jonathan},\n    booktitle = {Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},\n    doi = {10.18653/v1/N19-1421},\n    pages = {4149--4158},\n    publisher = {Association for Computational Linguistics},\n    title = {CommonsenseQA: A Question Answering Challenge Targeting Commonsense Knowledge},\n    url = {https://www.aclweb.org/anthology/N19-1421},\n    year = {2019}\n}\n\n# CODAH\n@inproceedings{Chen2019CODAHAA,\n    address = {Minneapolis, USA},\n    author = {Chen, Michael  and D{'}Arcy, Mike  and Liu, Alisa  and Fernandez, Jared  and Downey, Doug},\n    booktitle = {Proceedings of the 3rd Workshop on Evaluating Vector Space Representations for {NLP}},\n    doi = {10.18653/v1/W19-2008},\n    pages = {63--69},\n    publisher = {Association for Computational Linguistics},\n    title = {CODAH: An Adversarially-Authored Question Answering Dataset for Common Sense},\n    url = {https://www.aclweb.org/anthology/W19-2008},\n    year = {2019}\n}\n", "homepage": "https://inklab.usc.edu//XCSR/", "license": "", "features": {"id": {"dtype": "string", "id": null, "_type": "Value"}, "lang": {"dtype": "string", "id": null, "_type": "Value"}, "question_tag": {"dtype": "string", "id": null, "_type": "Value"}, "question": {"stem": {"dtype": "string", "id": null, "_type": "Value"}, "choices": {"feature": {"label": {"dtype": "string", "id": null, "_type": "Value"}, "text": {"dtype": "string", "id": null, "_type": "Value"}}, "length": -1, "id": null, "_type": "Sequence"}}, "answerKey": {"dtype": "string", "id": null, "_type": "Value"}}, "post_processed": null, "supervised_keys": null, "task_templates": null, "builder_name": "xcsr", "config_name": "X-CODAH-hi", "version": {"version_str": "1.1.0", "description": "", "major": 1, "minor": 1, "patch": 0}, "splits": {"test": {"name": "test", "num_bytes": 974019, "num_examples": 1000, "dataset_name": "xcsr"}, "validation": {"name": "validation", "num_bytes": 283116, "num_examples": 300, "dataset_name": "xcsr"}}, "download_checksums": {"https://inklab.usc.edu/XCSR/xcsr_datasets.zip": {"num_bytes": 7519903, "checksum": "c45b29ece740643252d5402e76be1e33f96f9d6910053f79e80d39887f10c85e"}}, "download_size": 7519903, "post_processing_size": null, "dataset_size": 1257135, "size_in_bytes": 8777038}, "X-CODAH-sw": {"description": "To evaluate multi-lingual language models (ML-LMs) for commonsense reasoning in a cross-lingual zero-shot transfer setting (X-CSR), i.e., training in English and test in other languages, we create two benchmark datasets, namely X-CSQA and X-CODAH. Specifically, we automatically translate the original CSQA and CODAH datasets, which only have English versions, to 15 other languages, forming development and test sets for studying X-CSR. As our goal is to evaluate different ML-LMs in a unified evaluation protocol for X-CSR, we argue that such translated examples, although might contain noise, can serve as a starting benchmark for us to obtain meaningful analysis, before more human-translated datasets will be available in the future.\n", "citation": "# X-CSR\n@inproceedings{lin-etal-2021-common,\n    title = \"Common Sense Beyond {E}nglish: Evaluating and Improving Multilingual Language Models for Commonsense Reasoning\",\n    author = \"Lin, Bill Yuchen  and\n      Lee, Seyeon  and\n      Qiao, Xiaoyang  and\n      Ren, Xiang\",\n    booktitle = \"Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)\",\n    month = aug,\n    year = \"2021\",\n    address = \"Online\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2021.acl-long.102\",\n    doi = \"10.18653/v1/2021.acl-long.102\",\n    pages = \"1274--1287\",\n}\n\n# CSQA\n@inproceedings{Talmor2019commonsenseqaaq,\n    address = {Minneapolis, Minnesota},\n    author = {Talmor, Alon  and Herzig, Jonathan  and Lourie, Nicholas and Berant, Jonathan},\n    booktitle = {Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},\n    doi = {10.18653/v1/N19-1421},\n    pages = {4149--4158},\n    publisher = {Association for Computational Linguistics},\n    title = {CommonsenseQA: A Question Answering Challenge Targeting Commonsense Knowledge},\n    url = {https://www.aclweb.org/anthology/N19-1421},\n    year = {2019}\n}\n\n# CODAH\n@inproceedings{Chen2019CODAHAA,\n    address = {Minneapolis, USA},\n    author = {Chen, Michael  and D{'}Arcy, Mike  and Liu, Alisa  and Fernandez, Jared  and Downey, Doug},\n    booktitle = {Proceedings of the 3rd Workshop on Evaluating Vector Space Representations for {NLP}},\n    doi = {10.18653/v1/W19-2008},\n    pages = {63--69},\n    publisher = {Association for Computational Linguistics},\n    title = {CODAH: An Adversarially-Authored Question Answering Dataset for Common Sense},\n    url = {https://www.aclweb.org/anthology/W19-2008},\n    year = {2019}\n}\n", "homepage": "https://inklab.usc.edu//XCSR/", "license": "", "features": {"id": {"dtype": "string", "id": null, "_type": "Value"}, "lang": {"dtype": "string", "id": null, "_type": "Value"}, "question_tag": {"dtype": "string", "id": null, "_type": "Value"}, "question": {"stem": {"dtype": "string", "id": null, "_type": "Value"}, "choices": {"feature": {"label": {"dtype": "string", "id": null, "_type": "Value"}, "text": {"dtype": "string", "id": null, "_type": "Value"}}, "length": -1, "id": null, "_type": "Sequence"}}, "answerKey": {"dtype": "string", "id": null, "_type": "Value"}}, "post_processed": null, "supervised_keys": null, "task_templates": null, "builder_name": "xcsr", "config_name": "X-CODAH-sw", "version": {"version_str": "1.1.0", "description": "", "major": 1, "minor": 1, "patch": 0}, "splits": {"test": {"name": "test", "num_bytes": 423707, "num_examples": 1000, "dataset_name": "xcsr"}, "validation": {"name": "validation", "num_bytes": 124882, "num_examples": 300, "dataset_name": "xcsr"}}, "download_checksums": {"https://inklab.usc.edu/XCSR/xcsr_datasets.zip": {"num_bytes": 7519903, "checksum": "c45b29ece740643252d5402e76be1e33f96f9d6910053f79e80d39887f10c85e"}}, "download_size": 7519903, "post_processing_size": null, "dataset_size": 548589, "size_in_bytes": 8068492}, "X-CODAH-ur": {"description": "To evaluate multi-lingual language models (ML-LMs) for commonsense reasoning in a cross-lingual zero-shot transfer setting (X-CSR), i.e., training in English and test in other languages, we create two benchmark datasets, namely X-CSQA and X-CODAH. Specifically, we automatically translate the original CSQA and CODAH datasets, which only have English versions, to 15 other languages, forming development and test sets for studying X-CSR. As our goal is to evaluate different ML-LMs in a unified evaluation protocol for X-CSR, we argue that such translated examples, although might contain noise, can serve as a starting benchmark for us to obtain meaningful analysis, before more human-translated datasets will be available in the future.\n", "citation": "# X-CSR\n@inproceedings{lin-etal-2021-common,\n    title = \"Common Sense Beyond {E}nglish: Evaluating and Improving Multilingual Language Models for Commonsense Reasoning\",\n    author = \"Lin, Bill Yuchen  and\n      Lee, Seyeon  and\n      Qiao, Xiaoyang  and\n      Ren, Xiang\",\n    booktitle = \"Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)\",\n    month = aug,\n    year = \"2021\",\n    address = \"Online\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2021.acl-long.102\",\n    doi = \"10.18653/v1/2021.acl-long.102\",\n    pages = \"1274--1287\",\n}\n\n# CSQA\n@inproceedings{Talmor2019commonsenseqaaq,\n    address = {Minneapolis, Minnesota},\n    author = {Talmor, Alon  and Herzig, Jonathan  and Lourie, Nicholas and Berant, Jonathan},\n    booktitle = {Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},\n    doi = {10.18653/v1/N19-1421},\n    pages = {4149--4158},\n    publisher = {Association for Computational Linguistics},\n    title = {CommonsenseQA: A Question Answering Challenge Targeting Commonsense Knowledge},\n    url = {https://www.aclweb.org/anthology/N19-1421},\n    year = {2019}\n}\n\n# CODAH\n@inproceedings{Chen2019CODAHAA,\n    address = {Minneapolis, USA},\n    author = {Chen, Michael  and D{'}Arcy, Mike  and Liu, Alisa  and Fernandez, Jared  and Downey, Doug},\n    booktitle = {Proceedings of the 3rd Workshop on Evaluating Vector Space Representations for {NLP}},\n    doi = {10.18653/v1/W19-2008},\n    pages = {63--69},\n    publisher = {Association for Computational Linguistics},\n    title = {CODAH: An Adversarially-Authored Question Answering Dataset for Common Sense},\n    url = {https://www.aclweb.org/anthology/W19-2008},\n    year = {2019}\n}\n", "homepage": "https://inklab.usc.edu//XCSR/", "license": "", "features": {"id": {"dtype": "string", "id": null, "_type": "Value"}, "lang": {"dtype": "string", "id": null, "_type": "Value"}, "question_tag": {"dtype": "string", "id": null, "_type": "Value"}, "question": {"stem": {"dtype": "string", "id": null, "_type": "Value"}, "choices": {"feature": {"label": {"dtype": "string", "id": null, "_type": "Value"}, "text": {"dtype": "string", "id": null, "_type": "Value"}}, "length": -1, "id": null, "_type": "Sequence"}}, "answerKey": {"dtype": "string", "id": null, "_type": "Value"}}, "post_processed": null, "supervised_keys": null, "task_templates": null, "builder_name": "xcsr", "config_name": "X-CODAH-ur", "version": {"version_str": "1.1.0", "description": "", "major": 1, "minor": 1, "patch": 0}, "splits": {"test": {"name": "test", "num_bytes": 687409, "num_examples": 1000, "dataset_name": "xcsr"}, "validation": {"name": "validation", "num_bytes": 199849, "num_examples": 300, "dataset_name": "xcsr"}}, "download_checksums": {"https://inklab.usc.edu/XCSR/xcsr_datasets.zip": {"num_bytes": 7519903, "checksum": "c45b29ece740643252d5402e76be1e33f96f9d6910053f79e80d39887f10c85e"}}, "download_size": 7519903, "post_processing_size": null, "dataset_size": 887258, "size_in_bytes": 8407161}}